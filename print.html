<!DOCTYPE HTML>
<html lang="en" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Calyx Documentation</title>
        <meta name="robots" content="noindex" />


        <!-- Custom HTML head -->
        
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        <link rel="icon" href="favicon.svg">
        <link rel="shortcut icon" href="favicon.png">
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        <link rel="stylesheet" href="css/print.css" media="print">

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        <link rel="stylesheet" href="fonts/fonts.css">

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->

        <!-- MathJax -->
        <script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
    </head>
    <body>
    <div id="body-container">
        <!-- Provide site root to javascript -->
        <script>
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script>
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script>
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script>
            var html = document.querySelector('html');
            var sidebar = null;
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            } else {
                sidebar = 'hidden';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="intro.html">Getting Started</a></li><li class="chapter-item expanded affix "><li class="part-title">Calyx Language</li><li class="chapter-item expanded "><a href="tutorial/language-tut.html"><strong aria-hidden="true">1.</strong> Language Tutorial</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="lang/multi-component.html"><strong aria-hidden="true">1.1.</strong> Multi-Component Designs</a></li><li class="chapter-item expanded "><a href="lang/memories-by-reference.html"><strong aria-hidden="true">1.2.</strong> Passing Memories by Reference</a></li></ol></li><li class="chapter-item expanded "><a href="lang/ref.html"><strong aria-hidden="true">2.</strong> Language Reference</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="lang/data-format.html"><strong aria-hidden="true">2.1.</strong> Data Format</a></li><li class="chapter-item expanded "><a href="lang/static.html"><strong aria-hidden="true">2.2.</strong> Static Timing</a></li><li class="chapter-item expanded "><a href="lang/sync.html"><strong aria-hidden="true">2.3.</strong> Experimental: Synchronization</a></li><li class="chapter-item expanded "><a href="lang/undefined.html"><strong aria-hidden="true">2.4.</strong> Undefined Behaviors</a></li></ol></li><li class="chapter-item expanded "><a href="lang/attributes.html"><strong aria-hidden="true">3.</strong> Attributes</a></li><li class="chapter-item expanded affix "><li class="part-title">Running Calyx Programs</li><li class="chapter-item expanded "><a href="fud/index.html"><strong aria-hidden="true">4.</strong> fud: The Calyx Driver</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="fud/examples.html"><strong aria-hidden="true">4.1.</strong> Examples</a></li><li class="chapter-item expanded "><a href="fud/xilinx.html"><strong aria-hidden="true">4.2.</strong> Xilinx Tools</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="fud/axi-gen.html"><strong aria-hidden="true">4.2.1.</strong> AXI Generation</a></li></ol></li><li class="chapter-item expanded "><a href="fud/external.html"><strong aria-hidden="true">4.3.</strong> External Stages</a></li><li class="chapter-item expanded "><a href="fud/multiple-paths.html"><strong aria-hidden="true">4.4.</strong> Multiple Paths</a></li><li class="chapter-item expanded "><a href="fud/circt.html"><strong aria-hidden="true">4.5.</strong> CIRCT</a></li><li class="chapter-item expanded "><a href="fud/resource-estimation.html"><strong aria-hidden="true">4.6.</strong> Resource Estimation</a></li></ol></li><li class="chapter-item expanded "><a href="interpreter.html"><strong aria-hidden="true">5.</strong> The Calyx Interpreter</a></li><li class="chapter-item expanded affix "><li class="part-title">Compile Development Guide</li><li class="chapter-item expanded "><a href="compiler.html"><strong aria-hidden="true">6.</strong> The Calyx Compiler</a></li><li class="chapter-item expanded "><a href="new-pass.html"><strong aria-hidden="true">7.</strong> Adding a New Pass</a></li><li class="chapter-item expanded "><a href="libraries/core.html"><strong aria-hidden="true">8.</strong> Primitive Library</a></li><li class="chapter-item expanded "><a href="compiler-as-library.html"><strong aria-hidden="true">9.</strong> The calyx Library</a></li><li class="chapter-item expanded "><a href="optimizations/dataflow.html"><strong aria-hidden="true">10.</strong> Dataflow Analysis</a></li><li class="chapter-item expanded "><a href="debug/index.html"><strong aria-hidden="true">11.</strong> Debugging</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="debug/cider.html"><strong aria-hidden="true">11.1.</strong> Logical Bugs</a></li><li class="chapter-item expanded "><a href="debug/debug.html"><strong aria-hidden="true">11.2.</strong> Compilation Bugs</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Generating Calyx</li><li class="chapter-item expanded "><a href="builder/calyx-py.html"><strong aria-hidden="true">12.</strong> Emitting Calyx from Python</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="builder/ref.html"><strong aria-hidden="true">12.1.</strong> calyx-py Builder Reference</a></li></ol></li><li class="chapter-item expanded "><a href="tutorial/frontend-tut.html"><strong aria-hidden="true">13.</strong> Frontend Tutorial</a></li><li class="chapter-item expanded "><a href="frontends/index.html"><strong aria-hidden="true">14.</strong> Frontend Compilers</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="frontends/dahlia.html"><strong aria-hidden="true">14.1.</strong> Dahlia</a></li><li class="chapter-item expanded "><a href="frontends/systolic-array.html"><strong aria-hidden="true">14.2.</strong> Systolic Array Generator</a></li><li class="chapter-item expanded "><a href="frontends/tvm-relay.html"><strong aria-hidden="true">14.3.</strong> TVM Relay</a></li><li class="chapter-item expanded "><a href="frontends/ntt.html"><strong aria-hidden="true">14.4.</strong> NTT Pipeline Generator</a></li><li class="chapter-item expanded "><a href="frontends/mrxl.html"><strong aria-hidden="true">14.5.</strong> MrXL</a></li></ol></li><li class="chapter-item expanded "><li class="part-title">Tools</li><li class="chapter-item expanded "><a href="tools/runt.html"><strong aria-hidden="true">15.</strong> Runt</a></li><li class="chapter-item expanded "><a href="tools/data-gen.html"><strong aria-hidden="true">16.</strong> Data Gen</a></li><li class="chapter-item expanded "><a href="tools/exp-generator.html"><strong aria-hidden="true">17.</strong> exp Generator</a></li><li class="chapter-item expanded "><a href="tools/editor-highlighting.html"><strong aria-hidden="true">18.</strong> Editor Highlighting</a></li><li class="spacer"></li><li class="chapter-item expanded affix "><a href="contributors.html">Contributors</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <!-- Track and set sidebar scroll position -->
        <script>
            var sidebarScrollbox = document.querySelector('#sidebar .sidebar-scrollbox');
            sidebarScrollbox.addEventListener('click', function(e) {
                if (e.target.tagName === 'A') {
                    sessionStorage.setItem('sidebar-scroll', sidebarScrollbox.scrollTop);
                }
            }, { passive: true });
            var sidebarScrollTop = sessionStorage.getItem('sidebar-scroll');
            sessionStorage.removeItem('sidebar-scroll');
            if (sidebarScrollTop) {
                // preserve sidebar scroll position when navigating via links within sidebar
                sidebarScrollbox.scrollTop = sidebarScrollTop;
            } else {
                // scroll sidebar to current active section when navigating via "next/previous chapter" buttons
                var activeSection = document.querySelector('#sidebar .active');
                if (activeSection) {
                    activeSection.scrollIntoView({ block: 'center' });
                }
            }
        </script>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                    </div>

                    <h1 class="menu-title">Calyx Documentation</h1>

                    <div class="right-buttons">
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>

                    </div>
                </div>

                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script>
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1 id="getting-started"><a class="header" href="#getting-started">Getting Started</a></h1>
<p>Calyx is an intermediate language and infrastructure for building compilers
that generate custom hardware accelerators.
These instructions will help you set up the Calyx compiler and associated
tools.
By the end, you should be able to compile and simulate hardware designs
generated by Calyx.</p>
<h2 id="compiler-installation"><a class="header" href="#compiler-installation">Compiler Installation</a></h2>
<p>There are three possible ways to install Calyx, depending on your goals.</p>
<h3 id="using-docker"><a class="header" href="#using-docker">Using Docker</a></h3>
<p>The easiest way is to use the <a href="https://github.com/cucapra/calyx/pkgs/container/calyx">Calyx Docker image</a> that provides a pinned version of the compiler, all frontends, as well as configuration for several tools.</p>
<p>The following commands will fetch the Docker image and start a container with an interactive shell:</p>
<pre><code class="language-sh">docker run -it --rm ghcr.io/cucapra/calyx:latest
</code></pre>
<p>The <code>--rm</code> flag will remove the container after you exit the shell. If you want to keep the container around, remove the flag.</p>
<p>You can skip forward to <a href="./intro.html#running-a-hardware-design"><em>running a hardware design</em></a>.</p>
<h3 id="installing-the-crate-to-use-but-not-extend-calyx"><a class="header" href="#installing-the-crate-to-use-but-not-extend-calyx">Installing the Crate (to use, but not extend, Calyx)</a></h3>
<p>First, install <a href="https://doc.rust-lang.org/cargo/getting-started/installation.html">Rust</a>.
This should automatically install <code>cargo</code>.</p>
<p>If you want just to play with the compiler, install the <a href="https://crates.io/crates/calyx"><code>calyx</code> crate</a>:</p>
<pre><code>cargo install calyx
</code></pre>
<p>This will install the <code>calyx</code> binary which can optimize and compile Calyx programs. You will still need the <a href="https://github.com/cucapra/calyx/blob/master/primitives/core.futil"><code>primitives/core.futil</code></a> and <a href="https://github.com/cucapra/calyx/blob/master/primitives/core.sv">its accompanying Verilog file</a> library to compile most programs.</p>
<h3 id="installing-from-source-to-use-and-extend-calyx"><a class="header" href="#installing-from-source-to-use-and-extend-calyx">Installing from Source (to use and extend Calyx)</a></h3>
<p>First, install <a href="https://doc.rust-lang.org/cargo/getting-started/installation.html">Rust</a>.
This should automatically install <code>cargo</code>.</p>
<p>Clone the repository:</p>
<pre><code>git clone https://github.com/cucapra/calyx.git
</code></pre>
<p>Then build the compiler:</p>
<pre><code>cargo build
</code></pre>
<p>You can build and run the compiler with:</p>
<pre><code>cargo build # Builds the compiler
./target/debug/calyx --help # Executes the compiler binary
</code></pre>
<h2 id="running-core-tests"><a class="header" href="#running-core-tests">Running Core Tests</a></h2>
<p>The core test suite tests the Calyx compiler's various passes.
Install the following tools:</p>
<ol>
<li><a href="https://github.com/rachitnigam/runt">runt</a> hosts our testing infrastructure. Install with:
<code>cargo install runt</code></li>
<li><a href="https://stedolan.github.io/jq/">jq</a> is a command-line JSON processor. Install with:
<ul>
<li>Ubuntu: <code>sudo apt install jq</code></li>
<li>Mac: <code>brew install jq</code></li>
<li>Other platforms: <a href="https://stedolan.github.io/jq/">JQ installation</a></li>
</ul>
</li>
</ol>
<p>Build the compiler:</p>
<pre><code>cargo build
</code></pre>
<p>Then run the core tests with:</p>
<pre><code>runt -i core
</code></pre>
<p>If everything has been installed correctly, this should not produce any failing
tests.</p>
<h2 id="installing-the-command-line-driver"><a class="header" href="#installing-the-command-line-driver">Installing the Command-Line Driver</a></h2>
<p><a href="./fud">The Calyx driver</a> wraps the various compiler frontends and
backends to simplify running Calyx programs.</p>
<p>Install <a href="https://flit.readthedocs.io/en/latest/">Flit</a>:</p>
<pre><code>pip3 install flit
</code></pre>
<p>Install <code>fud</code> (from the root of the repository):</p>
<pre><code>flit -f fud/pyproject.toml install -s --deps production
</code></pre>
<p>Configure <code>fud</code>:</p>
<pre><code>fud config --create global.root &lt;full path to Calyx repository&gt;
</code></pre>
<p>Check the <code>fud</code> configuration:</p>
<pre><code>fud check
</code></pre>
<p><code>fud</code> will report certain tools are not available. This is expected.</p>
<h2 id="simulation"><a class="header" href="#simulation">Simulation</a></h2>
<p>There are three ways to run Calyx programs:
<a href="https://www.veripool.org/wiki/verilator">Verilator</a>, <a href="http://iverilog.icarus.com">Icarus Verilog</a>, and Calyx's native <a href="./interpreter.html">interpreter</a>.
You'll want to set up at least one of these options so you can try out your code.</p>
<p>Icarus Verilog is an easy way to get started on most platforms.
On a Mac, you can install it via <a href="https://brew.sh">Homebrew</a> by typing <code>brew install icarus-verilog</code>.
On Ubuntu, <a href="https://iverilog.fandom.com/wiki/Installation_Guide#Installation_From_Source">install from source</a>.
Then install the relevant <a href="./fud/index.html#icarus-verilog">fud support</a> by running:</p>
<pre><code>fud register icarus-verilog -p fud/icarus/icarus.py
</code></pre>
<p>Type <code>fud check</code> to make sure the new stage is working.
Some missing tools are again expected; just pay attention to the report for <code>stages.icarus-verilog.exec</code>.</p>
<p>It is worth saying a little about the alternatives.
You could consider:</p>
<ol>
<li><a href="./fud/index.html#verilator">Setting up Verilator</a> for faster performance, which is good for long-running simulations.</li>
<li>Using the <a href="./interpreter.html">interpreter</a> to avoid RTL simulation altogether.</li>
</ol>
<h2 id="running-a-hardware-design"><a class="header" href="#running-a-hardware-design">Running a Hardware Design</a></h2>
<p>You're all set to run a Calyx hardware design now. Run the following command:</p>
<pre><code>fud e examples/tutorial/language-tutorial-iterate.futil \
  -s verilog.data examples/tutorial/data.json \
  --to dat --through icarus-verilog -v
</code></pre>
<p>(Change the last bit to <code>--through verilog</code> to use Verilator instead.)</p>
<p>This command will compile <code>examples/tutorial/language-tutorial-iterate.futil</code> to Verilog
using the Calyx compiler, simulate the design using the data in <code>examples/tutorial/data.json</code>, and generate a JSON representation of the
final memory state.</p>
<p>Congratulations! You've simulated your first hardware design with Calyx.</p>
<h2 id="where-to-go-next"><a class="header" href="#where-to-go-next">Where to go next?</a></h2>
<ul>
<li><a href="./tools/editor-highlighting.html">How can I setup syntax highlighting in my editor?</a></li>
<li><a href="./tutorial/language-tut.html">How does the language work?</a></li>
<li><a href="./fud/index.html#dahlia-fronted">How do I install Calyx frontends?</a></li>
<li><a href="./fud/examples.html">Where can I see further examples with <code>fud</code>?</a></li>
<li><a href="./tutorial/frontend-tut.html">How do I write a frontend for Calyx?</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="calyx-language-tutorial"><a class="header" href="#calyx-language-tutorial">Calyx Language Tutorial</a></h1>
<p>This tutorial will familiarize you with the Calyx language by writing a minimal program <em>by hand</em>.
Usually, Calyx code will be generated by a frontend.
However, by writing the program by hand, you can get familiar with all the
basic constructs you need to generate Calyx yourself!</p>
<p>Complete code for each example can be found in the <a href="https://github.com/cucapra/calyx/tree/master/examples/tutorial">tutorial</a> directory in
the Calyx repository.</p>
<h2 id="get-started"><a class="header" href="#get-started">Get Started</a></h2>
<p>The basic building block of Calyx programs is a <em>component</em> which corresponds
to hardware modules (or function definitions for the software-minded).</p>
<p>Here is an empty component definition for <code>main</code> along with an <code>import</code>
statement to import the standard library:</p>
<pre><code>import &quot;primitives/core.futil&quot;;

component main(@go go: 1) -&gt; (@done done: 1) {
  cells {}
  wires {}
  control {}
}
</code></pre>
<p>Put this in a file—you can call it <code>language-tutorial-mem.futil</code>, for example.
(The <code>futil</code> file extension comes from an old name for Calyx.)</p>
<p>You can think of a component as a unit of Calyx code roughly analogous to a function: it encapsulates a logical unit of hardware structures along with their control.
Every component definition has three sections:</p>
<ul>
<li><code>cells</code>: The hardware subcomponents that make up this component.</li>
<li><code>wires</code>: A set of guarded connections between components, possibly organized into <em>groups</em>.</li>
<li><code>control</code>: The imperative program that defines the component's execution schedule: i.e., when each group executes.</li>
</ul>
<p>We'll fill these sections up minimally in the next sections.</p>
<h2 id="a-memory-cell"><a class="header" href="#a-memory-cell">A Memory Cell</a></h2>
<p>Let's turn our skeleton into a tiny, nearly no-op Calyx program.
We'll start by adding a memory component to the cells:</p>
<pre><code>  cells {
    @external mem = std_mem_d1(32, 1, 1);
  }
</code></pre>
<p>This new line declares a new cell called <code>mem</code> and the primitive component <code>std_mem_d1</code> represents a 1D memory.
You can see the definition of <code>std_mem_d1</code>, and all the other standard components, in the <code>primitives/core.futil</code> library we imported.</p>
<p>This one has three parameters:
the data width (here, 32 bits),
the number of elements (just one),
and the width of the address port (one bit).</p>
<p>The <code>@external</code> syntax is an <a href="tutorial/../lang/attributes.html#external">extra bit of magic</a> that allows us
to read and write to the memory.</p>
<p>Next, we'll add some assignments to the <code>wires</code> section to update the value in
the memory.
Insert these lines to put a constant value into the memory:</p>
<pre><code>  wires {
      mem.addr0 = 1'b0;
      mem.write_data = 32'd42;
      mem.write_en = 1'b1;
      done = mem.done;
  }
</code></pre>
<p>These assignments refer to four <em>ports</em> on the memory component:
<code>addr0</code> (the address port),
<code>write_data</code> (the value we're putting into the memory),
<code>write_en</code> (the <em>write enable</em> signal, telling the memory that it's time to do a write), and
<code>done</code> (signals that the write was committed).
Constants like <code>32'd42</code> are Verilog-like literals that include the bit width (32), the base (<code>d</code> for decimal), and the value (42).</p>
<p>Assignments at the top level in the <code>wires</code> section, like these, are &quot;continuous&quot;.
They always happen, without any need for <code>control</code> statements to orchestrate them.
We'll see later how to organize assignments into groups.</p>
<blockquote>
<p>The complete program for this section is available under <a href="https://github.com/cucapra/calyx/blob/master/examples/tutorial/language-tutorial-mem.futil">examples/tutorial/language-tutorial-mem.futil</a>.</p>
</blockquote>
<h2 id="compile--run"><a class="header" href="#compile--run">Compile &amp; Run</a></h2>
<p>We can almost run this program!
But first, we need to provide it with data.
The Calyx infrastructure can <a href="tutorial/../lang/data-format.html">provide data to programs</a> from <a href="https://www.json.org/">JSON</a> files.
So make a file called something like <code>data.json</code> containing something along these lines:</p>
<pre><code>{
  &quot;mem&quot;: {
    &quot;data&quot;: [10],
    &quot;format&quot;: {
      &quot;numeric_type&quot;: &quot;bitnum&quot;,
      &quot;is_signed&quot;: false,
      &quot;width&quot;: 32
    }
  }
}
</code></pre>
<p>The <code>mem</code> key means we're providing the initial value for our memory called <code>mem</code>.
We have one (unsigned integer) data element, and we indicate the bit width (32 bits).</p>
<p>If you want to see how this Calyx program compiles to Verilog, here's the <a href="tutorial/../fud/index.html">fud</a> incantation you need:</p>
<pre><code>fud exec language-tutorial-mem.futil --to verilog
</code></pre>
<p>Not terribly interesting!
However, one nice thing you can do with programs is execute them.</p>
<p>To run our program using <a href="http://iverilog.icarus.com">Icarus Verilog</a>, do this:</p>
<pre><code>fud exec language-tutorial-mem.futil --to dat --through icarus-verilog \
    -s verilog.data data.json
</code></pre>
<p>Using <code>--to dat</code> asks fud to run the program, and the extra <code>-s verilog.data &lt;filename&gt;</code> argument tells it where to find the input data.
The <code>--through icarus-verilog</code> option tells fud which Verilog simulator to use (see <a href="tutorial/../fud/index.html">the chapter about fud</a> for alternatives such as <a href="https://www.veripool.org/wiki/verilator">Verilator</a>).
Executing this program should print:</p>
<pre><code>{
  &quot;cycles&quot;: 1,
  &quot;memories&quot;: {
    &quot;mem&quot;: [
      42
    ]
  }
}
</code></pre>
<p>Meaning that, after the program finished, the final value in our memory was 42.</p>
<blockquote>
<p><strong>Note</strong>: Verilator may report a different cycle count compared to the one above. As long as the final value in memory is correct, this does not matter.</p>
</blockquote>
<h2 id="add-control"><a class="header" href="#add-control">Add Control</a></h2>
<p>Let's change our program to use an execution schedule.
First, we're going to wrap all the assignments in the <code>wires</code> section into a
name <em>group</em>:</p>
<pre><code>  wires {
    group the_answer {
      mem.addr0 = 1'b0;
      mem.write_data = 32'd42;
      mem.write_en = 1'b1;
      the_answer[done] = mem.done;
    }
  }
</code></pre>
<p>We also need one extra line in the group: that assignment to <code>the_answer[done]</code>.
Here, we say that <code>the_answer</code>'s work is done once the update to <code>mem</code> has finished.
Calyx groups have <em>compilation holes</em> called <code>go</code> and <code>done</code> that the control program will use to orchestrate their execution.</p>
<p>The last thing we need is a control program.
Add one line to activate <code>the_answer</code> and then finish:</p>
<pre><code>  control {
    the_answer;
  }
</code></pre>
<p>If you execute this program, it should do the same thing as the original group-free version: <code>mem</code> ends up with 42 in it.
But now we're controlling things with an execution schedule.</p>
<p>If you're curious to see how the Calyx compiler lowers this program to a Verilog-like structural form of Calyx, you can do this:</p>
<pre><code>fud exec language-tutorial-mem.futil --to calyx-lowered
</code></pre>
<p>Notably, you'll see <code>control {}</code> in the output, meaning that the compiler has eliminated all the control statements and replaced them with continuous assignments in <code>wires</code>.</p>
<blockquote>
<p>The complete program for this section is available under <a href="https://github.com/cucapra/calyx/blob/master/examples/tutorial/language-tutorial-control.futil">examples/tutorial/language-tutorial-control.futil</a>.</p>
</blockquote>
<h2 id="add-an-adder"><a class="header" href="#add-an-adder">Add an Adder</a></h2>
<p>The next step is to actually do some computation.
In this version of the program, we'll read a value from the memory, increment it, and store the updated value back to the memory.</p>
<p>First, we will add two components to the <code>cells</code> section:</p>
<pre><code>  cells {
    @external(1) mem = std_mem_d1(32, 1, 1);
    val = std_reg(32);
    add = std_add(32);
  }
</code></pre>
<p>We make a register <code>val</code> and an integer adder <code>add</code>, both configured to work on 32-bit values.</p>
<p>Next, we'll create three groups in the <code>wires</code> section for the three steps we want to run: read, increment, and write back to the memory.
Let's start with the last step, which looks pretty similar to our <code>the_answer</code> group from above, except that the value comes from the <code>val</code> register instead of a constant:</p>
<pre><code>    group write {
      mem.addr0 = 1'b0;
      mem.write_en = 1'b1;
      mem.write_data = val.out;
      write[done] = mem.done;
    }
</code></pre>
<p>Next, let's create a group <code>read</code> that moves the value from the memory to our register <code>val</code>:</p>
<pre><code>    group read {
      mem.addr0 = 1'b0;
      val.in = mem.read_data;
      val.write_en = 1'b1;
      read[done] = val.done;
    }
</code></pre>
<p>Here, we use the memory's <code>read_data</code> port to get the initial value out.</p>
<p>Finally, we need a third group to add and update the value in the register:</p>
<pre><code>    group upd {
      add.left = val.out;
      add.right = 32'd4;
      val.in = add.out;
      val.write_en = 1'b1;
      upd[done] = val.done;
    }
</code></pre>
<p>The <code>std_add</code> component from the standard library has two input ports, <code>left</code> and <code>right</code>, and a single output port, <code>out</code>, which we hook up to the register's <code>in</code> port.
This group adds a constant 4 to the register's value, updating it in place.
We can enable the <code>val</code> register with a constant 1 because the <code>std_add</code> component is <em>combinational</em>, meaning its results are ready &quot;instantly&quot; without the need to wait for a done signal.</p>
<p>We need to extend our control program to orchestrate the execution of the three groups.
We will need a <code>seq</code> statement to say we want to the three steps sequentially:</p>
<pre><code>  control {
    seq {
      read;
      upd;
      write;
    }
  }
</code></pre>
<p>Try running this program again.
The memory's initial value was 10, and its final value after execution should be 14.</p>
<blockquote>
<p>The complete program for this section is available under <a href="https://github.com/cucapra/calyx/blob/master/examples/tutorial/language-tutorial-compute.futil">examples/tutorial/language-tutorial-compute.futil</a>.</p>
</blockquote>
<h2 id="iterate"><a class="header" href="#iterate">Iterate</a></h2>
<p>Next, we'd like to run our little computation in a loop.
The idea is to use Calyx's <code>while</code> control construct, which works like this:</p>
<pre><code>while &lt;value&gt; with &lt;group&gt; {
  &lt;body&gt;
}
</code></pre>
<p>A <code>while</code> loop runs the control statements in the body until <code>&lt;value&gt;</code>, which is some port on some component, becomes zero.
The <code>with &lt;group&gt;</code> bit means that we activate a given group in order to compute the condition value that determines whether the loop continues executing.</p>
<p>Let's run our memory-updating <code>seq</code> block in a while loop.
Change the control program to look like this:</p>
<pre><code>  control {
    seq {
      init;
      while lt.out with cond {
        par {
          seq {
            read;
            upd;
            write;
          }
          incr;
        }
      }
    }
  }
</code></pre>
<p>This version uses <code>while</code>, the parallel composition construct <code>par</code>, and a few new groups we will need to define.
The idea is that we'll use a counter register to make this loop run a fixed number of times, like a <code>for</code> loop.
First, we have an outer <code>seq</code> that invokes an <code>init</code> group that we will write to set the counter to zero.
The <code>while</code> loop then uses a new group <code>cond</code>, and it will run while a signal <code>lt.out</code> remains nonzero: this signal will compute <code>counter &lt; 8</code>.
The body of the loop runs our old <code>seq</code> block in parallel with a new <code>incr</code> group to increment the counter.</p>
<p>Let's add some cells to our component:</p>
<pre><code>    counter = std_reg(32);
    add2 = std_add(32);
    lt = std_lt(32);
</code></pre>
<p>We'll need a new register, an adder to do the incrementing, and a less-than comparator.</p>
<p>We can use these raw materials to build the new groups we need: <code>init</code>, <code>incr</code>, and <code>cond</code>.
First, the <code>init</code> group is pretty simple:</p>
<pre><code>    group init {
      counter.in = 32'd0;
      counter.write_en = 1'b1;
      init[done] = counter.done;
    }
</code></pre>
<p>This group just writes a zero into the counter and signals that it's done.
Next, the <code>incr</code> group adds one to the value in <code>counter</code> using <code>add2</code>:</p>
<pre><code>    group incr {
      add2.left = counter.out;
      add2.right = 32'd1;
      counter.in = add2.out;
      counter.write_en = 1'b1;
      incr[done] = counter.done;
    }
</code></pre>
<p>And finally, <code>cond</code> uses our comparator <code>lt</code> to compute the signal we need for
our <code>while</code> loop. We use a <code>comb group</code> to denote that the assignments inside
the condition can be run combinationally:</p>
<pre><code>    comb group cond {
      lt.left = counter.out;
      lt.right = 32'd8;
    }
</code></pre>
<p>By comparing with 8, we should now be running our loop body 8 times.</p>
<p>Try running this program again.
The output should be the result of adding 4 to the initial value 8 times, so 10 + 8 × 4.</p>
<blockquote>
<p>The complete program for this section is available under <a href="https://github.com/cucapra/calyx/blob/master/examples/tutorial/language-tutorial-iterate.futil">examples/tutorial/language-tutorial-iterate.futil</a>.</p>
</blockquote>
<p>Take a look at the <a href="tutorial/../lang/ref.html">full language reference</a> for details on the complete language.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multi-component-designs"><a class="header" href="#multi-component-designs">Multi-Component Designs</a></h1>
<p>Calyx designs can define and instantiate other Calyx components that themselves
encode complex <code>control</code> programs.</p>
<p>As an example, we'll build a Calyx design that uses a simple Calyx component
to save a value in a register and use it in a different component.</p>
<p>We define a new component called <code>identity</code> that has an input port <code>in</code>
and an output port <code>out</code>.</p>
<pre><code>component identity(in: 32) -&gt; (out: 32) {
  cells {
    r = std_reg(32);
  }
  wires {
    group save {
      r.in = in;
      r.write_en = 1'd1;
      save[done] = r.done;
    }

    // This component always outputs the current value in r
    out = r.out;
  }
  control {
    save;
  }
}
</code></pre>
<p>The following line defines a <em>continuous assignment</em>, i.e., an assignment
that is always kept active, regardless of the component's <code>control</code> program
being active.</p>
<pre><code>    // This component always outputs the current value in r
    out = r.out;
</code></pre>
<p>By defining this continuous assignment, we can <em>execute</em> our component and
later observe any relevant values.</p>
<p>Next, we can instantiate this component in any other Calyx component.
The following Calyx program instantiates the <code>id</code> component and uses it to
save a value and observe it.</p>
<pre><code>component main() -&gt; () {
  cells {
    // Instantiate the identity element
    id = identity();
    current_value = std_reg(32);
  }
  wires {
    group run_id {
      // We want to &quot;save&quot; the value 10 inside the identity group.
      id.in = 32'd10;
      // All components have a magic &quot;go&quot; and &quot;done&quot; port added to them.
      // Execute the component.
      id.go = 1'd1;
      run_id[done] = id.done;
    }
    group use_id {
      // We want to &quot;observe&quot; the current value saved in id.
      // The out port on the `id` component always shows the last saved
      // element. We don't need to set the `go` because we're not executing
      // and control.
      current_value.in = id.out;
      current_value.write_en = 1'd1;
      use_id[done] = current_value.done;
    }
  }
  control {
    seq { run_id; use_id; }
  }
}
</code></pre>
<p>Our first group executes the component by setting the <code>go</code> signal for the
component to high and placing the value <code>10</code> on the input port.
The second group simply saves the value on the output port. Importantly,
we don't have to set the <code>go</code> signal of the component to high because we
don't need to save a new value into it.
The component executes the two groups in-order.</p>
<p>To see the output from running this component, run the command:</p>
<pre><code>fud e examples/futil/multi-component.futil --to vcd_json
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="passing-cells-by-reference"><a class="header" href="#passing-cells-by-reference">Passing Cells by Reference</a></h1>
<p>One question that may arise when using Calyx as a backend is how to
pass a cell &quot;by reference&quot; between components. In C++, this might look like:</p>
<pre><code class="language-C++">#include &lt;array&gt;
#include &lt;cstdint&gt;

// Adds one to the first element in `v`.
void add_one(std::array&lt;uint32_t, 1&gt;&amp; v) {
  v[0] = v[0] + 1;
}

int main() {
  std::array&lt;uint32_t, 1&gt; x = { 0 };
  add_one(x); // The value at x[0] is now 1.
}
</code></pre>
<p>In Calyx, there are two steps to passing a cell by reference:</p>
<ol>
<li>Define the component in a manner such that it can accept a cell by reference.</li>
<li>Pass the desired cell by reference.</li>
</ol>
<p>When we say cell, we mean any cell, including memories of various dimensions and registers.</p>
<p>The language provides two ways of doing this.</p>
<h2 id="the-easy-way-ref-cells"><a class="header" href="#the-easy-way-ref-cells">The Easy Way: <code>ref</code> Cells</a></h2>
<p>Calyx uses the <code>ref</code> keyword to describe cells that are passed by reference:</p>
<pre><code>component add_one() -&gt; () {
  cells {
    ref mem = std_mem_d1(32, 4, 3); // A memory passed by reference.
    ...
  }
  ...
}
</code></pre>
<p>This component defines <code>mem</code> as a memory that is passed by reference to the component.
Inside the component, we can use the cell as usual.</p>
<p>Next, to pass the memory to the component, we use the <code>invoke</code> syntax:</p>
<pre><code>component add_one() -&gt; () { ... }
component main() -&gt; () {
  cells {
    A = std_mem_d1(32, 4, 3); // A memory passed by reference.
    one = add_one();
    ...
  }
  wires { ... }
  control {
    invoke one[mem = A]()(); // pass A as the `mem` for this invocation.
  }
}
</code></pre>
<p>The Calyx compiler will correctly lower the <code>add_one</code> component and the <code>invoke</code> call such that the memory is passed by reference.
In fact, any cell can be passed by reference in a Calyx program.
Read the next section if you're curious about how this process is implemented.</p>
<h3 id="multiple-memories-multiple-components"><a class="header" href="#multiple-memories-multiple-components">Multiple memories, multiple components</a></h3>
<p>To understand the power of <code>ref</code> cells, let us work through an example.
We will study a relatively simple <em>arbitration logic</em>:
the invoker has six memories of size 4 each, but needs to pretend, sometimes simulatenously, that:</p>
<ol>
<li>They are actually <em>two</em> memories of size <em>12</em> each.</li>
<li>They are actually <em>three</em> memories of size <em>8</em> each.</li>
</ol>
<p>We will do up two components that are designed to receive memories by reference:</p>
<pre><code>component wrap2(i: 32, j: 32) -&gt; () {
  cells {
    // Six memories that will be passed by reference.
    ref mem1 = std_mem_d1(32, 4, 32);
    // ...
    ref mem6 = std_mem_d1(32, 4, 32);
    // An answer cell, also passed by reference.
    ref ans = std_mem_d1(32, 1, 32);
  }
  wires { ... }
  control { ... }
}
</code></pre>
<p>and</p>
<pre><code>component wrap3(i: 32, j: 32) -&gt; () {
  cells {
    // Six memories that will be passed by reference.
    ref mem1 = std_mem_d1(32, 4, 32);
    // ...
    ref mem6 = std_mem_d1(32, 4, 32);
    // An answer cell, also passed by reference.
    ref ans = std_mem_d1(32, 1, 32);
  }
  wires { ... }
  control { ... }
}
</code></pre>
<p>That is, they have the same signature including <code>input</code> ports, <code>output</code> ports, and <code>ref</code> cells.
We have elided the logic, but feel free to explore the <a href="https://github.com/cucapra/calyx/blob/master/calyx-py/test/arbiter_6.futil">source code</a>.</p>
<p>Now the invoker has six locally defined memories.
By passing these memories to the components above, the invoker is able to wrap the same six memories two different ways, and then maintain two different fictional indexing systems at the same time.</p>
<pre><code>component main() -&gt; () {
  cells {
    // Six memories that will pass by reference.
    @external A = std_mem_d1(32, 4, 32);
    //...
    @external F = std_mem_d1(32, 4, 32);

    // Two answer cells that we will also pass.
    @external out2 = std_mem_d1(32, 1, 32);
    @external out3 = std_mem_d1(32, 1, 32);

    // Preparing to invoke the components above.
    together2 = wrap2();
    together3 = wrap3();
  }

  wires {
  }

  control {
    seq {
      invoke together2[mem1=A, mem2=B, mem3=C, mem4=D, mem5=E, mem6=F, ans=out2](i=32'd1, j=32'd11)();
      invoke together3[mem1=A, mem2=B, mem3=C, mem4=D, mem5=E, mem6=F, ans=out3](i=32'd2, j=32'd7)();
    }
  }
}
</code></pre>
<p>Observe: when &quot;wrapped&quot; into two chunks, \( 0 \le i &lt; 2 \) and \( 0 \le j &lt; 12 \); when wrapped into three chunks, \( 0 \le i &lt; 3 \) and \( 0 \le j &lt; 8 \).</p>
<h2 id="the-hard-way-without-ref-cells"><a class="header" href="#the-hard-way-without-ref-cells">The Hard Way: Without <code>ref</code> Cells</a></h2>
<blockquote>
<p>Proceed with caution. We recommend using the <code>ref</code> syntax in almost all cases since it enables the compiler to perform more optimizations.</p>
</blockquote>
<p>If we wish not to use <code>ref</code> cells, we can leverage the usual <code>input</code> and <code>output</code> ports to establish a call-by-reference-esque relationship between the calling and called components.
In fact, the Calyx compiler takes <code>ref</code> cells as descibed above and lowers them into code of the style described here.</p>
<p>Let us walk through an example.</p>
<h3 id="worked-example-mem_cpy"><a class="header" href="#worked-example-mem_cpy">Worked example: <code>mem_cpy</code></a></h3>
<p>In the C++ code above, we've constructed an &quot;l-value reference&quot; to the array,
which essentially means we can both read and write from <code>x</code> in the function
<code>add_one</code>.</p>
<p>Now, let's allow similar functionality at the Calyx IR level.
We define a new component named <code>add_one</code> which represents the function
above. However, we also need to include the correct ports to both read
and write to <code>x</code>:</p>
<div class="table-wrapper"><table><thead><tr><th>Read from <code>x</code></th><th>Write to <code>x</code></th></tr></thead><tbody>
<tr><td>read_data</td><td>done</td></tr>
<tr><td>address ports</td><td>write_data</td></tr>
<tr><td></td><td>write_en</td></tr>
<tr><td></td><td>address ports</td></tr>
</tbody></table>
</div>
<p>Since we're both reading and writing from <code>x</code>, we'll
include the union of the columns above:</p>
<pre><code>component add_one(x_done: 1, x_read_data: 32) -&gt;
                 (x_write_data: 32, x_write_en: 1, x_addr0: 1) {
</code></pre>
<p>One tricky thing to note is where the ports belong, i.e. should it be
an input port or an output port of the component? The way to reason about this
is to ask whether we want to receive signal from or send signal to the given wire. For example,
with <code>read_data</code>, we will always be receiving signal from it, so it should be an input port.
Conversely, address ports are used to mark where in memory we want to access,
so those are used as output ports.</p>
<p>We then simply use the given ports to both read and write to the memory passed
by reference. Note that we've split up the read and write to memory <code>x</code> in separate groups,
to ensure we can schedule them sequentially in the execution flow.
We're also using the exposed ports of the memory through the component interface rather than,
say, <code>x.write_data</code>.</p>
<pre><code>    group read_from_x {
      x_addr0 = 1'd0;            // Set address port to zero.
      tmp_reg.in = x_read_data;  // Read the value at address zero.
      tmp_reg.write_en = 1'd1;
      read_from_x[done] = tmp_reg.done;
    }
    group write_to_x {
      x_addr0 = 1'd0;            // Set address port to zero.
      add.left = one.out;
      add.right = tmp_reg.out;   // Saved value from previous read.

      x_write_data = add.out;    // Write value to address zero.
      x_write_en = 1'd1;         // Set write enable signal to high.

      write_to_x[done] = x_done; // The group is done when the write is complete.
    }
</code></pre>
<p>Bringing everything back together, the <code>add_one</code> component is written accordingly:</p>
<pre><code>component add_one(x_done: 1, x_read_data: 32) -&gt;
                 (x_write_data: 32, x_write_en: 1, x_addr0: 1) {
  cells {
    one = std_const(32, 1);
    add = std_add(32);
    tmp_reg = std_reg(32);
  }
  wires {
    group read_from_x {
      x_addr0 = 1'd0;            // Set address port to zero.
      tmp_reg.in = x_read_data;  // Read the value at address zero.
      tmp_reg.write_en = 1'd1;
      read_from_x[done] = tmp_reg.done;
    }
    group write_to_x {
      x_addr0 = 1'd0;            // Set address port to zero.
      add.left = one.out;
      add.right = tmp_reg.out;   // Saved value from previous read.

      x_write_data = add.out;    // Write value to address zero.
      x_write_en = 1'd1;         // Set write enable signal to high.

      write_to_x[done] = x_done; // The group is done when the write is complete.
    }
  }
  control {
    seq { read_from_x; write_to_x; }
  }
}
</code></pre>
<p>The final step is creating a <code>main</code> component from which the original component
will be invoked. In this step, it is important to hook up the proper wires in the
call to <code>invoke</code> to the corresponding memory you'd like to read and/or write to:</p>
<pre><code>  control {
    invoke add_one0(x_done = x.done, x_read_data = x.read_data)
                   (x_write_data = x.write_data, x_write_en = x.write_en, x_addr0 = x.addr0);
  }
</code></pre>
<p>This gives us the <code>main</code> component:</p>
<pre><code>component main() -&gt; () {
  cells {
    add_one0 = add_one();
    @external(1) x = std_mem_d1(32, 1, 1);
  }
  wires {
  }
  control {
    invoke add_one0(x_done = x.done, x_read_data = x.read_data)
                   (x_write_data = x.write_data, x_write_en = x.write_en, x_addr0 = x.addr0);
  }
}
</code></pre>
<p>To see this example simulated, run the command:</p>
<pre><code>fud e examples/futil/memory-by-reference/memory-by-reference.futil --to dat \
-s verilog.data examples/futil/memory-by-reference/memory-by-reference.futil.data
</code></pre>
<h3 id="multi-dimensional-memories"><a class="header" href="#multi-dimensional-memories">Multi-dimensional Memories</a></h3>
<p>Not much changes for multi-dimensional arrays. The only additional step is adding
the corresponding address ports. For example, a 2-dimensional memory will require address ports
<code>addr0</code> and <code>addr1</code>. More generally, an <code>N</code>-dimensional memory will require address ports
<code>addr0</code>, ..., <code>addr(N-1)</code>.</p>
<h3 id="multiple-memories"><a class="header" href="#multiple-memories">Multiple Memories</a></h3>
<p>Similarly, multiple memories will just require the ports to be passed for each of the given memories.
Here is an example of a memory copy (referred to as <code>mem_cpy</code> in the C language), with 1-dimensional memories of size 5:</p>
<pre><code>import &quot;primitives/core.futil&quot;;
component copy(dest_done: 1, src_read_data: 32, length: 3) -&gt;
              (dest_write_data: 32, dest_write_en: 1, dest_addr0: 3, src_addr0: 3) {
  cells {
    lt = std_lt(3);
    N = std_reg(3);
    add = std_add(3);
  }
  wires {
    comb group cond {
      lt.left = N.out;
      lt.right = length;
    }
    group upd_index&lt;&quot;static&quot;=1&gt; {
      add.left = N.out;
      add.right = 3'd1;
      N.in = add.out;
      N.write_en = 1'd1;
      upd_index[done] = N.done;
    }
    group copy_index_N&lt;&quot;static&quot;=1&gt; {
      src_addr0 = N.out;
      dest_addr0 = N.out;
      dest_write_en = 1'd1;
      dest_write_data = src_read_data;
      copy_index_N[done] = dest_done;
    }
  }
  control {
    while lt.out with cond {
      seq {
        copy_index_N;
        upd_index;
      }
    }
  }
}

component main() -&gt; () {
  cells {
    @external(1) d = std_mem_d1(32,5,3);
    @external(1) s = std_mem_d1(32,5,3);
    length = std_const(3, 5);
    copy0 = copy();
  }
  wires {
  }
  control {
    seq {
      invoke copy0(dest_done=d.done, src_read_data=s.read_data, length=length.out)
                  (dest_write_data=d.write_data, dest_write_en=d.write_en, dest_addr0=d.addr0, src_addr0=s.addr0);
    }
  }
}
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="calyx-language-reference"><a class="header" href="#calyx-language-reference">Calyx Language Reference</a></h1>
<h2 id="top-level-constructs"><a class="header" href="#top-level-constructs">Top-Level Constructs</a></h2>
<p>Calyx programs are a sequence of <code>import</code> statements followed by a sequence of
<code>extern</code> statements or <code>component</code> definitions.</p>
<h3 id="import-statements"><a class="header" href="#import-statements"><code>import</code> statements</a></h3>
<p><code>import &quot;&lt;path&gt;&quot;</code> has almost exactly the same semantics to that of <code>#include</code> in
the C preprocessor: it copies the code from the file at <code>path</code> into
the current file.</p>
<h3 id="extern-definitions"><a class="header" href="#extern-definitions"><code>extern</code> definitions</a></h3>
<p><code>extern</code> definitions allow Calyx programs to link against arbitrary RTL code.
An <code>extern</code> definition looks like this:</p>
<pre><code>extern &quot;&lt;path&gt;&quot; {
  &lt;primitives&gt;...
}
</code></pre>
<p><code>&lt;path&gt;</code> should be a valid file system path that points to a Verilog module that
defines the same names as the <em>primitives</em> defined in the <code>extern</code> block.
When run with the <code>-b verilog</code> flag, the Calyx compiler will copy the contents
of every such Verilog file into the generated output.</p>
<h3 id="primitive-definitions"><a class="header" href="#primitive-definitions"><code>primitive</code> definitions</a></h3>
<p>The <code>primitive</code> construct allows specification of the signature of an external
Verilog module that the Calyx program uses.
It has the following syntax:</p>
<pre><code>[comb] primitive name&lt;attributes&gt;[PARAMETERS](ports) -&gt; (ports);
</code></pre>
<p>The syntax for primitives resembles that for <a href="lang/ref.html#calyx-components">components</a>,
with some additional pieces:</p>
<ul>
<li>The <code>comb</code> keyword signals that the primitive definition wraps purely
combinational RTL code. This is useful for certain optimizations.</li>
<li><em><a href="lang/./attributes.html">Attributes</a></em> specify useful metadata for optimization.</li>
<li><em>PARAMETERS</em> are named compile-time (metaprogramming) parameters to pass to
the Verilog module definition. The primitive definition lists the names of
integer-valued parameters; the corresponding Verilog module definition should
have identical <code>parameter</code> declarations. Calyx code provides values for these
parameters when instantiating a primitive as a <a href="lang/ref.html#cells">cell</a>.</li>
<li>The <em>ports</em> section contain sized port definitions that can either be positive number
or one of the parameter names.</li>
</ul>
<p>For example, the following is the signature of the <code>std_reg</code> primitive from the
Calyx standard library:</p>
<pre><code>primitive std_reg&lt;&quot;state_share&quot;=1&gt;[WIDTH](
  @write_together(1) @data in: WIDTH,
  @write_together(1) @static(1) @go write_en: 1,
  @clk clk: 1,
  @reset reset: 1
) -&gt; (
  @stable out: WIDTH,
  @done done: 1
)
</code></pre>
<p>The primitive defines one parameter called <code>WIDTH</code>, which describes the sizes for
the <code>in</code> and the <code>out</code> ports.</p>
<h3 id="inlined-primitives"><a class="header" href="#inlined-primitives">Inlined Primitives</a></h3>
<p><em>Inlined primitives</em> do not have a corresponding Verilog file, and are defined within Calyx. The Calyx backend then converts these definitions into Verilog.</p>
<p>For example, the <code>std_unsyn_mult</code> primitive is inlined:</p>
<pre><code>comb primitive std_unsyn_mult&lt;&quot;share&quot;=1&gt;[WIDTH](left: WIDTH, right: WIDTH) -&gt; (out: WIDTH) {
  assign out = left * right;
};
</code></pre>
<p>This can be useful when a frontend needs to generate both Calyx and Verilog code at the same time. The backend ensures that the generated Verilog module has the correct signature.</p>
<h2 id="calyx-components"><a class="header" href="#calyx-components">Calyx Components</a></h2>
<p>Components are the primary encapsulation unit of a Calyx program.
They look like this:</p>
<pre><code>component name&lt;attributes&gt;(ports) -&gt; (ports) {
  cells { ... }
  wires { ... }
  control { ... }
}
</code></pre>
<p>Like <a href="lang/ref.html#primitive-definitions"><code>primitive</code> definitions</a>, <code>component</code> signatures consist of a name, an optional list of attributes, and input/output ports.
Unlike <code>primitive</code>s, <code>component</code> definitions do not have parameters; ports must have a concrete (integer) width.
A component encapsulates the control and the hardware structure that implements
a hardware module.</p>
<blockquote>
<p><strong>Well-formedness</strong>: The <code>control</code> program of a component must take at least one cycle to finish executing.</p>
</blockquote>
<h3 id="combinational-components"><a class="header" href="#combinational-components">Combinational Components</a></h3>
<p>Using the <code>comb</code> keyword before a component definition marks it as a purely combinational component:</p>
<pre><code>comb component add(left: 32, right: 32) -&gt; (out: 32) {
  cells {
    a = std_add(32);
  }
  wires {
    a.left = left;
    a.right = right;
    out = a.out;
  }
}
</code></pre>
<p>A combinational component does not have a <code>control</code> section, can only use other <code>comb</code> components or primitives, and performs its computation combinationally.</p>
<h3 id="ports"><a class="header" href="#ports">Ports</a></h3>
<p>A port definition looks like this:</p>
<pre><code>[@&lt;attr&gt;...] &lt;name&gt;: &lt;width&gt;
</code></pre>
<p>Ports have a bit width but are otherwise untyped.
They can also include optional <a href="lang/./attributes.html">attributes</a>.
For example, this component definition:</p>
<pre><code>component counter(left: 32, right: 32) -&gt; (@stable out0: 32, out1: 32) { .. }
</code></pre>
<p>defines two input ports, <code>left</code> and <code>right</code>, and two output ports,
<code>out0</code> and <code>out1</code>.
All four ports are 32-bit signals.
Additionally, the <code>out0</code> port has the <a href="lang/./attributes.html">attribute</a> <code>@stable</code>.</p>
<h3 id="cells"><a class="header" href="#cells"><code>cells</code></a></h3>
<p>A component's <code>cells</code> section instantiates a set of sub-components.
It contains a list of declarations with this syntax:</p>
<pre><code>[ref]? &lt;name&gt; = &lt;comp&gt;(&lt;param...&gt;);
</code></pre>
<p>Here, <code>&lt;comp&gt;</code> is the name of an existing <a href="lang/ref.html#primitive-definitions">primitive</a> or <a href="lang/ref.html#calyx-components">component definition</a>, and
<code>&lt;name&gt;</code> is the fresh, local name of the instance.
The optional <code>ref</code> parameter turns the cell into a <a href="lang/ref.html#ref-cells">by-reference cell</a>.
Parameters are only allowed when instantiating primitives, not Calyx-defined components.</p>
<p>For example, the following definition of the <code>counter</code> component instantiates a
<code>std_add</code> and <code>std_reg</code> primitive as well as a <code>foo</code> Calyx component</p>
<pre><code>component foo() -&gt; () { ... }
component counter() -&gt; () {
  cells {
    r = std_reg(32);
    a = std_add(32);
    f = foo();
  }
  wires { ... }
  control { ... }
}
</code></pre>
<p>When instantiating a <a href="lang/ref.html#primitive-definitions"><code>primitive</code> definition</a>, the parameters are passed within the
parenthesis.
For example, we pass <code>32</code> for the <code>WIDTH</code> parameter of the <code>std_reg</code> in the above
instantiation.
Since an instantiation of a Calyx component does not take any parameters, the parameters
are always empty.</p>
<h2 id="the-wires-section"><a class="header" href="#the-wires-section">The <code>wires</code> Section</a></h2>
<p>A component's <code>wires</code> section contains <em>guarded assignments</em> that connect ports
together. The assignments can either appear at the top level, making them
<em><a href="lang/ref.html#continuous-assignments">continuous assignments</a></em>, or be organized into named
<a href="lang/ref.html#group-definitions"><code>group</code></a> and <a href="lang/ref.html#comb-group-definitions"><code>comb group</code> definitions</a>.</p>
<h3 id="guarded-assignments"><a class="header" href="#guarded-assignments">Guarded Assignments</a></h3>
<p>Assignments connect ports between two cells together, with this syntax:</p>
<pre><code>&lt;cell&gt;.&lt;port&gt; = [&lt;guard&gt; ?] &lt;cell&gt;.&lt;port&gt;;
</code></pre>
<p>The left-hand and right-hand side are both <em>port references</em>, which name a
specific input or output port within a <a href="lang/ref.html#cells">cell</a> declared within the same
component. The optional <em>guard condition</em> is a logical expression that
determines whether the connection is active.</p>
<p>For example, this assignment:</p>
<pre><code>r.in = add.out;
</code></pre>
<p>unconditionally transfers the value from a port named <code>out</code> in the <code>add</code> cell to <code>r</code>'s <code>in</code> port.</p>
<p>Assignments are <em>simultaneous</em> and <em>non-blocking</em>. When a block of assignments
runs, they all first read their right-hand sides and then write into their
left-hand sides; they are not processed in order. The result is that the order
of assignments does not matter. For example, this block of assignments:</p>
<pre><code>r.in = add.out;
add.left = y.out;
add.right = z.out;
</code></pre>
<p>is a valid way to take the values from registers <code>y</code> and <code>z</code> and put the sum into <code>r</code>. Any permutation of these assignments is equivalent.</p>
<h3 id="guards"><a class="header" href="#guards">Guards</a></h3>
<p>An assignment's optional <em>guard</em> expression is a logical expression that produces a 1-bit value, as in these examples:</p>
<pre><code>r.in = cond.out ? add.out;
r.in = !cond.out ? 32'd0;
</code></pre>
<p>Using guards, Calyx programs can assign multiple different values to the same
port. Omitting a guard expression is equivalent to using <code>1'd1</code> (a constant
&quot;true&quot;) as the guard.</p>
<p>Guards can use the following constructs:</p>
<ul>
<li><code>port</code>: A port access on a defined cell</li>
<li><code>port op port</code>: A comparison between values on two ports. Valid <code>op</code> are: <code>&gt;</code>, <code>&lt;</code>, <code>&gt;=</code>, <code>&lt;=</code>, <code>==</code></li>
<li><code>!guard</code>: Logical negation of a guard value</li>
<li><code>guard || guard</code>: Disjunction between two guards</li>
<li><code>guard &amp;&amp; guard</code>: Conjunction of two guards</li>
</ul>
<blockquote>
<p><strong>Well-formedness</strong>: For each input port on the LHS, only one guard should be active in any given cycle during the execution of a Calyx program.</p>
</blockquote>
<h3 id="continuous-assignments"><a class="header" href="#continuous-assignments">Continuous Assignments</a></h3>
<p>When an assignment appears directly inside a component's <code>wires</code> section, it
is called a <em>continuous assignment</em> and is permanently active, even when the
<a href="lang/ref.html#the-control-operators">control program</a> of the component is inactive.</p>
<h3 id="group-definitions"><a class="header" href="#group-definitions"><code>group</code> definitions</a></h3>
<p>A <code>group</code> is a way to name a set of assignments that together represent some
meaningful action:</p>
<pre><code>group name&lt;attributes&gt; {
  assignments...
  name[done] = done_cond;
}
</code></pre>
<p>Assignments within a group can be reasoned about in isolation from assignments
in other groups.
Unlike <a href="lang/ref.html#continuous-assignments">continuous assignments</a>, a group's encapsulated assignments
only execute as dictated by the <a href="lang/ref.html#the-control-operators">control program</a>.
This means that seemingly conflicting writes to the same ports are allowed:</p>
<pre><code>group foo {
  r.in = 32'd10;
  foo[done] = ...;
}
group bar {
  r.in = 32'd22;
  bar[done] = ...;
}
</code></pre>
<p>However, group assignments must not conflict with <a href="lang/ref.html#continuous-assignments">continuous assignments</a> defined in the component:</p>
<pre><code>group foo {
  r.in = 32'd10; ... // Malformed because it conflicts with the write below.
  foo[done] = ...
}
r.in = 32'd50;
</code></pre>
<p>Groups can take any (nonzero) number of cycles to complete. To indicate to the
outside world when their execution has completed, every group has a special
<em>done signal</em>, which is a special port written as <code>&lt;group&gt;[done]</code>. The group
should assign 1 to this port to indicate that its execution is complete.</p>
<p>Groups can have an optional list of <a href="lang/./attributes.html">attributes</a>.</p>
<blockquote>
<p><strong>Well-formedness</strong>: All groups are required to run for at least one cycle. (Sub-cycle logic should use <code>comb group</code> instead.)</p>
</blockquote>
<h3 id="comb-group-definitions"><a class="header" href="#comb-group-definitions"><code>comb group</code> definitions</a></h3>
<p>Combinational groups are a restricted version of groups which perform their
computation purely combinationally and therefore run for &quot;less than one cycle&quot;:</p>
<pre><code>comb group name&lt;attributes&gt; {
  assignments...
}
</code></pre>
<p>Because their computation is required to run for less than a cycle, <code>comb group</code>
definitions do not specify a <code>done</code> condition.</p>
<p>Combinational groups cannot be used within normal <a href="lang/ref.html#the-control-operators">control
operators</a>.
Instead, they only occur after the <code>with</code> keyword in a control program.</p>
<h2 id="the-control-operators"><a class="header" href="#the-control-operators">The Control Operators</a></h2>
<p>The <code>control</code> section of a component contains an imperative program that
describes the component's behavior. The statements in the control program
consist of the following operators:</p>
<h3 id="group-enable"><a class="header" href="#group-enable">Group Enable</a></h3>
<p>Simply naming a group in a control statement, called a group enable, executes
the group to completion.
This is a leaf node in the control program.</p>
<h3 id="invoke"><a class="header" href="#invoke"><code>invoke</code></a></h3>
<p><code>invoke</code> acts like the function call operator for Calyx and has the following
syntax:</p>
<pre><code>invoke instance[ref cells](inputs)(outputs) [with comb_group];
</code></pre>
<ul>
<li><code>instance</code> is the name of the cell instance that needs to be invoked.</li>
<li><code>inputs</code> and <code>outputs</code> define connections for a subset of input and output
ports of the instance.</li>
<li>The <code>with comb_group</code> section is optional and names a <a href="lang/ref.html#comb-group-definitions">combinational
group</a> that is active during the execution of the <code>invoke</code>
statement.</li>
<li><code>ref cells</code> is a list of cell names to pass to the invoked component's
required <a href="lang/ref.html#ref-cells"><em>cell reference</em></a>. (It can be omitted if the invoked component
contains no cell references.)</li>
</ul>
<p>Invoking an instance runs its control program to completion before returning.
Any Calyx component or primitive that implements the <a href="lang/ref.html#the-go-done-interface">go-done interface</a> can be invoked.
Like the <a href="lang/ref.html#group-enable">group enable</a> statement, <code>invoke</code> is a leaf node in the control program.</p>
<h3 id="seq"><a class="header" href="#seq"><code>seq</code></a></h3>
<p>The syntax for sequential composition is:</p>
<pre><code>seq { c1; ...; cn; }
</code></pre>
<p>where each <code>ci</code> is a nested control statement.
Sequences run the control programs <code>c1</code>...<code>cn</code> in sequence, guaranteeing that
each program runs fully before the next one starts executing.
<code>seq</code> <strong>does not</strong> provide any cycle-level guarantees on when a succeeding
group starts executing after the previous one finishes.</p>
<h3 id="par"><a class="header" href="#par"><code>par</code></a></h3>
<p>The syntax for parallel composition is:</p>
<pre><code>par { c1; ...; cn; }
</code></pre>
<p>The statement runs the nested control programs <code>c1</code>...<code>cn</code> in parallel, guaranteeing that
each program only runs once.
<code>par</code> <strong>does not</strong> provide any guarantees on how the execution of child programs
is scheduled.
It is therefore not safe to assume that all children begin execution at the
same time.</p>
<blockquote>
<p><strong>Well-formedness</strong>: The assignments in the children <code>c1</code>...<code>cn</code> should never conflict with each other.</p>
</blockquote>
<h3 id="if"><a class="header" href="#if"><code>if</code></a></h3>
<p>The syntax is:</p>
<pre><code>if &lt;port&gt; [with comb_group] {
  true_c
} else {
  false_c
}
</code></pre>
<p>The conditional execution runs either <code>true_c</code> or <code>false_c</code> using the value of
<code>&lt;port&gt;</code>.
The optional <code>with comb_group</code> syntax allows running a <a href="lang/ref.html#comb-group-definitions">combinational group</a>
that computes the value of the port.</p>
<blockquote>
<p><strong>Well-formedness</strong>: The combinational group is considered to be running during the entire execution
of the control program and therefore should not have conflicting assignments
with either <code>true_c</code> or <code>false_c</code>.</p>
</blockquote>
<h3 id="while"><a class="header" href="#while"><code>while</code></a></h3>
<p>The syntax is:</p>
<pre><code>while &lt;port&gt; [with comb_group] {
  body_c
}
</code></pre>
<p>Repeatedly executes <code>body_c</code> while the value on <code>port</code> is non-zero.
The optional <code>with comb_group</code> enables a <a href="lang/ref.html#comb-group-definitions">combinational group</a> that computes the
value of <code>port</code>.</p>
<blockquote>
<p><strong>Well-formedness</strong>: The combinational group is considered active during the execution of the while
loop and therefore should not have conflicting assignments with <code>body_c</code>.</p>
</blockquote>
<h3 id="repeat"><a class="header" href="#repeat"><code>repeat</code></a></h3>
<p>The syntax is:</p>
<pre><code>repeat &lt;num_repeats&gt; {
  body_c
}
</code></pre>
<p>Repeatedly executes the control program <code>body_c</code> <code>num_repeat</code> times in a row. </p>
<h2 id="the-go-done-interface"><a class="header" href="#the-go-done-interface">The <code>go</code>-<code>done</code> Interface</a></h2>
<p>By default, Calyx components implement a one-sided ready-valid interface called
<em>the <code>go</code>-<code>done</code> interface</em>.
During compilation, the Calyx compiler will add an input port marked with the attribute <a href="lang/./attributes.html#go-done-clk-and-reset"><code>@go</code></a> and an output port marked with the attribute <a href="lang/./attributes.html#go-done-clk-and-reset"><code>@done</code></a> to the interface of the component:</p>
<pre><code>component counter(left: 32, right: 32, @go go: 1) -&gt; (out: 32, @done done: 1)
</code></pre>
<p>The interface provides a way to trigger the control program of the counter using
assignments.
When the <code>go</code> signal of the component is set to 1, the control program starts
executing.
When the component sets the <code>done</code> signal to 1, its control program has finished
executing.</p>
<blockquote>
<p><strong>Well-formedness</strong>: The <code>go</code> signal to the component must remain set to 1 while the done signal is not 1. Lowering the <code>go</code> signal before the <code>done</code> signal is set to 1 will lead to undefined behavior.</p>
</blockquote>
<h2 id="the-clk-and-reset-ports"><a class="header" href="#the-clk-and-reset-ports">The <code>clk</code> and <code>reset</code> Ports</a></h2>
<p>The compiler also adds special input ports marked with <a href="lang/./attributes.html#go-done-clk-and-reset"><code>@clk</code> and <code>@reset</code></a> to the
interface.
By default, Calyx components are not allowed to look at or use these signals.
They are automatically threaded to any primitive that defines <code>@clk</code> or
<code>@reset</code> ports.</p>
<h2 id="advanced-concepts"><a class="header" href="#advanced-concepts">Advanced Concepts</a></h2>
<h3 id="ref-cells"><a class="header" href="#ref-cells"><code>ref</code> cells</a></h3>
<p>Calyx components can specify that a cell needs to be passed &quot;by reference&quot;:</p>
<pre><code>// Component that performs mem[0] += 1;
component update_memory() -&gt; () {
  cells {
    ref mem = std_mem_d1(...)
  }
  wires { ... }
  control { ... }
}
</code></pre>
<p>When invoking such a component, the calling component must provide a binding for each defined cell:</p>
<pre><code>component main() -&gt; () {
  cells {
    upd = update_memory();
    m1 = std_mem_d1(...);
    m2 = std_mem_d2(...);
  }
  wires { ... }
  control {
    seq {
      invoke upd[mem=m1]()(); // Pass `m1` by reference
      invoke upd[mem=m2]()(); // Pass `m2` by reference
    }
  }
}
</code></pre>
<p>As the example shows, each invocation can take different bindings for each <code>ref</code> cell.
See <a href="lang/./memories-by-reference.html">the tutorial</a> for longer example on how to use this feature.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-format"><a class="header" href="#data-format">Data Format</a></h1>
<p>Calyx's <a href="lang/../fud/index.html"><code>fud</code></a>-based workflows specifies a JSON-based data format which can be used with software simulators.</p>
<h2 id="external-memories"><a class="header" href="#external-memories">External memories</a></h2>
<p>First, a Calyx program must mark memories using the <a href="lang/attributes.html#external"><code>@external</code> attribute</a> to tell the compiler that the memory is used as either an input or an ouput.</p>
<pre><code>component main() {
    cells {
        @external ext = std_mem_d1(...);
        internal = std_mem_d1(...);
    }
}
</code></pre>
<p>In the above program, the memory <code>ext</code> will be assumed to be an input-output memory by the compiler while <code>internal</code> is considered to be an internal memory.
For all external memories, the compiler will generate code to read initial values and dump out final values.
The external attribute is recognized for all the <code>std_mem</code> and <code>seq_mem</code> primitives.
The <code>@external</code> attribute can <strong>only be used</strong> on the <a href="lang/attributes.html#toplevel">top-level component</a>.</p>
<blockquote>
<p>When the <code>--synthesis</code> flag is passed to the compiler, this behavior is disabled and instead the memories are turned into ports on the top-level component.</p>
</blockquote>
<h2 id="the-data-format"><a class="header" href="#the-data-format">The Data Format</a></h2>
<p>The JSON-based data format allows us to provide inputs for a memory and specify how the values should be interpreted:</p>
<pre><code class="language-json">{
  &quot;mem&quot;: {
    &quot;data&quot;: [10],
    &quot;format&quot;: {
      &quot;numeric_type&quot;: &quot;bitnum&quot;,
      &quot;is_signed&quot;: false,
      &quot;width&quot;: 32
    }
  }
}
</code></pre>
<p>The <code>data</code> field represents the initial data for the memory and can use mutlidimensional arrays to describe it. For example, the following is the initial data for a two-dimensional (<code>std_mem_d2</code>) memory:</p>
<pre><code class="language-json">{
    &quot;data&quot;: [ [1, 2], [3, 4] ],
    &quot;format&quot;: {...}
}
</code></pre>
<p>The <code>format</code> specifier tells <code>fud</code> how to interpret the values in the data field. The original program specifies that all values should be treated as 32-bit, unsigned values.</p>
<p>In order to specify fixed-point values, we must specify both the total width and fraction widths:</p>
<pre><code class="language-json">&quot;root&quot;: {
  &quot;data&quot;: [
      0.0
  ],
  &quot;format&quot;: {
      &quot;numeric_type&quot;: &quot;fixed_point&quot;,
      &quot;is_signed&quot;: false,
      &quot;width&quot;: 32,
      &quot;frac_width&quot;: 16
  }
}
</code></pre>
<p>The format states that all values have a fractional width of 16-bits while the remainder is used for the integral part.</p>
<blockquote>
<p><strong>Note:</strong> <code>fud</code> requires that for each memory marked with the <code>@external</code> attribute in the program.</p>
</blockquote>
<h2 id="using-fud"><a class="header" href="#using-fud">Using <code>fud</code></a></h2>
<p>All software simulators supported by <code>fud</code>, including <a href="lang/../fud/index.html#verilator">Verilator</a> and <a href="lang/../fud/index.html#icarus-verilog">Icarus Verilog</a>, as well as the <a href="lang/../interpreter.html">Calyx interpreter</a> can use this data format.
To pass a JSON file with initial values, use the <code>-s verilog.data</code> flag:</p>
<pre><code class="language-bash"># Use Icarus Verilog
fud e --to dat --through icarus-verilog &lt;CALYX FILE&gt; -s verilog.data &lt;JSON&gt;
# Use Verilator
fud e --to dat --through verilog &lt;CALYX FILE&gt; -s verilog.data &lt;JSON&gt;
# Use the Calyx Interpreter
fud e --to interpreter-out &lt;CALYX FILE&gt; -s verilog.data &lt;JSON&gt;
</code></pre>
<h2 id="generating-random-values"><a class="header" href="#generating-random-values">Generating Random Values</a></h2>
<p>Often times, it can be useful to automatically generate random values for a large memory. The <a href="lang/../tools/data-gen.html">data-gen</a> tool takes a Calyx program as an input and automatically generates random values for each memory marked with <code>@external</code> in the above data format.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="static-timing"><a class="header" href="#static-timing">Static Timing</a></h1>
<p>By default, Calyx programs use a <em>latency-insensitive</em> model of computation.
This means that the compiler does not track the number of cycles it takes to perform a computation or run a control operator
In general, latency-insensitivity makes it easier to compose programs together and gives the compiler freedom to schedule operators however it wants.
However, the generated hardware to schedule the execution may not be efficient–especially if the program can take advantage of the <em>latency</em> information.</p>
<p>More crucially, however, it is impossible for <em>latency-insensitive</em> programs to interact with <em>latency-sensitive</em> hardware implemented in RTL.</p>
<p>Calyx uses the <code>@static</code> attribute to provide latency information to various constructs and provides strong guarantees about the generated programs.</p>
<h2 id="guarantees"><a class="header" href="#guarantees">Guarantees</a></h2>
<h2 id="tricks--tips"><a class="header" href="#tricks--tips">Tricks &amp; Tips</a></h2>
<h3 id="delay-by-n-cycles"><a class="header" href="#delay-by-n-cycles">Delay by <code>n</code> cycles</a></h3>
<p>Sometimes it can be useful to delay the execution of a group by <code>n</code> cycles:</p>
<pre><code>seq {
  @static(1) a; // Run in first cycle
  ???
  @static(2) b; // Run in the 10th cycle
}
</code></pre>
<p>A simple trick to achieve this is adding an empty group with <code>@static(n)</code> attribute on it:</p>
<pre><code>cell {
  r = @std_reg(0);
}
@static(9) group delay_9 {
  delay_9[done] = r.out; // Don't use r.done here
}
seq {
    @static(1) a; // Run in first cycle
    @static(9) delay_9;
    @static(2) b; // Run in the 10th cycle
}
</code></pre>
<p>The static compilation pass <code>tdst</code> will never attempt to use the <code>delay_9</code>'s <code>done</code> condition and since there are no assignments in the group, it'll not generate any additional hardware.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="experimental-synchronization"><a class="header" href="#experimental-synchronization">Experimental: Synchronization</a></h1>
<p>Calyx's default semantics <a href="lang/./undefined.html#semantics-of-par">do not admit</a> any predictable form of language-level
synchronization in presence of parallelism.
We're currently experimenting with a suite of new primitives that add synchronization to the
language.</p>
<h2 id="sync-attribute"><a class="header" href="#sync-attribute"><code>@sync</code> attribute</a></h2>
<h2 id="motivation"><a class="header" href="#motivation">Motivation</a></h2>
<p>Consider the following control program in calyx:</p>
<pre><code>    par {
      /// thread A
      while lt.out with comp {
        seq {
          incr_idx;
          add_r_to_accm;
        }
      }

      /// thread B
      while lt.out with comp {
        seq {
          incr_r;
        }
      }
    }
</code></pre>
<p>where groups <code>add_r_to_accm</code> and <code>incr_r</code> reads value and increments value in register <code>r</code>, respectively, as indicated by their names. </p>
<p>Because calyx does not make any guarantee of the order of execution for threads running in parallel, it is impossible for us to determine which thread will access r first for each iteration.</p>
<p>Nondeterminism when running parallel threads is beneficial on the compiler's end, as it will give the compiler more freedom for optimization. However, we sometimes do want to give parallel threads a measure of ordering while still taking advantage of the performance boost of parallelism. The <code>@sync</code> attribute allows us to do that. </p>
<h2 id="using-the-sync-attribute"><a class="header" href="#using-the-sync-attribute">Using the <code>@sync</code> attribute</a></h2>
<p>Now we want to modify the program above so that in every iteration, thread A always reads after thread B finishes incrementing using the <code>@sync</code> attribute with the following:</p>
<pre><code>    par {
      // thread A
      while lt.out with comp {
        seq {
          incr_idx;
          @sync(1);
          add_r_to_accm;
          @sync(2);
        }
      }

      // thread B
      while lt.out with comp {
        seq {
          incr_r;
          @sync(1);
          @sync(2);
        }
      }
    }
</code></pre>
<p>First and foremost, always remember to import &quot;primitives/sync.futil&quot; when using the @sync attribute.</p>
<p>The <code>@sync</code> syntax can only be marked with empty statements. <code>@sync</code> means that the thread
marked with a certain value, now called barrier index, for this attribute, must stop and wait for all other threads marked with the same barrier index to arrive, at which point they can proceed. </p>
<p>In the modified program above, we see that <code>incr_idx</code> and <code>incr_r</code> must both finish in order for either thread to go forth. Because <code>add_r_to_accm</code> is executed after <code>incr_idx</code> in thread A, we know that in each iteration, <code>incr_r</code> will always increment <code>r</code> before <code>add_r_to_accm</code> reads it. We've also inserted another barrier at the end of the while loops for each thread, which essentially means <code>add_r_to_accm</code> has to finish before either thread enters the next iteration.</p>
<h2 id="synchronization-in-branches"><a class="header" href="#synchronization-in-branches">Synchronization in Branches</a></h2>
<p>We can also have &quot;barriers&quot; in <code>if</code> branches:</p>
<pre><code>    par {
      // thread 1
      while lt.out with comp {
        if eq.out with st_0 {
          seq {
            prod_0;
            @sync(1);
            switch_to_st_1;
            @sync(2);
          }
        }
        else {
          seq {
            prod_1;
            @sync(1);
            switch_to_st_0;
            @sync(2);
          }
        }
      }

      // thread 2
      while lt.out with comp {
        seq {
          @sync(1);
          reg_to_mem;
          incr_idx;
          @sync(2);
        }
      }
    }
  }
</code></pre>
<p>In this control program, both branches of thread 1 have statements marked with <code>@sync(1)</code>, 
which syncs it up with thread 2.</p>
<p>Be really really careful when using the <code>@sync</code> attribute in conditional branches!
If the other thread sharing one &quot;barrier&quot; with your thread is blocked unconditionally, 
then you would probably want to have the same <code>@sync</code> value in both branches; since
having the same <code>@sync</code> value in only one branch would likely lead to a &quot;deadlock&quot; 
situation: if thread A is running in the unlocked branch while the thread B 
has a &quot;barrier&quot; that is expecting two threads, thread B may never proceed because
thread A never arrives at the &quot;barrier&quot;.</p>
<h2 id="more-complex-example"><a class="header" href="#more-complex-example">More Complex Example</a></h2>
<p>If you want to see a more complex design using <code>@sync</code>, see 
<a href="https://github.com/cucapra/calyx/blob/master/tests/correctness/sync/sync-dot-product.futil">sync-dot-product</a></p>
<h2 id="limitations"><a class="header" href="#limitations">Limitations</a></h2>
<p>Currently we only support two threads sharing the same &quot;barrier&quot;, i.e., only two threads can have control with the <code>@sync</code> attribute marked with the same value. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="undefined-behaviors"><a class="header" href="#undefined-behaviors">Undefined Behaviors</a></h1>
<p>Undefined behavior in Calyx is either intentional or unintentional. This page tracks the various issues discussing the undefined behaviors that are known to currently exist in Calyx.</p>
<h2 id="interface-signals"><a class="header" href="#interface-signals">Interface Signals</a></h2>
<p>The <code>go</code> and <code>done</code> signals form the two core interface signals in Calyx. Their semantics are baked into the compiler and pervasively used to define the meaning of programs.</p>
<ul>
<li><a href="https://github.com/cucapra/calyx/discussions/651">Isolation and stateful &quot;doneness&quot; (#651)</a></li>
<li><a href="https://github.com/cucapra/calyx/discussions/788">Well-formedness of <code>done</code> signals (#788)</a></li>
</ul>
<h2 id="undriven-ports"><a class="header" href="#undriven-ports">Undriven Ports</a></h2>
<p>Calyx's continuous assignments do not make any static guarantees about which ports need to be driven when. Current efforts attempt to codify <em>when</em> reading from an undriven port is incorrect.</p>
<ul>
<li><a href="https://github.com/cucapra/calyx/discussions/588">Port validity as a first class concept (#588)</a></li>
<li><a href="https://github.com/cucapra/calyx/discussions/922">A few notes on undefinedness (#922)</a></li>
</ul>
<h2 id="semantics-of-par"><a class="header" href="#semantics-of-par">Semantics of <code>par</code></a></h2>
<p><code>par</code> blocks in Calyx represent parallel execution of groups. Currently, there is no clear semantics for interactions between groups executing in parallel. The interpreter implements a form of lockstep semantics that disallows certain forms of concurrent reads and writes while the code generated by the compiler allows for arbitrary communication.</p>
<ul>
<li><a href="https://github.com/cucapra/calyx/discussions/921">On the semantics of <code>par</code> (#921)</a></li>
<li><a href="https://github.com/cucapra/calyx/discussions/932">Formalizing the semantics of <code>par</code> (#932)</a></li>
</ul>
<h2 id="isolation-guarantees"><a class="header" href="#isolation-guarantees">Isolation Guarantees</a></h2>
<p>Calyx groups have a strong isolation guarantee---they must execute for at least one cycle and guarantee that signals inside are not visible after they are done executing.
However, the isolation guarantees for combinational groups, continuous assignments, and <code>with</code> blocks is not clear.</p>
<ul>
<li><a href="https://github.com/cucapra/calyx/discussions/927">Isolation guarantees of combinational groups</a></li>
<li><a href="https://github.com/cucapra/calyx/discussions/934">The <code>with</code> operator</a></li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="attributes"><a class="header" href="#attributes">Attributes</a></h1>
<p>Calyx has an attribute system that allows information to be associated with
every basic Calyx construct. This information can then be used to optimize the program
or change how the program is compiled.</p>
<p>Attributes can decorate lots of things in Calyx: components, groups, cells, ports, and control statements.
The syntax looks like <code>name&lt;&quot;attr&quot;=value&gt;</code> for components and groups or <code>@attr(value)</code> for other constructs.
Attributes always map keys to values.
Because it's common to have a &quot;Boolean&quot; attribute that always maps to the value 1, the syntax <code>@attr</code> is a shorthand for <code>@attr(1)</code>.</p>
<p>Here is the syntax for attributes in different parts of the AST:</p>
<h4 id="component-and-port-attributes"><a class="header" href="#component-and-port-attributes"><strong>Component and Port Attributes</strong></a></h4>
<pre><code>component main&lt;&quot;static&quot;=10&gt;(@go go: 1) -&gt; (@done done: 1) {
 ...
}
</code></pre>
<h4 id="cell-attributes"><a class="header" href="#cell-attributes"><strong>Cell Attributes</strong></a></h4>
<pre><code>cells {
  @external mem = std_mem_d1(32, 8, 4);
  reg = std_reg(32);
  ...
}
</code></pre>
<h4 id="group-attributes"><a class="header" href="#group-attributes"><strong>Group Attributes</strong></a></h4>
<pre><code>group cond&lt;&quot;static&quot;=1&gt; {
  ...
}
</code></pre>
<h4 id="control-attributes"><a class="header" href="#control-attributes"><strong>Control Attributes</strong></a></h4>
<pre><code>control {
  @static(3) seq {
    @static(1) A;
    @static(2) B;
  }
}
</code></pre>
<h2 id="meaning-of-attributes"><a class="header" href="#meaning-of-attributes">Meaning of Attributes</a></h2>
<h3 id="toplevel"><a class="header" href="#toplevel"><code>toplevel</code></a></h3>
<p>The entrypoint for the Calyx program. If no component has this attribute, then
the compiler looks for a component named <code>main</code>. If neither is found, the
compiler errors out.</p>
<h3 id="go-done-clk-and-reset"><a class="header" href="#go-done-clk-and-reset"><code>go</code>, <code>done</code>, <code>clk</code> and <code>reset</code></a></h3>
<p>These four ports are part of the interface to Calyx components.
These are automatically added by the parser if they are missing from the component definition.
<code>go</code> and <code>done</code> provide the mechanism for how an &quot;outer&quot; component invokes an &quot;inner&quot; cell that it contains.
<code>clk</code> and <code>reset</code> thread through the global clock and resetting signal in a design.</p>
<h3 id="nointerface"><a class="header" href="#nointerface"><code>nointerface</code></a></h3>
<p>By default, interface ports are automatically added to a component by the parser if they are missing.
Adding this attribute disables this behavior.</p>
<h3 id="external"><a class="header" href="#external"><code>external</code></a></h3>
<p>The <code>external</code> attribute has meaning when it is attached to a cell.
It has two meanings:</p>
<ol>
<li>If the <code>externalize</code> compiler alias is enabled, the cell is turned into an &quot;external&quot;
cell by exposing all its ports through the current component and rewriting
assignments to the use the ports. See the documentation on <a href="https://docs.rs/calyx-opt/latest/calyx_opt/passes/struct.Externalize.html">externalize</a> for more information.</li>
<li>If the cell is a memory and has an <code>external</code> attribute on it, the Verilog backend (<code>-b verilog</code>) generates code to read <code>&lt;cell_name&gt;.dat</code> to initialize the memory state and dumps out its final value after execution.</li>
</ol>
<h3 id="staticn"><a class="header" href="#staticn"><code>static(n)</code></a></h3>
<p>Can be attached to components, groups, and control statements. They indicate how
many cycles a component, group, or control statement will take to run and are used
by <code>-p static-timing</code> to generate more efficient control FSMs.</p>
<p>The <code>go</code> and <code>done</code> attributes are, in particular, used by the <code>infer-static-timing</code> pass to configure which ports are used like
<code>go</code> and <code>done</code> signals.
Along with the <code>static(n)</code> attribute, this allows the pass to calculate when
a particular done signal of a primitive will be high.</p>
<h3 id="inline"><a class="header" href="#inline"><code>inline</code></a></h3>
<p>Used by the <code>inline</code> pass on cell definitions. Instructs the pass to completely
inline the instance into the parent component and replace all <code>invoke</code>s of the
instance with the control program of the instance.</p>
<h3 id="stable"><a class="header" href="#stable"><code>stable</code></a></h3>
<p>Used by the <code>canonicalize</code> pass.
Only meaningful on output ports and states that their value is provided by
a sequential element and is therefore available outside combinational time.</p>
<p>For example, after invoking a multiplier, the value on its <code>out</code> port remains
latched till the next invocation.</p>
<p>For example</p>
<pre><code>cells {
  m = std_mult_pipe(32);
}
wires {
  group use_m_out { // uses m.out }
}
control {
  invoke m(left = 32'd10, right = 32'd4)();
  use_m_out;
}
</code></pre>
<p>The value of <code>m.out</code> in <code>use_m_out</code> will be <code>32'd40</code>.</p>
<p>This annotation is currently used by the primitives library and the Dahlia
frontend.</p>
<h3 id="share"><a class="header" href="#share"><code>share</code></a></h3>
<p>Can be attached to a component and indicates that a component can be shared
across groups. This is used by the <code>-p cell-share</code> to decide which components
can be shared.</p>
<h3 id="state_share"><a class="header" href="#state_share"><code>state_share</code></a></h3>
<p>Can be attached to a component and indicates that a component can be shared
across groups. Different than <code>share</code> since <code>state_share</code> components can have
internal state.
This is used by <code>-p cell-share</code> to decide which components can be shared.
Specifically, a component is state shareable if each write to
that component makes any previous writes to the component irrelevant.
The definition of a &quot;write to a component&quot; is an activiation of
the component's &quot;go&quot; port, followed by a read of the component's &quot;done&quot; port (in
other words, the read of a &quot;done&quot; port still counts as part of a &quot;write&quot; to the
component).
For <code>c1</code> and <code>c2</code>, instances of a state_shareable component:
instantiate <code>c1</code>                        instantiate <code>c2</code>
<em>any write to <code>c1</code></em>                     <em>any write to <code>c2</code></em>
<em>write value <code>v</code> to port <code>p</code> in <code>c1</code></em>   <em>write value <code>v</code> to port <code>p</code> in <code>c2</code></em>
<code>c1</code> and <code>c2</code> should be equal.</p>
<h3 id="boundn"><a class="header" href="#boundn"><code>bound(n)</code></a></h3>
<p>Used in <code>infer-static-timing</code> and <code>static-timing</code> when the number of iterations
of a <code>While</code> control is known statically, as indicated by <code>n</code>.</p>
<h3 id="generated"><a class="header" href="#generated"><code>generated</code></a></h3>
<p>Added by <a href="https://docs.rs/calyx-ir/latest/calyx_ir/struct.Builder.html"><code>ir::Builder</code></a> to denote that the cell was added by a pass.</p>
<h3 id="clk"><a class="header" href="#clk"><code>clk</code></a></h3>
<p>Marks the special clock signal inserted by the <code>clk-insertion</code> pass, which helps with lowering to RTL languages that require an explicit clock.</p>
<h3 id="write_togethern"><a class="header" href="#write_togethern"><code>write_together(n)</code></a></h3>
<p>Used by the <code>papercut</code> pass.
Defines a group <code>n</code> of signals that all must be driven together:</p>
<pre><code>primitive std_mem_d2&lt;&quot;static&quot;=1&gt;[WIDTH, D0_SIZE, D1_SIZE, D0_IDX_SIZE, D1_IDX_SIZE](
  @write_together(2) addr0: D0_IDX_SIZE,
  @write_together(2) addr1: D1_IDX_SIZE,
  @write_together(1) write_data: WIDTH,
  @write_together(1) @go write_en: 1,
  ...
) -&gt; (...);
</code></pre>
<p>This defines two groups.
The first group requires that <code>write_en</code> and <code>write_data</code> signals together
while the second requires that <code>addr0</code> and <code>addr1</code> are driven together.</p>
<p>Note that <code>@write_together</code> specifications cannot encode implication of the
form &quot;if port <code>x</code> is driven then <code>y</code> should be driven&quot;.</p>
<h3 id="read_togethern"><a class="header" href="#read_togethern"><code>read_together(n)</code></a></h3>
<p>Used by <code>papercut</code> and <code>canonicalize</code>.
Defines a combinational path <code>n</code> between a set of an input ports and an output
port.</p>
<pre><code>primitive std_mem_d1&lt;&quot;static&quot;=1&gt;[WIDTH, SIZE, IDX_SIZE](
  @read_together(1) addr0: IDX_SIZE, ...
) -&gt; (
  @read_together(1) read_data: WIDTH, ...
);
</code></pre>
<p>This requires that when <code>read_data</code> is used then <code>addr0</code> must be driven.
Note that each group must have exactly one output port in it.</p>
<h3 id="data"><a class="header" href="#data"><code>@data</code></a></h3>
<p>Marks a cell or a port as a <em>purely datapath</em> component, i.e., the output does not propagate into a guard or another control signal. See <a href="https://github.com/cucapra/calyx/issues/1169">this issue</a> for the full set of constraints.</p>
<p>When we have following two conditions:</p>
<ol>
<li>An input port is marked with <code>@data</code> in the component definitions, and</li>
<li>The cell instance is marked as <code>@data</code></li>
</ol>
<p>The backend generate <code>'x</code> as the default value for the assignment to the port instead of <code>'0</code>. Additionally, if the port has exactly one assignment, the backend removes the guard entirely and produces a continuous assignment.</p>
<p>This represents the optimization:</p>
<pre><code>in = g ? out : 'x
</code></pre>
<p>into:</p>
<pre><code>in = out;
</code></pre>
<p>Since the value <code>'x</code> can be replaced with anything.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="fud-the-calyx-driver"><a class="header" href="#fud-the-calyx-driver"><code>fud</code>: The Calyx Driver</a></h1>
<p>Working with Calyx involves a lot of command-line tools. For example, an
incomplete yet daunting list of CLI tools used by Calyx is:</p>
<ul>
<li>All the Calyx <a href="fud/../frontends/index.html">frontends</a>.</li>
<li>Calyx compiler and its various command line tools</li>
<li>Verilator, the Verilog simulation framework used to test Calyx-generated designs.</li>
<li>Waveform viewers to see the results of simulation</li>
</ul>
<p><code>fud</code> aims to provide a simple interface for using these toolchains and executing them in a pipeline.
The source for fud is <a href="https://github.com/cucapra/calyx/tree/master/fud">here</a>.</p>
<h2 id="installation"><a class="header" href="#installation">Installation</a></h2>
<blockquote>
<p>Fud requires Python 3.9 or higher to work correctly.</p>
</blockquote>
<p>You need <a href="https://flit.readthedocs.io/en/latest/">Flit</a> to install <code>fud</code>. Install it with <code>pip3 install flit</code>.</p>
<p>You can then install <code>fud</code> with</p>
<pre><code class="language-bash">cd fud &amp;&amp; flit install
</code></pre>
<p>(If using this method to install <code>fud</code>, <code>pip3</code> should be version &gt;= 20)</p>
<p>If you are working on <code>fud</code> itself, you can install it with a symlink with:</p>
<pre><code class="language-bash">cd fud &amp;&amp; flit install --symlink
</code></pre>
<p>You can also install <code>fud</code> with</p>
<pre><code class="language-bash">flit build
pip3 install dist/fud-0.3.0-py3-none-any.whl
</code></pre>
<p>Finally, point <code>fud</code> to the root of the repository:</p>
<pre><code>fud config global.root &lt;full path to Calyx repository&gt;
</code></pre>
<h2 id="configuration"><a class="header" href="#configuration">Configuration</a></h2>
<p>Fud uses a global configuration file to locate tool paths and default values.
To view the configuration, use <code>fud c</code> or <code>fud config</code>.</p>
<p><strong>Check.</strong>
Fud can automatically check if your configuration is valid and can help you set
certain variables. Perform this check with:</p>
<pre><code class="language-bash">fud check
</code></pre>
<p><strong>Viewing keys.</strong>
To view the current value of a key, use <code>fud config key</code>. For example, the
following shows the path to the Calyx compiler.</p>
<pre><code class="language-bash">fud config stages.calyx.exec
</code></pre>
<p><strong>Updating keys.</strong>
Keys can be updated using <code>fud config key value</code>.
For example, the following command updates the path to the Calyx compiler.</p>
<pre><code class="language-bash">fud config stages.calyx.exec ./target/debug/calyx
</code></pre>
<h2 id="adding-backends"><a class="header" href="#adding-backends">Adding Backends</a></h2>
<p><code>fud</code> wraps both frontends and backends for Calyx.
For a useful <code>fud</code> installation, you need to configure the Verilator
backend and accompanying tools.</p>
<h3 id="verilator"><a class="header" href="#verilator">Verilator</a></h3>
<p>We use the open source <a href="https://www.veripool.org/wiki/verilator">Verilator</a> tool to simulate Verilog programs
generated by the Calyx compiler.
Install Verilator by <a href="https://www.veripool.org/projects/verilator/wiki/Installing">following the official instructions</a>.
On macOS, you can use <code>brew install verilator</code> or, otherwise, compile from source:</p>
<pre><code>git clone https://github.com/verilator/verilator
cd verilator
git pull
git checkout master
autoconf
./configure
make
sudo make install
</code></pre>
<p>Run <code>fud check</code> to make sure you have the right version. We currently require &gt;=v5.002 of Verilator with fud.</p>
<p>By default, <code>fud</code> will use the <code>verilator</code> executable to run Verilator.
To use a different binary, configure the path by:</p>
<pre><code>fud config stages.verilog.exec &lt;binary&gt;
</code></pre>
<p><strong>Vcdump.</strong>
Vcdump is a tool for converting <code>vcd</code> (Value Change Dump) files to JSON for
easier analysis with the command line.</p>
<p>Install it with:</p>
<pre><code class="language-bash">cargo install vcdump
</code></pre>
<h3 id="icarus-verilog"><a class="header" href="#icarus-verilog">Icarus Verilog</a></h3>
<p><code>fud</code> also supports <a href="http://iverilog.icarus.com/">Icarus Verilog</a> as a simulation backend.
Since Icarus Verilog interprets programs, it can often be faster than
<code>verilator</code>.
First <a href="https://iverilog.fandom.com/wiki/Installation_Guide">install Icarus Verilog</a> and ensure that <code>iverilog</code> and
<code>vvp</code> are on your path.
Next, register the <code>icarus-verilog</code> external stage with <code>fud</code>:</p>
<pre><code>fud register icarus-verilog -p fud/icarus/icarus.py
</code></pre>
<p>To test the simulation backend, run:</p>
<pre><code>fud e --to dat examples/tutorial/language-tutorial-iterate.futil -s verilog.data examples/tutorial/data.json --through icarus-verilog
</code></pre>
<p>Registering this stage will define multiple paths in the fud transformation
graph between <code>futil</code> and the <code>vcd</code> and <code>dat</code> stages.
If you'd like <code>fud</code> to default to <code>verilog</code> stage, give it a <a href="fud/./multiple-paths.html#using-stage-priority">high
priority</a>:</p>
<pre><code>fud c stages.verilog.priority 1
</code></pre>
<h2 id="dahlia-frontend"><a class="header" href="#dahlia-frontend">Dahlia Frontend</a></h2>
<p>In order to use the Dahlia frontend with Fud, first <a href="fud/../frontends/dahlia.html">install
Dahlia</a>.
Once Dahlia is compiled, point <code>fud</code> to the Dahlia compiler binary:</p>
<pre><code class="language-bash">fud config stages.dahlia.exec &lt;full path to dahlia repo&gt;/fuse
</code></pre>
<h2 id="python-frontends-systolic-array-ntt-mrxl-tvm-relay"><a class="header" href="#python-frontends-systolic-array-ntt-mrxl-tvm-relay">Python frontends (Systolic array, NTT, MrXL, TVM Relay)</a></h2>
<p>You need <a href="https://flit.readthedocs.io/en/latest/">flit</a> to install our Python frontends.</p>
<pre><code>pip3 install flit
</code></pre>
<p>Our Python <a href="fud/../frontends">frontends</a> use a Calyx ast library written in Python. Install with:</p>
<pre><code>cd calyx-py &amp;&amp; flit install -s
</code></pre>
<p>Frontend specific instructions:</p>
<ul>
<li><a href="fud/../frontends/systolic-array.html">Systolic array</a>: Nothing else needed.</li>
<li><a href="fud/../frontends/ntt.html">NTT</a>:
<ul>
<li>Install dependencies: <code>pip3 install prettytable</code></li>
<li>Install external <code>fud</code> stage: <code>fud register ntt -p frontends/ntt-pipeline/fud/ntt.py</code></li>
</ul>
</li>
<li><a href="fud/../frontends/mrxl.html">MrXL</a>:
<ul>
<li>Install <code>mrxl</code> binary: <code>cd frontends/mrxl &amp;&amp; flit install -s</code></li>
<li>Install <code>mrxl</code> <a href="fud/./external.html">external stage</a> for <code>fud</code>: <code>fud register mrxl -p frontends/mrxl/fud/mrxl.py</code></li>
</ul>
</li>
<li><a href="fud/../frontends/tvm-relay.html">TVM Relay</a>: See instructions.</li>
</ul>
<h2 id="adding-synthesis-backends"><a class="header" href="#adding-synthesis-backends">Adding Synthesis Backends</a></h2>
<p><code>fud</code> supports wraps the Vivado (<code>synth-verilog</code>) and Vivado HLS (<code>vivado-hls</code>)
tools to generate area and resource estimates for Calyx designs.
See <a href="fud/./xilinx.html">the instructions</a> to configure them.</p>
<h2 id="working-with-stages"><a class="header" href="#working-with-stages">Working with Stages</a></h2>
<p>Fud is structured as a sequence of stages that transform inputs of one form
to outputs.</p>
<p><strong>Stages.</strong>
<code>fud</code> transforms a file in one stage into a file in a later stage.
The <code>--from</code> and <code>--to</code> options specify the input and output stages to the
<code>fud exec</code> subcommand.
Use <code>fud info</code> to view all possible stages.</p>
<p><strong>Guessing stages.</strong>
<code>fud</code> will try to guess the starting stage by looking at the extension of the
input file and output file (if specified using the <code>-o</code> flag).
If it fails to guess correctly or doesn't know about the extension, you can
manually set the stages using <code>--to</code> and <code>--from</code>.</p>
<h2 id="profiling"><a class="header" href="#profiling">Profiling</a></h2>
<p>Fud provides some very basic profiling tools through the use of the <code>--dump_prof</code> (or <code>-pr</code>) flag.
You can get overall stage durations for a <code>fud</code> run by simply using <code>-pr</code>.
For example,</p>
<pre><code class="language-bash">  fud e examples/dahlia/dot-product.fuse --to dat \
  -s verilog.data examples/dahlia/dot-product.fuse.data \
  -pr
</code></pre>
<p>will output:</p>
<pre><code>stage                           elapsed time (s)
dahlia                          1.231
futil                           0.029
verilog                         4.915
</code></pre>
<p>If you want time elapsed for each step in a stage, you can also provide one or more stages after the flag.
For example,</p>
<pre><code class="language-bash">  fud e examples/dahlia/dot-product.fuse --to dat \
  -s verilog.data examples/dahlia/dot-product.fuse.data \
  -pr verilog
</code></pre>
<p>will output:</p>
<pre><code>verilog                         elapsed time (s)
mktmp                           0.0
json_to_dat                     0.004
compile_with_verilator          5.584
simulate                        0.161
output_json                     0.003
cleanup                         0.003
</code></pre>
<p>If you want time elapsed for a single step, you can specify the given step, e.g.</p>
<pre><code class="language-bash">  fud e examples/dahlia/dot-product.fuse --to dat \
  -s verilog.data examples/dahlia/dot-product.fuse.data \
  -pr verilog.simulate
</code></pre>
<p>will output:</p>
<pre><code>verilog                         elapsed time (s)
simulate                        0.161
</code></pre>
<p>Lastly, the <code>-csv</code> flag will provide the profiling information in CSV format.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="examples"><a class="header" href="#examples">Examples</a></h1>
<p>These commands will assume you're in the root directory of the Calyx
repository.</p>
<p><strong>Compiling Calyx.</strong>
Fud wraps the Calyx compiler and provides a set of default compiler options
to compile Calyx programs to Verilog.</p>
<pre><code class="language-bash"># Compile Calyx source in the test simple.expect
# to Verilog. We must explicitly specify the input
# file type because it can not be guessed from
# the file extension.
fud exec examples/futil/simple.futil --from calyx --to verilog
</code></pre>
<p>Fud can explain its execution plan when running a complex sequence of
steps using the <code>--dry-run</code> option.</p>
<pre><code class="language-bash"># Dry run of compiling the Dahlia dot product file
# to Calyx. As expected, this will *only* print
# the stages that will be run.
fud exec examples/dahlia/dot-product.fuse --to calyx --dry-run
</code></pre>
<p><strong>Simulating Calyx.</strong>
Fud can compile a Calyx program to Verilog and simulate it using Verilator.</p>
<pre><code class="language-bash"># Compile and simulate a vectorized add implementation
# in Calyx using the data provided,
# then dump the vcd into a new file for debugging.
# === Calyx:   examples/futil/vectorized-add.futil
# === data:    examples/dahlia/vectorized-add.fuse.data
# === output:  v-add.vcd
fud exec \
  examples/futil/vectorized-add.futil \
  -o v-add.vcd \
  -s verilog.data examples/dahlia/vectorized-add.fuse.data
</code></pre>
<p><strong>Simulating Dahlia.</strong>
The following command prints out the final state of all memories by specifying
<code>--to dat</code>.</p>
<pre><code class="language-bash"># Compile a Dahlia dot product implementation and
# simulate in verilog using the data provided.
# === Dahlia: examples/dahlia/dot-product.fuse
# === data:   examples/dahlia/dot-product.fuse.data
#     (`.data` is used as an extension alias for `.json`)
fud exec \
  examples/dahlia/dot-product.fuse \
  --to dat \
  -s verilog.data examples/dahlia/dot-product.fuse.data
</code></pre>
<p><strong>Interpreting Calyx.</strong>
In addition to Verilator, fud can execute Calyx programs using the experimental <a href="fud/../interpreter.html">interpreter</a>.</p>
<pre><code class="language-bash"># Execute a Calyx program without compiling it,
# producing a JSON snapshot of the final state.
# === Calyx:   tests/correctness/while.futil
# === data:    tests/correctness/while.futil.data
fud exec \
  tests/correctness/while.futil \
  -s verilog.data tests/correctness/while.futil.data \
  --to interpreter-out
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="xilinx-toolchain"><a class="header" href="#xilinx-toolchain">Xilinx Toolchain</a></h1>
<blockquote>
<p>Working with vendor EDA toolchains is never a fun experience. Something will
almost certainly go wrong. If you're at Cornell, you can at least avoid
installing the tools yourself by using our lab servers, <a href="https://capra.cs.cornell.edu/private/gorgonzola.html">Gorgonzola</a> or <a href="https://capra.cs.cornell.edu/private/havarti.html">Havarti</a>.</p>
</blockquote>
<p><code>fud</code> can interact with the Xilinx tools (<a href="https://www.xilinx.com/products/design-tools/vivado.html">Vivado</a>, <a href="https://www.xilinx.com/products/design-tools/vivado/integration/esl-design.html">Vivado HLS</a>, and <a href="https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html">Vitis</a>). There are three main things it can do:</p>
<ul>
<li>Synthesize Calyx-generated RTL designs to collect area and resource estimates.</li>
<li>Compile <a href="https://capra.cs.cornell.edu/dahlia/">Dahlia</a> programs via C++ and <a href="https://www.xilinx.com/products/design-tools/vivado/integration/esl-design.html">Vivado HLS</a> for comparison with the Calyx backend.</li>
<li>Compile Calyx programs for <em>actual execution</em> in Xilinx emulation modes or on real FPGA hardware.</li>
</ul>
<p>You can set <code>fud</code> up to use either a local installation of the Xilinx tools or one on a remote server, via SSH.</p>
<h2 id="synthesis-only"><a class="header" href="#synthesis-only">Synthesis Only</a></h2>
<p>The simplest way to use the Xilinx tools is to synthesize RTL or HLS designs to collect statistics about them.
This route will not produce actual, runnable executables; see the next section for that.</p>
<h3 id="installing-dependencies"><a class="header" href="#installing-dependencies">Installing Dependencies</a></h3>
<p><code>fud</code> uses extra dependencies to invoke the Xilinx toolchains.
Run the following command to install all required dependencies:</p>
<pre><code>cd fud &amp;&amp; flit install -s --deps all
</code></pre>
<h3 id="setting-up-remote-tools"><a class="header" href="#setting-up-remote-tools">Setting up Remote Tools</a></h3>
<blockquote>
<p>Follow these instructions if you're attempting to run <code>vivado</code> or <code>vivado-hls</code> on a server from your local machine. If you are working directly on a server with these tools, skip to the <a href="fud/xilinx.html#run">run instructions</a>.</p>
</blockquote>
<p>To set up to <strong>invoke the Xilinx tools over SSH</strong>, first tell <code>fud</code> your username and hostname for the server:</p>
<pre><code># Vivado
fud config stages.synth-verilog.ssh_host &lt;hostname&gt;
fud config stages.synth-verilog.ssh_username &lt;username&gt;

# Vivado HLS
fud config stages.vivado-hls.ssh_host &lt;hostname&gt;
fud config stages.vivado-hls.ssh_username &lt;username&gt;
</code></pre>
<p>The following commands enable remote usage of <code>vivado</code> and <code>vivado-hls</code> by default:</p>
<pre><code>fud config stages.synth-verilog.remote 1
fud config stages.vivado-hls.remote 1
</code></pre>
<p>The server must have <code>vivado</code> and <code>vivado_hls</code> available on the remote machine's path. (If you need the executable names to be something else, please file an issue.)</p>
<p>To tell if this has been set up correctly, run <code>ssh &lt;username&gt;@&lt;xilinx.tool.server&gt;</code> and ensure that you are not prompted for a password. The <code>ssh-copy-id</code> command will let you setup your server to authenticate without a password. Note that after you SSH into the server, the Vivado command should work without needing to run any source command. </p>
<p>Here's how you would ssh into Havarti:</p>
<pre><code>ssh user@havarti.cs.cornell.edu
user@havarti:~$ vivado

****** Vivado v2020.2 (64-bit)
</code></pre>
<h3 id="setting-up-local-tools"><a class="header" href="#setting-up-local-tools">Setting up Local Tools</a></h3>
<p>To instead <strong>invoke the Xilinx tools locally</strong>, just let <code>fud</code> run the <code>vivado</code> and <code>vivado_hls</code> commands.
You can optionally tell <code>fud</code> where these commands exist on your machine:</p>
<pre><code>fud config stages.synth-verilog.exec &lt;path&gt; # update vivado path
fud config stages.vivado-hls.exec &lt;path&gt; # update vivado_hls path
</code></pre>
<p>Setting the <code>remote</code> option for the stages to <code>0</code> ensure that <code>fud</code> will always try to run the commands locally.</p>
<pre><code>fud config stages.synth-verilog.remote 0
fud config stages.vivado-hls.remote 0
</code></pre>
<h3 id="run"><a class="header" href="#run">Run</a></h3>
<p>To run the entire toolchain and extract statistics from RTL synthesis, use the <code>resource-estimate</code> target state.
For example:</p>
<pre><code>fud e --to resource-estimate examples/futil/dot-product.futil
</code></pre>
<p>To instead obtain the raw synthesis results, use <code>synth-files</code>.</p>
<p>To run the analogous toolchain for Dahlia programs via HLS, use the <code>hls-estimate</code> target state:</p>
<pre><code>fud e --to hls-estimate examples/dahlia/dot-product.fuse
</code></pre>
<p>There is also an <code>hls-files</code> state for the raw results of Vivado HLS.</p>
<h2 id="emulation-and-execution"><a class="header" href="#emulation-and-execution">Emulation and Execution</a></h2>
<p><code>fud</code> can also compile Calyx programs for actual execution, either in the Xilinx toolchain's emulation modes or for running on a physical FPGA.
This route involves generating an <a href="https://en.wikipedia.org/wiki/Advanced_eXtensible_Interface">AXI</a> interface wrapper for the Calyx program and invoking it using Xilinx's <a href="https://github.com/Xilinx/PYNQ">PYNQ</a> interface.</p>
<h3 id="set-up"><a class="header" href="#set-up">Set Up</a></h3>
<p>As above, you can invoke the Xilinx toolchain locally or remotely, via SSH.
To set up SSH execution, you can edit your <code>config.toml</code> to add settings like this:</p>
<pre><code>[stages.xclbin]
ssh_host = &quot;havarti&quot;
ssh_username = &quot;als485&quot;
remote = 1
</code></pre>
<p>To use local execution, just leave off the <code>remote = true</code> line.</p>
<p>You can also set the Xilinx mode and target device:</p>
<pre><code>[stages.xclbin]
mode = &quot;hw_emu&quot;
device = &quot;xilinx_u50_gen3x16_xdma_201920_3&quot;
</code></pre>
<p>The options for <code>mode</code> are <code>hw_emu</code> (simulation) and <code>hw</code> (on-FPGA execution).
The device string above is for the <a href="https://www.xilinx.com/products/boards-and-kits/alveo/u50.html">Alveo U50</a> card, which we have at Cornell. The installed Xilinx card would typically be found under the directory <code>/opt/xilinx/platforms</code>, where one would be able to find a device name of interest.</p>
<p>To run simulations (or on real FPGAs), you will also need to configure the <code>fpga</code> stage to point to your installations of <a href="https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html">Vitis</a> and <a href="https://xilinx.github.io/XRT/">XRT</a>:</p>
<pre><code>[stages.fpga]
xilinx_location = &quot;/scratch/opt/Xilinx/Vitis/2020.2&quot;
xrt_location = &quot;/scratch/opt/xilinx/xrt&quot;
</code></pre>
<p>Those are the paths on Cornell's havarti server.</p>
<h3 id="compile"><a class="header" href="#compile">Compile</a></h3>
<p>The first step in the Xilinx toolchain is to generate <a href="https://xilinx.github.io/XRT/2021.2/html/formats.html#xclbin">an <code>xclbin</code> executable file</a>.
Here's an example of going all the way from a Calyx program to that:</p>
<pre><code>fud e examples/futil/dot-product.futil -o foo.xclbin --to xclbin
</code></pre>
<p>On our machines, compiling even a simple example like the above for simulation takes about 5 minutes, end to end.
A failed run takes about 2 minutes to produce an error.</p>
<p>By default, the Xilinx tools run in a temporary directory that is deleted when <code>fud</code> finishes.
To instead keep the sandbox directory, use <code>-s xclbin.save_temps true</code>.
You can then find the results in a directory named <code>fud-out-N</code> for some number <code>N</code>.</p>
<h3 id="execute"><a class="header" href="#execute">Execute</a></h3>
<p>Now that you have an <code>xclbin</code>, the next step is to run it.
Here's a fud invocation that goes from the <code>xclbin</code> stage to the <code>fpga</code> stage:</p>
<pre><code>fud e foo.xclbin --from xclbin --to fpga -s fpga.data examples/dahlia/dot-product.fuse.data
</code></pre>
<p>fud will print out JSON memory contents in the same format as for other RTL simulators.</p>
<h4 id="waveform-debugging"><a class="header" href="#waveform-debugging">Waveform Debugging</a></h4>
<p>In emulation mode, this stage can produce a waveform trace in Xilinx's proprietary <a href="https://support.xilinx.com/s/article/64000?language=en_US">WDB</a> file format as well as a standard <a href="https://en.wikipedia.org/wiki/Value_change_dump">VCD</a> file.</p>
<p>Use the fud options <code>-s fpga.waveform true -s fpga.save_temps true</code> when emulating your program.
The first option instructs XRT to use <a href="https://xilinx.github.io/Vitis_Accel_Examples/2021.1/html/debug_profile.html">the <code>batch</code> debug mode</a> and to dump a VCD, and the second asks fud not to delete the directory where the waveform files will appear.</p>
<p>Then, look in the resulting directory, which will be named <code>fud-out-*</code> for some <code>*</code>.
In there, the Xilinx trace files you want are named <code>*.wdb</code> and <code>*.wcfg</code>.
The VCD file is at <code>.run/*/hw_em/device0/binary_0/behav_waveform/xsim/dump.vcd</code> or similar.</p>
<h3 id="how-it-works"><a class="header" href="#how-it-works">How it Works</a></h3>
<p>The first step is to generate input files.
We need to generate:</p>
<ul>
<li>The RTL for the design itself, using the compile command-line flags <code>-b verilog --synthesis -p external</code>. We name this file <code>main.sv</code>.</li>
<li>A Verilog interface wrapper, using <code>XilinxInterfaceBackend</code>, via <code>-b xilinx</code>. We call this <code>toplevel.v</code>.</li>
<li>An XML document describing the interface, using <code>XilinxXmlBackend</code>, via <code>-b xilinx-xml</code>. This file gets named <code>kernel.xml</code>.</li>
</ul>
<p>The <code>fud</code> driver gathers these files together in a sandbox directory.
The next step is to run the Xilinx tools.</p>
<p>The rest of this section describes how this workflow works under the hood.
If you want to follow along by typing commands manually, you can start by invoking the setup scripts for <a href="https://www.xilinx.com/products/design-tools/vitis/vitis-platform.html">Vitis</a> and <a href="https://xilinx.github.io/XRT/">XRT</a>:</p>
<pre><code>source &lt;Vitis_install_path&gt;/Vitis/2020.1/settings64.sh
source /opt/xilinx/xrt/setup.sh
</code></pre>
<p>On some Ubuntu setups, you may need to update <code>LIBRARY_PATH</code>:</p>
<pre><code>export LIBRARY_PATH=/usr/lib/x86_64-linux-gnu
</code></pre>
<p>You can check that everything is working by typing <code>vitis -version</code> or <code>vivado -version</code>.</p>
<h4 id="background-xo-and-xclbin"><a class="header" href="#background-xo-and-xclbin">Background: <code>.xo</code> and <code>.xclbin</code></a></h4>
<p>In the Xilinx toolchain, compilation to an executable bitstream (or simulation blob) appears to requires two steps:
taking your Verilog sources and creating an <code>.xo</code> file, and then taking that and producing an <code>.xclbin</code> “executable” file.
The idea appears to be a kind of metaphor for a standard C compilation workflow in software-land: <code>.xo</code> is like a <code>.o</code> object file, and <code>.xclbin</code> contains actual executable code (bitstream or emulation equivalent), like a software executable binary.
Going from Verilog to <code>.xo</code> is like “compilation” and going from <code>.xo</code> to <code>.xclbin</code> is like “linking.”</p>
<p>However,  this analogy is kind of a lie.
Generating an <code>.xo</code> file actually does very little work:
it just packages up the Verilog source code and some auxiliary files.
An <code>.xo</code> is literally a zip file with that stuff packed up inside.
All the actual work happens during “linking,” i.e., going from <code>.xo</code> to <code>.xclbin</code> using the <code>v++</code> tool.
This situation is a poignant reminder of how impossible separate compilation is in the EDA world.
A proper analogy would involve separately compiling the Verilog into some kind of low-level representation, and then linking would properly smash together those separately-compiled objects.
Instead, in Xilinx-land, “compilation” is just simple bundling and “linking” does all the compilation in one monolithic step.
It’s kind of cute that the Xilinx toolchain is pretending the world is otherwise, but it’s also kind of sad.</p>
<p>Anyway, the only way to produce a <code>.xo</code> file from RTL code appears to be to use Vivado (i.e., the actual <code>vivado</code> program).
Nothing from the newer Vitis package currently appears capable of producing <code>.xo</code> files from Verilog (although <code>v++</code> can produce these files during HLS compilation, presumably by invoking Vivado).</p>
<p>The main components in an <code>.xo</code> file, aside from the Verilog source code itself, are two XML files:
<code>kernel.xml</code>, a short file describing the argument interfaces to the hardware design,
and <code>component.xml</code>, a much longer and more complicated <a href="https://en.wikipedia.org/wiki/IP-XACT">IP-XACT</a> file that also has to do with the interface to the RTL.
We currently generate <code>kernel.xml</code> ourselves (with the <code>xilinx-xml</code> backend described above) and then use Vivado, via a Tcl script, to generate the IP-XACT file.</p>
<p>In the future, we could consider trying to route around using Vivado by generating the IP-XACT file ourselves, using a tool such as <a href="https://github.com/sifive/duh">DUH</a>.</p>
<h4 id="our-completion-workflow"><a class="header" href="#our-completion-workflow">Our Completion Workflow</a></h4>
<p>The first step is to produce an <code>.xo</code> file.
We also use <a href="https://github.com/cucapra/calyx/blob/master/fud/bitstream/gen_xo.tcl">a static Tcl script, <code>gen_xo.tcl</code>,</a> which is a simplified version of <a href="https://github.com/Xilinx/Vitis-Tutorials/blob/2021.1/Hardware_Acceleration/Feature_Tutorials/01-rtl_kernel_workflow/reference-files/scripts/package_kernel.tcl">a script from Xilinx's Vitis tutorials</a>.
The gist of this script is that it creates a Vivado project, adds the source files, twiddles some settings, and then uses the <a href="https://docs.xilinx.com/r/en-US/ug1393-vitis-application-acceleration/package_xo-Command"><code>package_xo</code> command</a> to read stuff from this project as an &quot;IP directory&quot; and produce an <code>.xo</code> file.
The Vivado command line looks roughly like this:</p>
<pre><code>vivado -mode batch -source gen_xo.tcl -tclargs xclbin/kernel.xo
</code></pre>
<p>That output filename after <code>-tclargs</code>, unsurprisingly, gets passed to <a href="https://github.com/cucapra/calyx/blob/master/fud/bitstream/gen_xo.tcl"><code>gen_xo.tcl</code></a>.</p>
<p>Then, we take this <code>.xo</code> and turn it into an <a href="https://xilinx.github.io/XRT/2021.2/html/formats.html#xclbin"><code>.xclbin</code></a>.
This step uses the <code>v++</code> tool, with a command line that looks like this:</p>
<pre><code>v++ -g -t hw_emu --platform xilinx_u50_gen3x16_xdma_201920_3 --save-temps --profile.data all:all:all --profile.exec all:all:all -lo xclbin/kernel.xclbin xclbin/kernel.xo
</code></pre>
<p>Fortunately, the <code>v++</code> tool doesn't need any Tcl to drive it; all the action happens on the command line.</p>
<h4 id="execution-via-xclrun"><a class="header" href="#execution-via-xclrun">Execution via <code>xclrun</code></a></h4>
<p>Now that we have an <code>.xclbin</code> file, we need a way to execute it (either in simulation or on a real FPGA).
We have a tool called <code>xclrun</code> that just executes a given <code>.xclbin</code> bitstream, supplying it with data in a fud-style JSON format and formatting the results in the same way.
In fact, it's possible to use it directly---it's invokable with <code>python -m fud.xclrun</code>.
However, it's somewhat annoying to use directly because you have to carefully set up your environment first---this setup stage appears to be unavoidable when using the Xilinx runtime libraries.
So an invocation of <code>xclrun</code> actually looks something like this:</p>
<pre><code>EMCONFIG_PATH=`pwd` XCL_EMULATION_MODE=hw_emu XRT_INI_PATH=`pwd`/xrt.ini \
    bash -c 'source /scratch/opt/Xilinx/Vitis/2020.2/settings64.sh ; source /scratch/opt/xilinx/xrt/setup.sh ; python3.9 -m fud.xclrun foo.xclbin examples/tutorial/data.json'
</code></pre>
<p>This monster of a command first sets three environment variables that XRT and the simulation process will need, and then it <code>source</code>s the relevant setup scripts before finally launching <code>xclrun</code>.
The two actual arguments to the tool are just the <code>.xclbin</code> executable itself and the JSON input data; the tool prints the output data to stdout by default.</p>
<p>fud's <code>execute</code> stage is just a big wrapper around launching <code>xclrun</code>.
It sets up the necessary input files and constructs a command line that looks much like the above example.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="axi-interface-generation"><a class="header" href="#axi-interface-generation">AXI Interface Generation</a></h1>
<p>Calyx currently generates a fairly complex AXI interface that can be daunting
to deal with if confronting for the first time.
The following is an overview of how the generation occurs
and how the output AXI interface behaves as of 2022-9-11.</p>
<p>In general, when <code>fud</code> is asked to create an <a href="https://xilinx.github.io/XRT/2021.2/html/formats.html#xclbin"><code>.xclbin</code> file</a> a <code>kernel.xml</code>,
<code>main.sv</code>, and <code>toplevel.v</code> are created as intermediate steps for <a href="https://github.com/cucapra/calyx/blob/master/docs/fud/xilinx.md">xilinx tools</a>
to properly work.</p>
<p><code>main.sv</code> contains the SystemVerilog needed for our computations to perform
correctly. It is implemented as an FSM that derives from the original Calyx program.
<a href="https://docs.xilinx.com/r/en-US/ug1393-vitis-application-acceleration/RTL-Kernel-XML-File"><code>kernel.xml</code></a> defines register maps and ports of our
toplevel xilinx tools needs. <code>toplevel.v</code> wraps our computation kernel and contains
the AXI interface for each memory defined in a Calyx program and corresponds to the standard Calux lowering process.</p>
<p>For more info on file generation see <a href="https://docs.calyxir.org/fud/xilinx.html?highlight=synthesis#how-it-works">how the Xilinx Toolchain works</a></p>
<h2 id="toplevel-1"><a class="header" href="#toplevel-1">Toplevel</a></h2>
<p>Our <a href="https://docs.calyxir.org/lang/attributes.html?highlight=toplevel#toplevel">toplevel</a> is generated through files in <code>src/backend/xilinx/</code>.</p>
<h3 id="axi-memory-controller"><a class="header" href="#axi-memory-controller">AXI memory controller</a></h3>
<p>Here, the <a href="https://docs.calyxir.org/lang/attributes.html?highlight=toplevel#toplevel">toplevel</a> component of a Calyx program is queried and
memories marked <a href="https://docs.calyxir.org/lang/attributes.html?highlight=external#external"><code>@external</code></a> are turned into AXI buses.
To note, separate AXI interfaces are created for each memory 
(meaning, there is no shared bus between memories). Each memory has its own
(single port) BRAM which writes data taken from an <code>mi_axi_RDATA</code> wire where <code>i</code> is the index of
the memory. Eventually the BRAMs are read and fed into the
computation kernel of <code>main.sv</code>, which outputs results directly into the relevant
memories as defined in the original Calyx program.
Address and data widths and sizes are determined from cell declerations.</p>
<blockquote>
<p>There is always the possiblity that something is hardcoded as a remnant
from previous versions of our AXI generation. If something is hardcoded where it shouldn't
be please open an <a href="https://github.com/cucapra/calyx/issues">issue</a>.</p>
</blockquote>
<p>AXI memory controllers are constructed as (full) <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Signal-Descriptions?lang=en">AXI4 managers</a> that lack a small amount
of functionality. For example, <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Transaction-Attributes/Access-permissions?lang=en">xPROT signals</a> are not currently supported.
Additionally, things like <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Single-Interface-Requirements/Transaction-structure/Address-structure?lang=en">bursting</a> are not currently supported, but should be
easy to implement due to the existing infrastructure and generation.</p>
<p>A list of current signals that are hardcoded follows:</p>
<ul>
<li><code>xLEN</code> is set to 0, corresponding to a burst length of 1.</li>
<li><code>xBURST</code> is set to 01, corresponding to INCR type of bursts.</li>
<li><code>xSIZE</code> is set to the width of the data we are using in bytes.</li>
<li><code>xPROT</code> is not generated, and is therefore not supported.</li>
<li><code>xLOCK</code> is not generated, defaulting to 0 (normal accesses).</li>
<li><code>xCACHE</code> is not generated, making accesses non-modifiable, non-bufferable.</li>
<li><code>xQOS</code> is not generated. See <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/AXI4-Additional-Signaling/QoS-signaling/QoS-interface-signals?lang=en">QoS signaling</a>.</li>
<li><code>xREGION</code> is not generated. See <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/AXI4-Additional-Signaling/Multiple-region-signaling/Additional-interface-signals?lang=en">Multiple region signaling</a>.</li>
<li>No <a href="https://developer.arm.com/documentation/ihi0022/e/AMBA-AXI3-and-AXI4-Protocol-Specification/Signal-Descriptions/Low-power-interface-signals?lang=en">low power signals</a> are generated.</li>
</ul>
<h3 id="subordinate-axi-control-controller"><a class="header" href="#subordinate-axi-control-controller">Subordinate AXI control controller</a></h3>
<p>In addition to our manager memory controllers, a subordinate controller for
our control module is also generated. This module is responsible for signaling
our computational kernel to start working, as well as calculating the correct
base addresses to use for our memory controllers. Things like address and
data widths are hard coded at the moment. It is suspected that this hardcoding
is okay for the types of programs we generate. But more work needs to be done to see
if our control structure works for arbitrary programs or needs to be changed to
allow this.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="external-stages"><a class="header" href="#external-stages">External Stages</a></h1>
<p><code>fud</code> supports using stages that aren't defined in its main source tree.
These are known as 'external stages' and the provide a mechanism
for projects using Calyx to take advantage of <code>fud</code>. You can register an
external stage with:</p>
<pre><code>fud register stage_name -p /path/to/stage.py
</code></pre>
<p>Once an external stage is registered, it behaves exactly like any other stage.</p>
<p>You can remove an external stage with:</p>
<pre><code>fud register stage_name --delete
</code></pre>
<p>The following defines a stage that transforms <a href="fud/../frontends/mrxl.html">MrXL</a> programs to Calyx
programs.</p>
<pre><code class="language-python">from fud.stages import Stage, SourceType, Source
from fud.utils import shell, TmpDir
from fud.errors import MissingDynamicConfiguration

from pathlib import Path

# The temporary filename used for converting mrxl.data to verilog.data
_DATA_FILE = &quot;data.json&quot;


class MrXLStage(Stage):
    &quot;&quot;&quot;
    Stage that invokes the MrXL frontend.
    &quot;&quot;&quot;

    name = &quot;mrxl&quot;

    def __init__(self):
        &quot;&quot;&quot;
        Initialize this stage. Initializing a stage *does not* construct its
        computation graph.
        &quot;&quot;&quot;
        super().__init__(
            src_state=&quot;mrxl&quot;,
            target_state=&quot;calyx&quot;,
            input_type=SourceType.Path,
            output_type=SourceType.Stream,
            description=&quot;Compiles MrXL to Calyx.&quot;,
        )

    @staticmethod
    def pre_install():
        pass

    @staticmethod
    def defaults():
        &quot;&quot;&quot;
        Specify defaults that should be added to fud's configuration file when
        this stage is registered.
        &quot;&quot;&quot;
        return {&quot;exec&quot;: &quot;mrxl&quot;, &quot;flags&quot;: &quot;&quot;}

    def _define_steps(self, input, builder, config):
        &quot;&quot;&quot;
        Define the steps that will execute in this stage. Each step represents
        a delayed computation that will occur when the stage is executed.
        &quot;&quot;&quot;

        # Commands at the top-level are evaluated when the computation is being
        # staged
        cmd = config[&quot;stages&quot;, self.name, &quot;exec&quot;]
        flags = config.get((&quot;stages&quot;, self.name, &quot;flags&quot;)) or &quot;&quot;

        # Computations within a step are delayed from being executed until
        # the full execution pipeline is generated.
        @builder.step()
        def mktmp() -&gt; SourceType.Directory:
            &quot;&quot;&quot;
            Make temporary directory to store Verilator build files.
            &quot;&quot;&quot;
            return TmpDir()

        @builder.step(description=&quot;Set stages.mrxl.prog as `input`&quot;)
        def set_mrxl_prog(mrxl_prog: SourceType.Path):
            config[&quot;stages&quot;, &quot;mrxl&quot;, &quot;prog&quot;] = str(mrxl_prog)

        @builder.step(
            description=&quot;Save verilog.data in `tmpdir` and update stages.verilog.data&quot;
        )
        def save_data(tmpdir: SourceType.Directory, verilog_data: SourceType.String):
            save_loc = Path(tmpdir.name) / _DATA_FILE

            with open(save_loc, &quot;w&quot;) as out:
                out.write(verilog_data)

            config[&quot;stages&quot;, &quot;verilog&quot;, &quot;data&quot;] = save_loc

        @builder.step(description=cmd)
        def run_mrxl(mrxl_prog: SourceType.Path) -&gt; SourceType.Stream:
            return shell(f&quot;{cmd} {str(mrxl_prog)} {flags}&quot;)

        # Define a schedule using the steps.
        # A schedule *looks* like an imperative program but actually represents
        # a computation graph that is executed later on.
        mrxl_data = config.get([&quot;stages&quot;, &quot;mrxl&quot;, &quot;data&quot;])

        if mrxl_data is not None:
            tmpdir = mktmp()

            set_mrxl_prog(input)
            mrxl_data_stage = MrXLDataStage()
            mrxl_data_stage_input = Source.path(mrxl_data)

            builder.ctx.append(&quot;mrxl-data&quot;)
            verilog_data = builder.also_do(
                mrxl_data_stage_input, mrxl_data_stage, config
            )
            builder.ctx.pop()
            verilog_data = builder.convert_source_to(verilog_data, SourceType.String)

            save_data(tmpdir, verilog_data)
        return run_mrxl(input)


class MrXLDataStage(Stage):
    &quot;&quot;&quot;
    Stage that invokes the MrXL data converter.
    &quot;&quot;&quot;

    name = &quot;mrxl-data&quot;

    def __init__(self):
        &quot;&quot;&quot;
        Initialize this stage. Initializing a stage *does not* construct its
        computation graph.
        &quot;&quot;&quot;
        super().__init__(
            src_state=&quot;mrxl-data&quot;,
            target_state=&quot;verilog-data&quot;,
            input_type=SourceType.Path,
            output_type=SourceType.Stream,
            description=&quot;Compiles MrXL-native input to Calyx-native input.&quot;,
        )

    @staticmethod
    def pre_install():
        pass

    @staticmethod
    def defaults():
        &quot;&quot;&quot;
        Specify defaults that should be added to fud's configuration file when
        this stage is registered.
        &quot;&quot;&quot;
        return {}

    def _define_steps(self, input, builder, config):
        &quot;&quot;&quot;
        Define the steps that will execute in this stage. Each step represents
        a delayed computation that will occur when the stage is executed.
        &quot;&quot;&quot;

        # Commands at the top-level are evaluated when the computation is being
        # staged
        cmd = config[&quot;stages&quot;, &quot;mrxl&quot;, &quot;exec&quot;]

        # Computations within a step are delayed from being executed until
        # the full execution pipeline is generated.
        @builder.step(description=&quot;Dynamically retrieve the value of stages.mrxl.prog&quot;)
        def get_mrxl_prog() -&gt; SourceType.Path:
            return Source(Path(config.get([&quot;stages&quot;, &quot;mrxl&quot;, &quot;prog&quot;])), SourceType.Path)

        @builder.step()
        def convert_mrxl_data_to_calyx_data(
            data_path: SourceType.Path, mrxl_prog: SourceType.Path
        ) -&gt; SourceType.Stream:
            &quot;&quot;&quot;
            Converts MrXL input into calyx input
            &quot;&quot;&quot;
            return shell(f&quot;{cmd} {str(mrxl_prog.data)} --data {data_path} --convert&quot;)

        # Define a schedule using the steps.
        # A schedule *looks* like an imperative program but actually represents
        # a computation graph that is executed later on.

        mrxl_prog = get_mrxl_prog()

        if mrxl_prog is None:
            raise MissingDynamicConfiguration(&quot;mrxl.prog&quot;)
        return convert_mrxl_data_to_calyx_data(input, mrxl_prog)


# Export the defined stages to fud
__STAGES__ = [MrXLStage, MrXLDataStage]
</code></pre>
<p>External stages <em>must</em> define default values for configuration keys using the
<code>Stage.defaults()</code> static method and the name of the stage using the static
<code>name</code> field.</p>
<h2 id="stage-configuration"><a class="header" href="#stage-configuration">Stage Configuration</a></h2>
<p>Like normal stages, external stages can have persistent configuration
information saved using <code>fud config</code>.</p>
<p>To add persistent stage configuration, run:</p>
<pre><code>fud config stages.&lt;stage-name&gt;.&lt;key&gt; &lt;value&gt;
</code></pre>
<p>To dynamically override the value of a field during execution, use the <code>-s flag</code>:</p>
<pre><code>fud e -s &lt;stage-name&gt;.&lt;key&gt; &lt;value&gt; ...
</code></pre>
<p>The override order for stage configuration is:</p>
<ol>
<li>Dynamic values provided by <code>-s</code>.</li>
<li>Configuration value in the fud config.</li>
<li>Default value provided by <code>Stage.defaults()</code></li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="multiple-paths"><a class="header" href="#multiple-paths">Multiple Paths</a></h1>
<p><code>fud</code> can define a stage graph that can have multiple paths between the source
and target.
For example, if you register the <a href="fud/./index.html#icarus-verilog">Icarus Verilog</a> simulator stage, then multiple
paths can be used to generate VCD files from Dahlia programs:</p>
<pre><code>% fud e --from dahlia --to vcd
[fud] ERROR: Multiple stage pipelines can transform dahlia to vcd:
dahlia → calyx → verilog → vcd
dahlia → calyx → icarus-verilog → vcd
Use the --through flag to select an intermediate stage
</code></pre>
<p><code>fud</code> says that both the <code>verilog</code> and <code>icarus-verilog</code> stages can be used to
generate the VCD file and you need to provide the <code>--through</code> flag to decide
which stage to select.</p>
<p>The following command will simulate the program using the <code>icarus-verilog</code>
stage:</p>
<pre><code>% fud e --from dahlia --to vcd --through icarus-verilog
</code></pre>
<p>In general, the <code>--through</code> flag can be repeated as many times as needed to
get a unique <code>fud</code> transformation pipeline.</p>
<h2 id="using-stage-priority"><a class="header" href="#using-stage-priority">Using Stage Priority</a></h2>
<p>If the common workflow uses the same stage every time, it can be annoying to
specify the stage name using the <code>--through</code> flag.
You can specify a priority field in the configuration of a stage to ensure
it <code>fud</code> automatically selects it when multiple paths exists.</p>
<p>For example, to always select the <code>verilog</code> stage, add the priority <code>1</code> to the
stage:</p>
<pre><code>fud c stages.verilog.priority 1
</code></pre>
<p>Now, the command <code>fud e --from dahlia --to vcd</code> is no longer ambiguous; <code>fud</code>
will always choose the <code>verilog</code> stage to transform programs from Dahlia
sources to VCD.</p>
<p>In case multiple paths have the same cost, <code>fud</code> will again require the
<code>--through</code> flag to disambiguate paths.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="circt"><a class="header" href="#circt">CIRCT</a></h1>
<p>An ongoing effort is under way to establish Calyx as a dialect in the LLVM umbrella project <a href="https://circt.llvm.org/">CIRCT</a>.
There is documentation about the Calyx dialect <a href="https://circt.llvm.org/docs/Dialects/Calyx/">on the MLIR site</a>. While semantically
equivalent, they are syntactically different.  Because the Calyx dialect is still under progress and
does not include all the optimizations that the native Rust compiler supports, we have crafted an emitter
from the Calyx dialect (MLIR) to the native compiler representation (used by the Rust compiler). This means
you can lower from your favorite frontend in MLIR to the Calyx dialect, and continue all the way to
SystemVerilog (with spunky optimizations) using the native compiler.</p>
<p>The native compiler also supports round-tripping back into the MLIR representation. We'll assume you've
already built the Rust compiler and installed <code>fud</code>. Here are the steps below to round-trip:</p>
<h2 id="mlir-to-native-representation"><a class="header" href="#mlir-to-native-representation">MLIR to Native Representation</a></h2>
<ol>
<li>
<p>Set up the CIRCT project with <a href="https://github.com/llvm/circt#setting-this-up">these instructions</a>.</p>
</li>
<li>
<p>There should be a <code>circt-translate</code> binary in <code>&lt;root-directory&gt;/build/bin</code>. To emit the native compiler
representation, use the command:</p>
</li>
</ol>
<pre><code>path/to/circt-translate --export-calyx /path/to/file
</code></pre>
<p>For example, you can use the expected output of the test <code>tests/backend/mlir/simple.expect</code>:</p>
<pre><code>calyx.program &quot;main&quot; {

calyx.component @main(%go: i1 {go=1}, %clk: i1 {clk=1}, %reset: i1 {reset=1}) -&gt; (%out: i1, %done: i1 {done=1}) {
  %r1.in, %r1.write_en, %r1.clk, %r1.reset, %r1.out, %r1.done = calyx.register @r1 : i1, i1, i1, i1, i1, i1
  %_1_1.out = hw.constant 1 : i1
  calyx.wires {
    calyx.group @Group1 {
      calyx.assign %r1.in = %_1_1.out : i1
      calyx.assign %r1.write_en = %_1_1.out : i1
      calyx.group_done %r1.done : i1
    }
  }

  calyx.control {
    calyx.seq {
      calyx.enable @Group1
    }
  }
}

}
</code></pre>
<p>Using the command:</p>
<pre><code class="language-bash"># Don't worry too much about the file alias; this is used for testing purposes.
path/to/circt-translate --export-calyx tests/backend/mlir/simple.expect
</code></pre>
<p>This should output:</p>
<pre><code>// -p well-formed -b mlir
import &quot;primitives/core.futil&quot;;
component main(@go go: 1, @clk clk: 1, @reset reset: 1) -&gt; (out: 1, @done done: 1) {
  cells {
    r1 = std_reg(1);
  }
  wires {
    group Group1 {
      r1.in = 1'd1;
      r1.write_en = 1'd1;
      Group1[done] = r1.done;
    }
  }
  control {
    seq { Group1; }
  }
}
</code></pre>
<h2 id="native-representation-to-mlir"><a class="header" href="#native-representation-to-mlir">Native Representation to MLIR</a></h2>
<p>To round-trip back to the Calyx dialect, we can use <code>fud</code>:</p>
<pre><code class="language-sh">fud exec path/to/file --to mlir
</code></pre>
<p>For example,</p>
<pre><code class="language-sh">fud exec tests/backend/mlir/simple.futil --to mlir
</code></pre>
<p>This should emit the Calyx dialect once again.</p>
<h2 id="using-native-tools-with-mlir-generated-calyx"><a class="header" href="#using-native-tools-with-mlir-generated-calyx">Using Native Tools with MLIR-Generated Calyx</a></h2>
<p>The native infrastructure, such as <a href="fud/../fud"><code>fud</code></a>, <a href="fud/../interpreter.html">the calyx debugger</a>, our <a href="fud/../fud/xilinx.html#synthesis-only">synthesis scripts</a>, and the <a href="fud/../fud/axi-gen.html">AXI generator</a> all make certain assumptions that are violated by MLIR-generated code.
Specifically, the tools often require that:</p>
<ol>
<li>The interface memories are marked with the <a href="fud/../lang/attributes.html#external"><code>@external</code></a> attribute. This allows our testbench to generate the code needed by <a href="fud/../fud"><code>fud</code></a> to simulate designs with the convenient data format. It is also used by the <a href="fud/../fud/axi-gen.html">AXI generator</a> to generate AXI interfaces for memories.</li>
<li>The <code>toplevel</code> component is named <code>main</code>. This is used by the <a href="fud/../fud/xilinx.html#synthesis-only">synthesis scripts</a> to generate resource usage numbers and the test bench to simulate the design.</li>
</ol>
<p>While we're working on addressing these problems directly, in the meantime, if you'd like to use the native tools with MLIR-generated code, you can use the following two passes:</p>
<ol>
<li><code>discover-external</code> which transforms MLIR's representation of interface memories into <code>@external</code> memories.</li>
<li><code>wrap-main</code> which adds a <code>main</code> component to the program and makes it the entrypoint component. This pass is enabled by default.</li>
</ol>
<p>An example invocation of these passes is:</p>
<pre><code class="language-sh">calyx &lt;file&gt; -p validate -p discover-external -p all -x discover-external:default=4
</code></pre>
<p>The <code>-p discover-external</code> flag enables the pass to transform ports into interface memories. Unfortunately, this process is not fully automatic.
For example, it is not possible for the pass to infer the size of your memories by just looking at the signals provided to the top-level component.
We provide <code>-x discover-external:default=&lt;size&gt;</code> which tells the pass that when you cannot infer the size parameter of a memory, use <code>&lt;size&gt;</code> as the default.
A limitation of this approach is that the pass does not support discovering interface memories with different sizes.
If you desperately need this, please <a href="https://github.com/cucapra/calyx/issues/new">open an issue</a>, and we'll try to prioritize it.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="resource-estimation-backend"><a class="header" href="#resource-estimation-backend">Resource Estimation Backend</a></h1>
<p>The resources estimation backend aims to provide a size estimation for the hardware that Calyx generates. Currently, it only supports estimation for <code>std_reg</code>, <code>std_mem_*</code>, and <code>seq_mem_*</code> primitives, but more primitives will be added.</p>
<h2 id="running-the-resource-estimation-backend"><a class="header" href="#running-the-resource-estimation-backend">Running the resource estimation backend</a></h2>
<ol>
<li>Run <code>cargo build</code> if you haven't built the compiler already.</li>
<li>Run <code>fud e path/to/futil.file --to resources</code>. This should tally up the primitives used in the program and output a CSV with the number of instantiated primitives according to their attributes.</li>
</ol>
<p>To output the CSV to a file, you can use <code>-o myfile.csv</code>.
If you would like to see an English summary of the CSV as well as the estimated size of the hardware (counting only the supported primitives), add the verbose flag <code>-vv</code> to your <code>fud</code> command.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-calyx-interpreter"><a class="header" href="#the-calyx-interpreter">The Calyx Interpreter</a></h1>
<p>The experimental Calyx interpreter resides in the <code>interp/</code> directory of the
repository.
The interpreter supports all Calyx programs—from high-level programs that
make heavy use of control operators, to fully lowered Calyx programs.
(RTL simulation, in contrast, only supports execution of fully lowered programs.)</p>
<p>There are two ways to use the interpreter: you can directly invoke it, or you can use <a href="fud/index.html">fud</a>.</p>
<h2 id="basic-use"><a class="header" href="#basic-use">Basic Use</a></h2>
<p>To run an example program, try:</p>
<pre><code>cd interp &amp;&amp; cargo run tests/control/if.futil
</code></pre>
<p>You can see the available command-line options by typing <code>cargo run -- --help</code>.</p>
<h2 id="interpreting-via-fud"><a class="header" href="#interpreting-via-fud">Interpreting via fud</a></h2>
<p>The interpreter is available as a stage in <a href="fud/index.html">fud</a>, which lets you provide standard JSON data files as input and easily execute passes on the input Calyx program before interpretation.</p>
<p>You'll want to build the interpreter first:</p>
<pre><code>cd interp &amp;&amp; cargo build
</code></pre>
<p>Here's how to run a Calyx program:</p>
<pre><code>fud e --to interpreter-out interp/tests/control/if.futil
</code></pre>
<p>To provide input data, set the <code>verilog.data</code> variable, like so:</p>
<pre><code>fud e --to interpreter-out \
    -s verilog.data tests/correctness/while.futil.data \
    tests/correctness/while.futil
</code></pre>
<p>By default, fud will not transform the Calyx code before feeding it to the interpreter.
To run passes before the interpreter, use the <code>calyx.flags</code> variable in conjunction with the <code>-p</code> flag.
For example, to fully lower the Calyx program before interpreting it:</p>
<pre><code>fud e --to interpreter-out \
    -s calyx.flags '-p all' \
    interp/tests/control/if.futil
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-calyx-compiler"><a class="header" href="#the-calyx-compiler">The Calyx Compiler</a></h1>
<p>The Calyx compiler has several command line options to control the execution of
various passes and backends.</p>
<h2 id="controlling-passes"><a class="header" href="#controlling-passes">Controlling Passes</a></h2>
<p>The compiler is organized as a sequence of passes that are run when the compiler
executes.
To get a complete list of all passes, run the following from the repository
root:</p>
<pre><code>cargo run -- --list-passes
</code></pre>
<p>This generates results of the form:</p>
<pre><code>Passes:
- collapse-control: &lt;description&gt;
- compile-control: &lt;description&gt;
...

Aliases:
- all: well-formed, papercut, remove-external-memories, ...
...
</code></pre>
<p>The first section lists all the passes implemented in the compiler.
The second section lists <em>aliases</em> for combinations of passes that are commonly
run together.
For example, the alias <code>all</code> is an ordered sequence of default passes executed
when the compiler is run from the command-line.</p>
<p>The command-line provides two options to control the execution of passes:</p>
<ul>
<li><code>-p, --pass</code>: Execute this pass or alias. Overrides default alias.</li>
<li><code>-d, --disable-pass</code>: Disable this pass or alias. Takes priority over <code>-p</code>.</li>
</ul>
<p>For example, we can run the following to disable the <code>static-timing</code> pass from
the default execution alias <code>all</code>:</p>
<pre><code class="language-bash">cargo run -- examples/futil/simple.futil -p all -d static-timing
</code></pre>
<h2 id="providing-pass-options"><a class="header" href="#providing-pass-options">Providing Pass Options</a></h2>
<p>Some passes take options to control their behavior. The <code>--list-passes</code> command prints out the options for each pass. For example, the <code>tdcc</code> pass has the following options:</p>
<pre><code>tdcc: &lt;description&gt;
  * dump-fsm: Print out the state machine implementing the schedule
</code></pre>
<p>The option allows us to change the behavior of the pass. To provide a pass-specific option, we use the <code>-x</code> switch:</p>
<pre><code>cargo run -- examples/futil/simple.futil -p tdcc -x tdcc:dump-fsm
</code></pre>
<p>Note that we specify the option of <code>tdcc</code> by prefixing it with the pass name and a colon.</p>
<h2 id="specifying-primitives-library"><a class="header" href="#specifying-primitives-library">Specifying Primitives Library</a></h2>
<p>The compiler implementation uses a standard library of components to compile
programs.
The only standard library for the compiler is located in:</p>
<pre><code>&lt;path to Calyx repository&gt;/primitives
</code></pre>
<p>Specify the location of the library using the <code>-l</code> flag:</p>
<pre><code>cargo run -- -l ./primitives
</code></pre>
<h2 id="primitive-libraries-format"><a class="header" href="#primitive-libraries-format">Primitive Libraries Format</a></h2>
<p>The primitive libraries consist of a <code>.futil</code> file paired with a <code>.sv</code> file. The
<code>.futil</code> file defines a series of Calyx shim bindings in <code>extern</code> blocks which
match up with SystemVerilog definitions of those primitives. These libraries may
also expose components written in Calyx, usually defined using primitives
exposed by the file.</p>
<p>No Calyx program can work without the primitives defined in the <a href="libraries/core.html">Core Library</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="adding-a-new-pass"><a class="header" href="#adding-a-new-pass">Adding a New Pass</a></h1>
<p>All passes in the compiler are stored in the <code>calyx/src/passes</code> directory.
To add a new pass, we need to do a couple of things:</p>
<ol>
<li>Define a pass struct and implement the required traits.</li>
<li>Expose the pass using in the <code>passes</code> module.</li>
<li>Register the pass in the compiler.</li>
</ol>
<blockquote>
<p>It is possible to add passes outside the compiler tree, but we haven't needed to do this yet, so we will not cover it here.</p>
</blockquote>
<h2 id="defining-a-pass-struct"><a class="header" href="#defining-a-pass-struct">Defining a Pass Struct</a></h2>
<p>We first define a <a href="https://doc.rust-lang.org/book/ch05-01-defining-structs.html">Rust structure</a> that will manage the state of the pass:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pub struct NewPass;
<span class="boring">}</span></code></pre></pre>
<p>A pass needs to implement the <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/traversal/trait.Named.html"><code>Named</code></a> and <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/traversal/trait.Visitor.html"><code>Visitor</code></a> traits.
The former defines the name, description, and <a href="./compiler.html#providing-pass-options">pass-specific options</a> of the pass.</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>impl Named for NewPass {
    fn name(&amp;self) -&gt; &amp;'static str { &quot;new-pass&quot; }
    ...
}
impl Visitor for NewPass { ... }
<span class="boring">}</span></code></pre></pre>
<p>The pass name provided in used in the compiler's driver and needs to be unique for each registered pass.</p>
<h2 id="the-visitor-trait"><a class="header" href="#the-visitor-trait">The Visitor Trait</a></h2>
<p>The visitor trait allows us to define the behavior of the pass.
The visitor visits each <a href="./lang/ref.html#the-control-operators">control operator</a> in each component and performs some action.
Furthermore, it also allows us to control the order in which components are visited.</p>
<h3 id="component-iteration-order"><a class="header" href="#component-iteration-order">Component Iteration Order</a></h3>
<p>The <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/traversal/enum.Order.html"><code>Order</code></a> struct allows us to control the order in which components are visited:</p>
<ul>
<li><code>Post</code>: Iterate the subcomponents of a component before the component itself.</li>
<li><code>Pre</code>: Iterate the subcomponents of a component after the component itself.</li>
<li><code>No</code>: Iterate the components in any order.</li>
</ul>
<h3 id="visiting-components"><a class="header" href="#visiting-components">Visiting Components</a></h3>
<p>Most passes will attempt to transform the structural part of the program (<code>wires</code> or <code>cells</code>), the <code>control</code> schedule, or both.
The <code>Visitor</code> trait is flexible enough to allow all of these patterns and efficiently traverse the program.</p>
<p>For a control program like this:</p>
<pre><code>seq {
    one;
    if cond { two } else { three }
    invoke foo(..)
}
</code></pre>
<p>The following sequence of <code>Visitor</code> methods are called:</p>
<pre><code>- start
- start_seq
  - enable       // group one
  - start_if
    - enable     // group two
    - enable     // group three
  - end_if
  - invoke       // invocation
- finish_seq
- finish
</code></pre>
<p>Each non-leaf control operator defines both a <code>start_*</code> and <code>finish_*</code> method which allows us to encode top-down and bottom-up traversal patterns.</p>
<p>Each method returns an <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/traversal/enum.Action.html"><code>Action</code></a> value which allows us to control the traversal of the program.
For example, <code>Action::Stop</code> will immediately stop the traversal of the program while <code>Action::SkipChildren</code> will skip the traversal of the children of the current control operator.</p>
<h2 id="registering-the-pass"><a class="header" href="#registering-the-pass">Registering the Pass</a></h2>
<p>The final step is to register the pass in the compiler.
We use the <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/pass_manager/struct.PassManager.html"><code>PassManager</code></a> to register the pass defined in the <code>default_passes.rs</code> file.</p>
<p>Registering a pass is as simple as calling the register pass:</p>
<pre><pre class="playground"><code class="language-rust"><span class="boring">#![allow(unused)]
</span><span class="boring">fn main() {
</span>pm.register_pass::&lt;NewPass&gt;();
<span class="boring">}</span></code></pre></pre>
<p>Once done, the pass is accessible from the command line:</p>
<pre><code class="language-bash">cargo run -- -p new-pass &lt;file&gt;
</code></pre>
<p>This will run <code>-p new-pass</code> on the input file.
In order to run this pass in the default pipeline, we need to add it to the <code>all</code> alias (which is called when no <code>-p</code> option is provided).
The <code>all</code> alias is itself defined using other aliases which separate the pipeline into different phases.
For example, if <code>NewPass</code> needs to run before the compilation passes, we can add it to the <code>pre-opt</code> alias.</p>
<h2 id="some-useful-links"><a class="header" href="#some-useful-links">Some Useful Links</a></h2>
<p>The compiler has a ton of shared infrastructure that can be useful:</p>
<ul>
<li><a href="https://docs.rs/calyx-ir/latest/calyx_ir/struct.Context.html"><code>ir::Context</code></a>: The top-level data structure that holds a complete Calyx program.</li>
<li><a href="https://docs.rs/calyx-ir/latest/calyx_ir/rewriter/index.html">Rewriter</a>: Helps with consistent renaming of ports, cells, groups, and comb groups in a component.</li>
<li><a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/analysis/index.html"><code>analysis</code></a>: Provides a number of useful analysis that can be used within a pass.</li>
<li>IR macros: Macros useful for adding cells (<a href="https://docs.rs/calyx-ir/latest/calyx_ir/macro.structure.html"><code>structure!</code></a>), guards (<a href="https://docs.rs/calyx-ir/latest/calyx_ir/macro.guard.html"><code>guard!</code></a>) and assignments (<a href="https://docs.rs/calyx-ir/latest/calyx_ir/macro.build_assignments.html"><code>build_assignments!</code></a>) to component.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="core-library"><a class="header" href="#core-library">Core Library</a></h1>
<p>This library defines a standard set of components used in most Calyx programs
such as registers and basic bitwise operations.</p>
<h2 id="contents"><a class="header" href="#contents">Contents</a></h2>
<ul>
<li><a href="libraries/core.html#numerical-operators">Numerical Operators</a></li>
<li><a href="libraries/core.html#logical-operators">Logical Operators</a></li>
<li><a href="libraries/core.html#comparison-operators">Comparison Operators</a></li>
<li><a href="libraries/core.html#memories">Memories</a></li>
</ul>
<hr />
<h2 id="numerical-operators"><a class="header" href="#numerical-operators">Numerical Operators</a></h2>
<h3 id="std_regwidth"><a class="header" href="#std_regwidth"><code>std_reg&lt;WIDTH&gt;</code></a></h3>
<p>A <code>WIDTH</code>-wide register.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>in: WIDTH</code> - An input value to the register <code>WIDTH</code>-bits.</li>
<li><code>write_en: 1</code> - The one bit write enabled signal. Indicates that the register
should store the value on the <code>in</code> wire.</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The value contained in the register.</li>
<li><code>done: 1</code> - The register's done signal. Set high for one cycle after writing a
new value.</li>
</ul>
<hr />
<h3 id="std_constwidthval"><a class="header" href="#std_constwidthval"><code>std_const&lt;WIDTH,VAL&gt;</code></a></h3>
<p>A constant WIDTH-bit value with value VAL.</p>
<p><strong>Inputs:</strong> None</p>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The value of the constant (i.e. <code>VAL</code>)</li>
</ul>
<hr />
<h3 id="std_lshwidth"><a class="header" href="#std_lshwidth"><code>std_lsh&lt;WIDTH&gt;</code></a></h3>
<p>A left bit shift. Performs <code>left &lt;&lt; right</code>. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit value to be shifted</li>
<li><code>right: WIDTH</code> - A WIDTH-bit value representing the shift amount</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - A WIDTH-bit value equivalent to <code>left &lt;&lt; right</code></li>
</ul>
<hr />
<h3 id="std_rshwidth"><a class="header" href="#std_rshwidth"><code>std_rsh&lt;WIDTH&gt;</code></a></h3>
<p>A right bit shift. Performs <code>left &gt;&gt; right</code>. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit value to be shifted</li>
<li><code>right: WIDTH</code> - A WIDTH-bit value representing the shift amount</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - A WIDTH-bit value equivalent to <code>left &gt;&gt; right</code></li>
</ul>
<hr />
<h3 id="std_addwidth"><a class="header" href="#std_addwidth"><code>std_add&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise addition without a carry flag. Performs <code>left + right</code>. This component
is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit value</li>
<li><code>right: WIDTH</code> - A WIDTH-bit value</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - A WIDTH-bit value equivalent to <code>left + right</code></li>
</ul>
<hr />
<h3 id="std_subwidth"><a class="header" href="#std_subwidth"><code>std_sub&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise subtraction. Performs <code>left - right</code>. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit value</li>
<li><code>right: WIDTH</code> - A WIDTH-bit value</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - A WIDTH-bit value equivalent to <code>left - right</code></li>
</ul>
<hr />
<h3 id="std_slicein_width-out_width"><a class="header" href="#std_slicein_width-out_width"><code>std_slice&lt;IN_WIDTH, OUT_WIDTH&gt;</code></a></h3>
<p>Slice out the lower OUT_WIDTH bits of an IN_WIDTH-bit value. Computes
<code>in[OUT_WIDTH - 1 : 0]</code>. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>in: IN_WIDTH</code> - An IN_WIDTH-bit value</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: OUT_WIDTH</code> - The lower OUT_WIDTH bits of <code>in</code></li>
</ul>
<hr />
<h3 id="std_padin_width-out_width"><a class="header" href="#std_padin_width-out_width"><code>std_pad&lt;IN_WIDTH, OUT_WIDTH&gt;</code></a></h3>
<p>Given an IN_WIDTH-bit input, zero pad from the left to an output of
OUT_WIDTH-bits. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>in: IN_WIDTH</code> - An IN_WIDTH-bit value to be padded</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: OUT_WIDTH</code> - The padded value</li>
</ul>
<hr />
<h2 id="logical-operators"><a class="header" href="#logical-operators">Logical Operators</a></h2>
<h3 id="std_notwidth"><a class="header" href="#std_notwidth"><code>std_not&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise NOT. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>in: WIDTH</code> - A WIDTH-bit input.</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The bitwise NOT of the input (<code>~in</code>)</li>
</ul>
<hr />
<h3 id="std_andwidth"><a class="header" href="#std_andwidth"><code>std_and&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise AND. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The bitwise AND of the arguments (<code>left &amp; right</code>)</li>
</ul>
<hr />
<h3 id="std_orwidth"><a class="header" href="#std_orwidth"><code>std_or&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise OR. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The bitwise OR of the arguments (<code>left | right</code>)</li>
</ul>
<hr />
<h3 id="std_xorwidth"><a class="header" href="#std_xorwidth"><code>std_xor&lt;WIDTH&gt;</code></a></h3>
<p>Bitwise XOR. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: WIDTH</code> - The bitwise XOR of the arguments (<code>left ^ right</code>)</li>
</ul>
<hr />
<h2 id="comparison-operators"><a class="header" href="#comparison-operators">Comparison Operators</a></h2>
<h3 id="std_gtwidth"><a class="header" href="#std_gtwidth"><code>std_gt&lt;WIDTH&gt;</code></a></h3>
<p>Greater than. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left &gt; right</code> else 0.</li>
</ul>
<hr />
<h3 id="std_ltwidth"><a class="header" href="#std_ltwidth"><code>std_lt&lt;WIDTH&gt;</code></a></h3>
<p>Less than. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left &lt; right</code> else 0.</li>
</ul>
<hr />
<h3 id="std_eqwidth"><a class="header" href="#std_eqwidth"><code>std_eq&lt;WIDTH&gt;</code></a></h3>
<p>Equality comparison. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left = right</code> else 0.</li>
</ul>
<hr />
<h3 id="std_neqwidth"><a class="header" href="#std_neqwidth"><code>std_neq&lt;WIDTH&gt;</code></a></h3>
<p>Not equal. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left != right</code> else 0.</li>
</ul>
<hr />
<h3 id="std_gewidth"><a class="header" href="#std_gewidth"><code>std_ge&lt;WIDTH&gt;</code></a></h3>
<p>Greater than or equal. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left &gt;= right</code> else 0.</li>
</ul>
<hr />
<h3 id="std_lewidth"><a class="header" href="#std_lewidth"><code>std_le&lt;WIDTH&gt;</code></a></h3>
<p>Less than or equal. This component is combinational.</p>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>left: WIDTH</code> - A WIDTH-bit argument</li>
<li><code>right: WIDTH</code> - A WIDTH-bit argument</li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>out: 1</code> - A single bit output. 1 if <code>left &lt;= right</code> else 0.</li>
</ul>
<hr />
<h2 id="memories"><a class="header" href="#memories">Memories</a></h2>
<h3 id="std_mem_d1"><a class="header" href="#std_mem_d1"><code>std_mem_d1</code></a></h3>
<p>A one-dimensional memory.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>WIDTH</code> - Size of an individual memory slot.</li>
<li><code>SIZE</code> - Number of slots in the memory.</li>
<li><code>IDX_SIZE</code> - The width of the index given to the memory.</li>
</ul>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>addr0: IDX_SIZE</code> - The index to be accessed or updated</li>
<li><code>write_data: WIDTH</code> - Data to be written to the selected memory slot</li>
<li><code>write_en: 1</code> - One bit write enabled signal, causes the memory to write <code>write_data</code> to the slot indexed by <code>addr0</code></li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>read_data: WIDTH</code> - The value stored at <code>addr0</code>. This value is combinational with respect to <code>addr0</code>.</li>
<li><code>done: 1</code>: The done signal for the memory. This signal goes high for one cycle after finishing a write to the memory.</li>
</ul>
<hr />
<h3 id="std_mem_d2"><a class="header" href="#std_mem_d2"><code>std_mem_d2</code></a></h3>
<p>A two-dimensional memory.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>WIDTH</code> - Size of an individual memory slot.</li>
<li><code>D0_SIZE</code> - Number of memory slots for the first index.</li>
<li><code>D1_SIZE</code> - Number of memory slots for the second index.</li>
<li><code>D0_IDX_SIZE</code> - The width of the first index.</li>
<li><code>D1_IDX_SIZE</code> - The width of the second index.</li>
</ul>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>addr0: D0_IDX_SIZE</code> - The first index into the memory</li>
<li><code>addr1: D1_IDX_SIZE</code> - The second index into the memory</li>
<li><code>write_data: WIDTH</code> - Data to be written to the selected memory slot</li>
<li><code>write_en: 1</code> - One bit write enabled signal, causes the memory to write <code>write_data</code> to the slot indexed by <code>addr0</code> and <code>addr1</code></li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>read_data: WIDTH</code> - The value stored at <code>mem[addr0][addr1]</code>. This value is combinational with respect to <code>addr0</code> and <code>addr1</code>.</li>
<li><code>done: 1</code>: The done signal for the memory. This signal goes high for one cycle after finishing a write to the memory.</li>
</ul>
<hr />
<h3 id="std_mem_d3"><a class="header" href="#std_mem_d3"><code>std_mem_d3</code></a></h3>
<p>A three-dimensional memory.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>WIDTH</code> - Size of an individual memory slot.</li>
<li><code>D0_SIZE</code> - Number of memory slots for the first index.</li>
<li><code>D1_SIZE</code> - Number of memory slots for the second index.</li>
<li><code>D2_SIZE</code> - Number of memory slots for the third index.</li>
<li><code>D0_IDX_SIZE</code> - The width of the first index.</li>
<li><code>D1_IDX_SIZE</code> - The width of the second index.</li>
<li><code>D2_IDX_SIZE</code> - The width of the third index.</li>
</ul>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>addr0: D0_IDX_SIZE</code> - The first index into the memory</li>
<li><code>addr1: D1_IDX_SIZE</code> - The second index into the memory</li>
<li><code>addr2: D2_IDX_SIZE</code> - The third index into the memory</li>
<li><code>write_data: WIDTH</code> - Data to be written to the selected memory slot</li>
<li><code>write_en: 1</code> - One bit write enabled signal, causes the memory to write <code>write_data</code> to the slot indexed by <code>addr0</code>, <code>addr1</code>, and <code>addr2</code></li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>read_data: WIDTH</code> - The value stored at <code>mem[addr0][addr1][addr2]</code>. This value is combinational with respect to <code>addr0</code>, <code>addr1</code>, and <code>addr2</code>.</li>
<li><code>done: 1</code>: The done signal for the memory. This signal goes high for one cycle after finishing a write to the memory.</li>
</ul>
<hr />
<h3 id="std_mem_d4"><a class="header" href="#std_mem_d4"><code>std_mem_d4</code></a></h3>
<p>A four-dimensional memory.</p>
<p><strong>Parameters:</strong></p>
<ul>
<li><code>WIDTH</code> - Size of an individual memory slot.</li>
<li><code>D0_SIZE</code> - Number of memory slots for the first index.</li>
<li><code>D1_SIZE</code> - Number of memory slots for the second index.</li>
<li><code>D2_SIZE</code> - Number of memory slots for the third index.</li>
<li><code>D3_SIZE</code> - Number of memory slots for the fourth index.</li>
<li><code>D0_IDX_SIZE</code> - The width of the first index.</li>
<li><code>D1_IDX_SIZE</code> - The width of the second index.</li>
<li><code>D2_IDX_SIZE</code> - The width of the third index.</li>
<li><code>D3_IDX_SIZE</code> - The width of the fourth index.</li>
</ul>
<p><strong>Inputs:</strong></p>
<ul>
<li><code>addr0: D0_IDX_SIZE</code> - The first index into the memory</li>
<li><code>addr1: D1_IDX_SIZE</code> - The second index into the memory</li>
<li><code>addr2: D2_IDX_SIZE</code> - The third index into the memory</li>
<li><code>addr3: D3_IDX_SIZE</code> - The fourth index into the memory</li>
<li><code>write_data: WIDTH</code> - Data to be written to the selected memory slot</li>
<li><code>write_en: 1</code> - One bit write enabled signal, causes the memory to write <code>write_data</code> to the slot indexed by <code>addr0</code>, <code>addr1</code>, <code>addr2</code>, and <code>addr3</code></li>
</ul>
<p><strong>Outputs:</strong></p>
<ul>
<li><code>read_data: WIDTH</code> - The value stored at <code>mem[addr0][addr1][addr2][addr3]</code>. This value is combinational with respect to <code>addr0</code>, <code>addr1</code>, <code>addr2</code>, and <code>addr3</code>.</li>
<li><code>done: 1</code>: The done signal for the memory. This signal goes high for one cycle after finishing a write to the memory.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="calyx-compiler-as-a-library"><a class="header" href="#calyx-compiler-as-a-library">Calyx Compiler as a Library</a></h1>
<p>The Calyx compiler is separated into <a href="https://docs.rs/releases/search?query=calyx">multiple crates</a> that can be used independently.
If you're interested in adding a new pass to the Calyx compiler or build a tool using it, your best bet is to <a href="https://docs.rs/calyx-opt/0.2.1/calyx_opt/">take a look at the example in the <code>calyx-opt</code></a> library.</p>
<p>The <code>calyx</code> implements the compiler driver and plumbs together all the other crates.
You mostly likely want to include the <code>calyx-opt</code> crate if you're working passes or just the <code>calyx-ir</code> crate if you're working with the IR.
You'll also need <code>calyx-frontend</code> and <code>calyx-utils</code> if you're parsing frontend code.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dataflow-optimizations"><a class="header" href="#dataflow-optimizations">Dataflow Optimizations</a></h1>
<p>In general, dataflow analysis uses the control and data flow of a program to compute
various properties (liveness, reaching definitions, ...) at each point in a program.</p>
<p>For Calyx, dataflow analyses use the explicit control program and knowledge about
the dataflow of each group to compute properties about each group.</p>
<h2 id="basic-blocks-vs-groups"><a class="header" href="#basic-blocks-vs-groups">Basic blocks vs. Groups</a></h2>
<p>Normally, dataflow analyses compute a property at each basic block of a control
flow graph (CFG). Calyx doesn't have a notion of basic blocks, and so Calyx computes
a property at each group in a program.</p>
<p>Because Calyx separates the control flow of a program from the specification of
groups, it's possible for a group to appear multiple times in the control program.
For this reason we compute a property at each group <em>enable</em> rather than each group
<em>definition</em>. The property at each group <em>definition</em> can easily be computed
as the meet over all group enables.</p>
<h2 id="dataflow-on-an-ast"><a class="header" href="#dataflow-on-an-ast">Dataflow on an AST</a></h2>
<p>Dataflow analyses are typically performed by finding the fixed point
of a set of equations defined at each node of a control flow graph (CFG)
using the <a href="https://en.wikipedia.org/wiki/Data-flow_analysis#An_iterative_algorithm">worklist algorithm</a>.</p>
<p>Because our control AST is little more than just the edges of a <a href="https://en.wikipedia.org/wiki/Control-flow_graph#Reducibility">reducible cfg</a>,
we don't bother to build an explicit CFG and instead perform the
dataflow analysis directly on the AST using Calyx's visitor infrastructure.</p>
<h3 id="abstract-algorithm"><a class="header" href="#abstract-algorithm">Abstract Algorithm</a></h3>
<p>We model each control statement <code>s</code> as a function, <code>f: p -&gt; p</code> where <code>p</code> is
the type of the property. Control statements that have children define how information
flows between its children.</p>
<h4 id="enable"><a class="header" href="#enable">Enable</a></h4>
<p><code>f</code> for <code>enable A</code> is similar to the transfer function in standard dataflow analysis. It
uses information from the definition of group <code>A</code> to modify the input in some way. For example,
if <code>p</code> is the set of live variables, the enable <code>f</code> is defined as:</p>
<pre><code>f(enable A, inputs) = (inputs - kill(A)) | gen(A)
</code></pre>
<h4 id="seq-1"><a class="header" href="#seq-1">Seq</a></h4>
<p><code>seq</code> defines sequential control flow edges between its children.
It is implemented by threading its input through all of its children to produce an output.</p>
<pre><code>f(seq { A; B; C; ...; Z; }, inputs) =
     f(A, inputs)
  |&gt; f(B, _)
  |&gt; f(C, _)
  |&gt; ...
  |&gt; f(Z, _)
</code></pre>
<p>To implement a backwards dataflow analysis, all you need to do is reverse the
order that <code>seq</code> pipes inputs to its children:</p>
<pre><code>// reverse
f(seq { A; B; C; ...; Z; }, inputs) =
     f(Z, inputs)
  |&gt; ...
  |&gt; f(C, _)
  |&gt; f(B, _)
  |&gt; f(A, _)
</code></pre>
<h4 id="if-1"><a class="header" href="#if-1">If</a></h4>
<p><code>if</code> passes its inputs to its condition group and then feeds the result of this
to both of its children. The output is the union of the outputs of both of its
children. This is standard.</p>
<pre><code>f(if some.port with G { True; } else { False; }, inputs) =
  f(True, f(G, inputs)) | f(False, f(G, inputs))
</code></pre>
<h4 id="while-1"><a class="header" href="#while-1">While</a></h4>
<p><code>while</code> statements are interesting because the outputs of the body may affect the
input to the body. For this reason, we need to find a fixed point:</p>
<pre><code>f(while some.port with G { body; }, inputs) =
  P = inputs;
  loop until P stops changing {
    P = f(body, f(G, inputs))
  }
</code></pre>
<h4 id="par-1"><a class="header" href="#par-1">Par</a></h4>
<p>Par is the only statement that differs substantially from traditional dataflow because
control flow graphs don't support nodes running in parallel. In other words, there is only
ever one thing executing. However, <code>par</code> changes this and allows multiple things to
execute at the same time. Consider the following example where we are computing
the liveness of <code>x</code> to see why this is weird:</p>
<pre><code>F; // wr x
...
par {
  A; // wr x
  B;
}
G; // rd x
</code></pre>
<p>Is <code>x</code> alive between <code>X</code> and the beginning of <code>par</code>? The answer is no because we know
that <em>both</em> <code>A</code> and <code>B</code> will run. Therefore the write to <code>x</code> in <code>F</code> can not be seen by any
group.</p>
<p>At first glance this doesn't seem like a problem. Great, we say, we can just take
the union of the outputs of the children of <code>par</code> and call it a day.</p>
<img src="optimizations/par1.png" width="35%"/>
<p>This is wrong because <code>B</code> doesn't kill <code>x</code> and so <code>x</code> is alive coming into <code>B</code>.
The union preserves this information and results in <code>x</code> being alive above <code>par</code>.</p>
<p>Taking the set intersection is not quite right here either. Consider adding another group
<code>C</code> that reads from <code>x</code>.</p>
<img src="optimizations/par2.png" width="40%"/>
<p>We have no information about how this read is ordered with the write
to <code>x</code> in <code>A</code> so we have to assume that <code>x</code> is alive above <code>par</code>. If we take the intersection
here:</p>
<pre><code>  live(A) &amp; live(B) &amp; live(C)
= {} &amp; {x} &amp; {x}
= {}
</code></pre>
<p>We get the wrong answer. More generally, we can see that union clobbers
any writes and intersection clobbers any reads that happen in the par.</p>
<p>The solution to this problem is solved by passing the <code>gen</code> and <code>kill</code> sets along
with the <code>live</code> sets. Then <code>par</code> can set its output to be </p>
<pre><code>(union(live(children)) - union(kill(children))) | union(gen(children))
</code></pre>
<p>The final tricky bit is thinking about how information flows between siblings in a <code>par</code> statement.
Consider again the picture above with three nodes: <code>A</code>, <code>B</code>, and <code>C</code>. Should <code>x</code> be live
at <code>B</code>? For liveness it turns out to be yes, but bare with me for a second for a thought experiment
and consider the case where we have the guarantee that statements running in parallel can not interact 
with each other. This lets us reorder statements in some cases.
Then there seems to be an information trade-off for how to define the liveness of <code>x</code> at <code>B</code>:</p>
<ul>
<li>You could say that <code>x</code> is dead at <code>B</code> because it doesn't see any previous writes to <code>x</code>
and doesn't read from <code>x</code>. This implies that you could potentially replace writes to other
registers with <code>x</code>. However, this by itself would cause <code>x</code> to be written to twice in parallel.
You would have to reorder <code>B</code> to run before <code>A</code>. The takeaway here is that calling <code>x</code> dead
at <code>B</code> gives the register reuse pass more information to work with. To compute
this information <code>B</code> needs the <code>gens</code> and <code>kills</code> from all of its siblings (for the same reason that <code>par</code>)
needed it. This is not particularly hard to implement, but it's worthy of noting.</li>
<li>If you say that <code>x</code> is live at <code>B</code>, then you can never rewrite <code>B</code> to use <code>x</code> instead
of some other register, but you also don't have to worry about reordering statements in a <code>par</code>.</li>
</ul>
<p>Leaving thought experiment land, in our case we can never reorder statements in a <code>par</code> because
siblings may interact with each other in arbitrary ways. For this reason, we must say that <code>x</code>
is live at <code>B</code>. However, it's not immediately clear to me that this will be true of all dataflow
analyses. That's why I set this thought experiment down in writing.</p>
<h3 id="equivalence-to-worklist-algorithm"><a class="header" href="#equivalence-to-worklist-algorithm">Equivalence to worklist algorithm</a></h3>
<p>In the normal worklist algorithm, we add a statement back to the worklist when
its predecessor has changed.</p>
<p>The intuition for why this algorithm is equivalent to worklist algorithm is
that because the only entry into the children for each parent control statement
is the parent control statement itself. The only way that a child statement would
need to be recomputed is if the inputs to the parent need to be recomputed. Anything
above the parent in the tree will take care of this re-computation.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging"><a class="header" href="#debugging">Debugging</a></h1>
<p>Calyx programs can provide wrong answers for two reasons:</p>
<ol>
<li>The program implements the wrong algorithm, i.e., it has a logical bug.</li>
<li>The Calyx compiler incorrectly compiles the program, i.e., there is a compilation bug.</li>
</ol>
<p>First make sure that the program generates the correct values with the <a href="debug/../interpreter.html">Calyx
Interpreter</a>. If it produces the wrong values, your Calyx implementation of the
algorithm is incorrect. You can use the <a href="debug/./cider.html">Calyx Debugger</a> to debug these problems.</p>
<p>If the interpreter produces the right values, try a different Verilog backed. We support both
<a href="debug/../fud/index.html#verilator">Verilator</a> and <a href="debug/../fud/index.html#icarus-verilog">Icarus Verilog</a>. If
both produce the wrong answer <em>and</em> the interpreter produces the right answer then you likely have
a compilation bug on your hands. Use the <a href="debug/./debug.html">debugging tips</a> to narrow down the pass that causes
the error.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="the-calyx-interactive-debugger"><a class="header" href="#the-calyx-interactive-debugger">The Calyx Interactive Debugger</a></h1>
<p>The Calyx Interactive Debugger is a prototype debugging tool built on top of the
<a href="debug/../interpreter.html">Calyx Interpreter</a> which exposes a <a href="https://sourceware.org/gdb/">gdb</a>-like interface for
debugging Calyx programs.</p>
<h2 id="getting-started-1"><a class="header" href="#getting-started-1">Getting Started</a></h2>
<p>If you are using <a href="debug/../fud/index.html"><code>fud</code></a> getting started with the debugger is easy.
Assuming you are trying to debug a program called <code>my_program.futil</code> with data
file <code>my_program.futil.data</code>, invoke the debugger with the following command:</p>
<pre><code>fud e --to debugger -q my_program.futil -s verilog.data my_program.futil.data
</code></pre>
<p>This will open the target program in the interactive debugger. Note that <code>fud</code>
uses <strong>the quiet flag</strong>, <code>-q</code>, here. This prevents the printing from the <code>fud</code> tool
from conflicting the debugger as both tools interact with standard out.</p>
<h2 id="advancing-program-execution"><a class="header" href="#advancing-program-execution">Advancing Program execution</a></h2>
<h3 id="step"><a class="header" href="#step"><code>step</code></a></h3>
<p>The simplest way to advance the program is via the <code>step</code> command which causes
time to advance by a clock tick. It also has a shortcode: <code>s</code>.</p>
<pre><code> &gt; step
 &gt; s
</code></pre>
<p>The above snippet advances the program by two steps.</p>
<h3 id="step-over"><a class="header" href="#step-over"><code>step-over</code></a></h3>
<p>Another way to advance the program is via the <code>step-over</code> command. Unlike the
<code>step</code> command, this command requires a second argument which is the name of the
group to advance over. The <code>step-over</code> command then advances the program until
the given group is no longer running.</p>
<p>If you want to use the command to advance the program past a group <code>group_1</code>, do
the following:</p>
<pre><code> &gt; step-over group_1
</code></pre>
<p>Note that the <code>step-over</code> command will do nothing if the given group is not
running.</p>
<pre><code> &gt; step-over other_group
 Group is not running
 &gt;
</code></pre>
<h3 id="continue"><a class="header" href="#continue"><code>continue</code></a></h3>
<p>Finally, the continue command will run the program until either a breakpoint is
hit or the program terminates. This command is used in conjunction with
breakpoints and watchpoints to provide more targeted inspection. It may also be
accessed with the shortcode <code>c</code>.</p>
<pre><code> &gt; continue
Main component has finished executing. Debugger is now in inspection mode.
</code></pre>
<h2 id="breakpoints"><a class="header" href="#breakpoints">Breakpoints</a></h2>
<p>CIDR supports breakpoints on group definitions. This helps focus attention on
suspect portions of the code.</p>
<h3 id="setting-a-breakpoint"><a class="header" href="#setting-a-breakpoint">Setting a breakpoint</a></h3>
<p>Breakpoints may be set on the main component by simple specifying the group of
interest.</p>
<pre><code> &gt; break group_1
</code></pre>
<p>This is identical to</p>
<pre><code> &gt; break main::group_1
</code></pre>
<p>For sub-components, the name of the sub-component must be included with the
double colon separating the group name. To break on the <code>do_mul</code> group inside
the <code>pow</code> sub-component:</p>
<pre><code> &gt; break pow::do_mul
</code></pre>
<h3 id="managing-breakpoints"><a class="header" href="#managing-breakpoints">Managing breakpoints</a></h3>
<p>To see a list of breakpoints:</p>
<pre><code> &gt; info break
</code></pre>
<p>or</p>
<pre><code> &gt; ib
</code></pre>
<p>This produces output like this:</p>
<pre><code> &gt; ib
     Current breakpoints:
    1.  main::group_1  enabled
    2.  pow::do_mul enabled
</code></pre>
<p>All breakpoints have a number associated with them and they may be managed with
this number or the group name.</p>
<p>To enable or disable a breakpoint:</p>
<pre><code> &gt; disable group_1 2
 &gt; enable 1 pow::do_mul
</code></pre>
<p>Note that this is equivalent to:</p>
<pre><code> &gt; disable group_1
 &gt; disable 2
 &gt; enable 1
 &gt; enable pow::do_mul
</code></pre>
<p>To delete a breakpoint:</p>
<pre><code> &gt; delete 1
 &gt; del pow::do_mul
</code></pre>
<p>Deleted breakpoints will be entirely removed while disabled breakpoints will
remain until they are either enabled again or subsequently deleted. Disabled
breakpoints will not cause program execution to halt when <code>continue</code>-ing.</p>
<h2 id="inspecting-state"><a class="header" href="#inspecting-state">Inspecting State</a></h2>
<h3 id="display"><a class="header" href="#display"><code>display</code></a></h3>
<p>The display command dumps the full state of the main component without
formatting. Use the <code>print</code> and <code>print-state</code> commands for targeted inspection
with formatting.</p>
<h3 id="formatting-codes"><a class="header" href="#formatting-codes">Formatting codes</a></h3>
<p>CIDR supports several different formatting codes which do the hard work of
interpreting the data in human readable ways.</p>
<div class="table-wrapper"><table><thead><tr><th>name</th><th>code</th><th>description</th></tr></thead><tbody>
<tr><td>binary</td><td></td><td>The default, a bit vector with the msb on the left</td></tr>
<tr><td>unsigned</td><td>\u</td><td>Unsigned bit-num formatting</td></tr>
<tr><td>signed</td><td>\s</td><td>Two's Complement formatting</td></tr>
<tr><td>unsigned fixedpoint</td><td>\u.N</td><td>For N &gt;=1. Unsigned Fixed-point with N fractional bits. The remaining bits are for the integral component.</td></tr>
<tr><td>signed fixedpoint</td><td>\s.N</td><td>For N &gt;=1. Signed Fixed-point with N fractional bits. The remaining bits are for the integral component.</td></tr>
</tbody></table>
</div>
<h3 id="print-and-print-state"><a class="header" href="#print-and-print-state"><code>print</code> and <code>print-state</code></a></h3>
<p>These commands allow inspecting <em>instance</em> state with optional formatting. Note
that this is different from breakpoints which operate on <em>definitions</em>. For example to print the ports of the <code>std_mul</code> instance named <code>mul</code> in the <code>pow</code> instance <code>pow_1</code> attached to the main component:</p>
<pre><code> &gt; print main.pow_1.mul
</code></pre>
<p>as with breakpoints, the leading <code>main</code> may be elided:</p>
<pre><code> &gt; print pow_1.mul
</code></pre>
<p>This will print all the ports attached to this multiplier instance with binary
formatting.</p>
<p>Formatting codes may be supplied as the first argument.</p>
<pre><code> &gt; print \u pow_1.mul
</code></pre>
<p>The <code>print</code> may also target specific ports on cells, rather than just the cell
itself. To see only the output of the multiplier (with unsigned formatting):</p>
<pre><code> &gt; print \u pow_1.mul.out
</code></pre>
<p>The <code>print-state</code> command works in the same way as the <code>print</code> command, except
it displays the internal state of a cell, rather than port values. As such, it
can only target cells and only those with some internal state, such as registers
or memories. For example, if the main component has a memory named <code>out_mem</code> its
contents may be viewed via:</p>
<pre><code> &gt; print-state main.out_mem
</code></pre>
<p>or just</p>
<pre><code> &gt; print-state out_mem
</code></pre>
<p>As with <code>print</code>, <code>print-state</code> supports formatting codes as an optional first
argument. So to view the contents of <code>out_mem</code> with a signed interpretation:</p>
<pre><code> &gt; print-state \s out_mem
</code></pre>
<h2 id="watchpoints"><a class="header" href="#watchpoints">Watchpoints</a></h2>
<p>Watchpoints are like breakpoints but rather than stop the execution when they
are passed, they instead print out some information. Like breakpoints, they are
set on group <em>definitions</em>, such as <code>main::group_1</code> or <code>pow::do_mul</code></p>
<h3 id="setting-watchpoints"><a class="header" href="#setting-watchpoints">Setting watchpoints</a></h3>
<p>The general form of watchpoints looks like</p>
<pre><code>watch [POSITION] GROUP with PRINT-COMMAND
</code></pre>
<p>where:</p>
<ul>
<li><code>GROUP</code> is the group definition to be watched</li>
<li><code>PRINT-COMMAND</code> is a full <code>print</code> or <code>print-state</code> command to be run by the watchpoint</li>
</ul>
<p>The optional <code>POSITION</code> argument may either be <code>before</code> or <code>after</code>. This
specifies whether the watchpoint should run when the group first becomes active
(<code>before</code>) or when the group finishes running (<code>after</code>). This defaults to
<code>before</code> if not set.</p>
<h3 id="managing-watchpoints"><a class="header" href="#managing-watchpoints">Managing watchpoints</a></h3>
<p>Watchpoint management is similar to breakpoints. However there may be multiple
watchpoints for a single group definition, so deleting watchpoints via the group
name will delete all the watchpoints associated with the group. Watchpoints do
not currently have an enable/disable state.</p>
<p>To view all the watchpoint definitions:</p>
<pre><code> &gt; info watch

...

 &gt; iw
</code></pre>
<p>To delete watchpoints:</p>
<pre><code> &gt; delete-watch 1
 &gt; del-watch main::group_1
</code></pre>
<h2 id="viewing-the-program-counter"><a class="header" href="#viewing-the-program-counter">Viewing the program counter</a></h2>
<p>There <code>where</code> command (alias <code>pc</code>) displays the currently running portion of the
control tree including active subcomponents. This can be used to more easily
determine the currently active portion of the design as well as visualize how
much of the execution is occurring in parallel at any given point.</p>
<h2 id="exiting-the-debugger"><a class="header" href="#exiting-the-debugger">Exiting the debugger</a></h2>
<p>Use <code>help</code> to see all commands. Use <code>exit</code> to exit the debugger.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="debugging-compilation-bugs"><a class="header" href="#debugging-compilation-bugs">Debugging Compilation Bugs</a></h1>
<p>These tips are directed towards <em>compilation bugs</em>. Before trying these, make sure your program
produces the correct values with the <a href="debug/../interpreter.html">Calyx Interpreter</a></p>
<h2 id="disabling-optimizations"><a class="header" href="#disabling-optimizations">Disabling Optimizations</a></h2>
<p>The first step is disabling optimization passes and running the bare bones compilation pipeline.</p>
<p>To disable the passes, add the flag <code>-p no-opt</code> to compiler invocation:</p>
<ol>
<li>For the compiler: <code>futil &lt;filename&gt; -p no-opt</code>.</li>
<li>For <code>fud</code>: <code>fud ... -s calyx.flags &quot; -p no-opt&quot;</code>.</li>
</ol>
<p>If the output is still incorrect then one of the core compilation passes is incorrect.
Our best bet at this point is to reduce the test file such that the output from the
interpreter and the Calyx compiler still disagree and <a href="https://github.com/cucapra/calyx/issues/new">report the
bug</a>. We can use the <a href="debug/debug.html#waveform-debugging">waveform
debugging</a> to figure out which part of the compilation pipeline generates the
incorrect result.</p>
<p>If the execution generates the right result, then one of the optimizations
passes is incorrect.
To identify which optimization pass is wrong, add back individual passes and see
when the execution fails.
The <code>calyx/src/default_passes.rs</code> file defines the compilation pipeline. Start by incrementally
adding passes to this flag invocation:</p>
<pre><code>-p validate -p simplify-with-control -p &lt;PASS 1&gt; ... -p &lt;PASS N&gt; -p compile -p lower
</code></pre>
<h2 id="reducing-test-files"><a class="header" href="#reducing-test-files">Reducing Test Files</a></h2>
<p>It is often possible to reduce the size of the example program that is
generating incorrect results.
In order to perform a reduction, we need to run the program twice, once with
a &quot;golden workflow&quot; that we trust to generate the right result and once with
the buggy workflow.</p>
<h3 id="inlining-optional"><a class="header" href="#inlining-optional">Inlining (Optional)</a></h3>
<p>It is useful to inline all the code into the <code>main</code> component so that we can focus our energy on reducing one control program. This can be done by passing the following flags to the compiler:</p>
<pre><code>-p well-formed -p inline -x inline:always -p post-opt
</code></pre>
<p>The <code>-x inline:always</code> flag tells the inlining pass to attempt to inline all components into one. If this command fails, we can just work with the original program and reduce control programs for each component.</p>
<h3 id="reducing"><a class="header" href="#reducing">Reducing</a></h3>
<p>At a high-level, we want to do the following:</p>
<ol>
<li>Delete some part of the control program</li>
<li>See if the error still occurs</li>
<li>If it doesn't, delete a smaller part of the control program</li>
<li>Otherwise, continue deleting more parts of the control program</li>
</ol>
<blockquote>
<p>When deleting parts of the control program, the compiler may complain that certain groups are no longer being used. In this case, run the <code>-p dead-group-removal</code> pass before any other pass runs.</p>
</blockquote>
<p>Next, if we've identified the problem to be in one of the Calyx passes,
the &quot;golden workflow&quot; is running the program without the pass while the buggy
workflow is running the program with the pass enabled.
This case is so common that we've written <a href="https://github.com/cucapra/calyx/blob/master/tools/flag-compare.sh">a script</a> that can run
programs with different set of flags to the Calyx compiler and show the
difference in the outputs after simulation.</p>
<p>The script is invoked as:</p>
<pre><code>tools/flag-compare.sh &lt;calyx program&gt; &lt;data&gt;
</code></pre>
<p>By default, the script will try to run the programs by simulating them through
Verilator by providing <code>fud</code> with the target <code>--to dat</code>.
If you'd like to use the Calyx Interpreter instead, run the following command:</p>
<pre><code>tools/flag-compare.sh &lt;calyx program&gt; &lt;data&gt; interpreter-out
</code></pre>
<h3 id="reducing-calyx-programs"><a class="header" href="#reducing-calyx-programs">Reducing Calyx Programs</a></h3>
<p>The best way to reduce Calyx program deleting group enables from the control
program and seeing if the generated program still generates the wrong output.
While doing this, make sure that you're not deleting an update to a loop
variable which might cause infinite loops.</p>
<p>By default, the compiler will complain if the program contains a <code>group</code> that
is not used in the control program which can get in the way of minimizing
programs.
To get around this, run the <a href="https://docs.rs/calyx-opt/latest/calyx_opt/passes/struct.DeadGroupRemoval.html"><code>dead-group-removal</code></a> pass before the validation
passes:</p>
<pre><code>futil -p dead-group-removal -p validate ...
</code></pre>
<h3 id="reducing-dahlia-programs"><a class="header" href="#reducing-dahlia-programs">Reducing Dahlia Programs</a></h3>
<p>If you're working with Dahlia programs, it is also possible to reduce the
program with the script since it simply uses <code>fud</code> to run the program with the
simulator.
As with Calyx reduction, try deleting parts of the program and seeing if the
flag configurations for the Calyx program still generate different outputs.</p>
<h2 id="waveform-debugging-1"><a class="header" href="#waveform-debugging-1">Waveform Debugging</a></h2>
<p>Waveform debugging is the final way of debugging Calyx programs.
A waveform captures the value of every port at every clock cycle and can be
viewed using a wave viewer program like <a href="http://gtkwave.sourceforge.net/">GTKWave</a> or
<a href="https://marketplace.visualstudio.com/items?itemName=wavetrace.wavetrace">WaveTrace</a> to look at the wave form.
Because of this level of granularity, it generates a lot of information.
To make the information a little more digestible, we can use information
generated by Calyx during compilation.</p>
<p>For waveform debugging, we recommend disabling the optimization passes and
static timing compilation (unless you're debugging these passes).
In this debugging strategy, we'll do the following:</p>
<ol>
<li>Dump out the control FSM for the program we're debugging.</li>
<li>Find the FSM states that enable the particular groups that might be misbehaving.</li>
<li>Open the waveform viewer and find clock cycles where the FSM takes the corresponding
values and identify other signals that we care about.</li>
</ol>
<p>Consider the control section from <a href="https://github.com/cucapra/calyx/blob/master/examples/futil/dot-product.futil">examples/futil/dot-product.futil</a>:</p>
<pre><code>    seq {
      let0;
      while le0.out with cond0 {
        seq {
          par {
            upd0;
            upd1;
          }
          let1;
          let2;
          upd2;
          upd3;
        }
      }
    }
</code></pre>
<p>Suppose that we want to make sure that <code>let0</code> is correctly performing its
computation.
We can generate the control FSM for the program using:</p>
<pre><code>  futil &lt;filename&gt; -p top-down-cc
</code></pre>
<p>This generates a Calyx program with several new groups.
We want to look for groups with the prefix <code>tdcc</code> which look something like
this:</p>
<pre><code>group tdcc {
  let0[go] = !let0[done] &amp; fsm.out == 4'd0 ? 1'd1;
  cs_wh.in = fsm.out == 4'd1 ? le0.out;
  cs_wh.write_en = fsm.out == 4'd1 ? 1'd1;
  cond0[go] = fsm.out == 4'd1 ? 1'd1;
  par[go] = !par[done] &amp; cs_wh.out &amp; fsm.out == 4'd2 ? 1'd1;
  let1[go] = !let1[done] &amp; cs_wh.out &amp; fsm.out == 4'd3 ? 1'd1;
  let2[go] = !let2[done] &amp; cs_wh.out &amp; fsm.out == 4'd4 ? 1'd1;
  upd2[go] = !upd2[done] &amp; cs_wh.out &amp; fsm.out == 4'd5 ? 1'd1;
  upd3[go] = !upd3[done] &amp; cs_wh.out &amp; fsm.out == 4'd6 ? 1'd1;
  ...
}
</code></pre>
<p>The assignments to <code>let0[go]</code> indicate what conditions make the <code>let0</code> group
execute.
In this program, we have:</p>
<pre><code>let0[go] = !let0[done] &amp; fsm.out == 4'd0 ? 1'd1;
</code></pre>
<p>Which states that <code>let0</code> will be active when the state of the <code>fsm</code> register
is <code>0</code> along with some other conditions.
The remainder of the group defines how the state in the <code>fsm</code> variable changes:</p>
<pre><code>  ...
  fsm.in = fsm.out == 4'd0 &amp; let0[done] ? 4'd1;
  fsm.write_en = fsm.out == 4'd0 &amp; let0[done] ? 1'd1;
  fsm.in = fsm.out == 4'd1 &amp; cond0[done] ? 4'd2;
  fsm.write_en = fsm.out == 4'd1 &amp; cond0[done] ? 1'd1;
  ...
</code></pre>
<p>For example, we can see that when the value of the FSM is 0 and <code>let0[done]</code>
becomes high, the FSM will take the value 1.</p>
<p>Once we have this information, we can open the VCD file and look at points when
the <code>fsm</code> register has the value 1 and check to see if the assignments in
<code>let0</code> activated in the way we expected.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="emitting-calyx-from-python"><a class="header" href="#emitting-calyx-from-python">Emitting Calyx from Python</a></h1>
<p>The <code>calyx</code> builder library can be used to generate Calyx code in Python.</p>
<h2 id="installation-1"><a class="header" href="#installation-1">Installation</a></h2>
<p>To install the library, run the following from the repository root (requires
<a href="https://flit.readthedocs.io/en/latest/">flit</a> installation):</p>
<pre><code>cd calyx-py &amp;&amp; flit install -s
</code></pre>
<h2 id="using-the-calyx-builder"><a class="header" href="#using-the-calyx-builder">Using the <code>calyx</code> builder</a></h2>
<p>The <code>calyx</code> library provides a builder to generate Calyx code. The <a href="builder/ref.html">library reference</a> documents most builder methods and constructs.</p>
<p>We will also walk through the file <a href="https://github.com/cucapra/calyx/blob/master/calyx-py/test/builder_example.py"><code>builder_example.py</code></a> to demonstrate how the builder library is used. This Calyx program initializes two registers with the numbers 1 and 41, adds them together, and stores the result in a register.</p>
<p>The <code>add_main_component(prog)</code> method will, as the name suggests, add a main component to our program. We can define components for our Calyx program <code>prog</code> with <code>prog.component</code>. Here's a defininition of a <code>main</code> component with a 32-bit input <code>in</code> and output <code>out</code>:</p>
<pre><code class="language-python">def add_main_component(prog):
    main = prog.component(&quot;main&quot;)
    main.input(&quot;in&quot;, 32)
    main.output(&quot;out&quot;, 32)
</code></pre>
<p>Technically, we didn't need to assign <code>prog.component(&quot;main&quot;)</code> to a variable; the component <code>main</code> would have been added to <code>prog</code> regardless. However, it will often prove useful to store handles to components, registers, or other objects you'd like to use later.</p>
<p>We then instantiate our cells: three 32-bit registers and one 32-bit adder.</p>
<pre><code class="language-python">    lhs = main.reg(&quot;lhs&quot;, 32)
    rhs = main.reg(&quot;rhs&quot;, 32)
    sum = main.reg(&quot;sum&quot;, 32)
    add = main.add(&quot;add&quot;, 32)
</code></pre>
<p>As with adding components to a program, we don't need to assign <code>main.reg(...)</code> to a variable, but it'll be useful to be able to quickly refer to these cells.</p>
<p>Next, we'll define our groups of assignments. The syntax for defining a group looks like <code>with {component}.group(&quot;group_name&quot;) as group_variable</code>, as we do below:</p>
<pre><code class="language-python">    with main.group(&quot;update_operands&quot;) as update_operands:
</code></pre>
<p>Now, we'll initialize our registers. You can access cell ports using dot notation. Notably, port names that are also reserved keywords in Python such as <code>in</code> are followed by an underscore.</p>
<pre><code class="language-python">        # Directly index cell ports using dot notation
        lhs.write_en = 1
        # Builder attempts to infer the bitwidth of the constant
        rhs.write_en = 1
        # `in` is a reserved keyword, so we use `in_` instead
        lhs.in_ = 1
</code></pre>
<p>As mentioned in the comments above, the Calyx builder will try to infer the bitwidth of constants. In case this doesn't work and you run into problems with this, you can provide the constant's size like so:</p>
<pre><code class="language-python">        # Explicilty sized constants when bitwidth inference may not work
        rhs.in_ = const(32, 41)
</code></pre>
<p>Calyx groups use a <a href="builder/..lang/ref.html#the-go-done-interface">latency-insensitive go/done interface</a>. When the <code>done</code> signal of a component is <code>1</code>, it signals that the component has finished executing. Oftentimes, computing this signal is conditional. We use <a href="builder/../lang/ref.html#guarded-assignments">guarded assignements</a> to a group's done signal in order to express this. Writing a group's done condition with the builder is pretty similar to doing so in Calyx, except that the <code>?</code> used for guarded assignments is now <code>@</code> (due to conflicting usage of <code>?</code> in Python).</p>
<pre><code class="language-python">        # Guards are specified using the `@` syntax
        update_operands.done = (lhs.done &amp; rhs.done) @ 1
</code></pre>
<p>In order to use the ports of cells in our <code>main</code> component within the code for our component, we'll expose the adder's output port by explicitly constructing it using the <code>calyx-py</code> AST.</p>
<pre><code class="language-python">    # Bare name of the cell
    add_out = ast.CompPort(ast.CompVar(&quot;add&quot;), &quot;out&quot;)
</code></pre>
<p>Now, when we want to use the output port of our adder, we can do so easily:</p>
<pre><code class="language-python">        sum.in_ = add_out
</code></pre>
<p>In order to add <a href="builder/../lang/ref.html#continuous-assignments">continuous assignments</a> to your program, use the construct <code>with {component}.continuous:</code>.</p>
<pre><code class="language-python">    with main.continuous:
        this.out = sum.out
</code></pre>
<p>To access a component's ports while defining it, like we did above, we use the method <code>this()</code>.</p>
<pre><code class="language-python">    # Use `this()` method to access the ports on the current component
    this = main.this()
</code></pre>
<p>Lastly, we'll construct the control portion of this Calyx program. It's pretty simple; we're running two groups in sequence. Sequences of groups are just Python lists:</p>
<pre><code class="language-python">    main.control += [
        update_operands,
        compute_sum,
    ]
</code></pre>
<p>You can also use the builder to generate parallel control blocks. To do this, use the <code>par</code> keyword. For instance, the above code with some parallel groups in it might look like</p>
<pre><code class="language-python">    main.control += [
        update_operands,
        compute_sum,
        par(A, B, C)
    ]
</code></pre>
<p>After making our modifications to the <code>main</code> component, we'll build the program using the <code>build()</code> method. We use the <code>Builder</code> object to construct <code>prog</code>, and then return the generated program.</p>
<pre><code class="language-python">def build():
    prog = Builder()
    add_main_component(prog)
    return prog.program
</code></pre>
<p>Finally, we can emit the program we built.</p>
<pre><code class="language-python">if __name__ == &quot;__main__&quot;:
    build().emit()
</code></pre>
<p>That's about it for getting started with the <code>calyx-py</code> builder library! You can inspect the generated Calyx code yourself by running:</p>
<pre><code class="language-python">python calyx-py/test/builder_example.py
</code></pre>
<p>Other examples using the builder can also be found in the <code>calyx-py</code> <a href="https://github.com/cucapra/calyx/tree/master/calyx-py/test/">test directory</a>. All of our frontends were also written using this library, in case you'd like even more examples!</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="builder-library-reference"><a class="header" href="#builder-library-reference">Builder Library Reference</a></h1>
<h2 id="top-level-program-structure"><a class="header" href="#top-level-program-structure">Top-Level Program Structure</a></h2>
<p>Here's the general structure of a program that uses the builder to generate Calyx code.</p>
<pre><code class="language-python"># import the builder library
import calyx.builder as cb


# define `second_comp`
def add_second_comp(prog):
    # `second_comp` definition here


# method for defining `my_component` and adding it to a program
def add_my_component(prog, second_comp): 
    # add the component to the program
    my_component = prog.component(&quot;my_component&quot;)

    # Adding an instance of `second_comp` as a cell of `my_component`
    my_second_comp = my_component.cell(&quot;my_second_comp&quot;, second_comp)

    # adding a register cell (or other cells) to the component 
    my_reg = my_component.reg(&quot;my_reg&quot;, 32)

    # define a `my_component` group
    with my_component.group(&quot;my_group&quot;) as my_group:
      # assignments here 
      my_reg.write_en = 1

    # add the group to `my_component`'s control program
    my_component.control += my_group


# assemble the program
def build():
    prog = cb.Builder()
    my_second_comp = add_second_comp(prog)
    add_my_component(prog, my_second_comp)

    # return the generated program
    return prog.program


# emit the program
if __name__ == &quot;__main__&quot;:
    build().emit()
</code></pre>
<h2 id="components"><a class="header" href="#components">Components</a></h2>
<h3 id="defining-components"><a class="header" href="#defining-components">Defining Components</a></h3>
<p>To define a component, call the <code>Builder().component()</code> method.</p>
<pre><code class="language-python">prog = cb.Builder()
prog.component(&quot;my_component&quot;)
</code></pre>
<h3 id="retrieving-components"><a class="header" href="#retrieving-components">Retrieving Components</a></h3>
<p>To reference a component without an existing <a href="builder/ref.html#creating-handles">handle</a> to it, use the <code>Builder().get_component()</code> method.</p>
<pre><code class="language-python">prog = cb.Builder()
prog.component(&quot;my_component&quot;)
# a few lines later 
my_component = prog.get_component(&quot;my_component&quot;)
</code></pre>
<h3 id="defining-component-inputs-and-outputs"><a class="header" href="#defining-component-inputs-and-outputs">Defining Component Inputs and Outputs</a></h3>
<p>Components can be given input and output ports. Just specify the name of the port and its size.</p>
<pre><code class="language-python">my_component.input(&quot;my_input&quot;, 32)
my_component.output(&quot;my_output&quot;, 32)
</code></pre>
<p>To access the input and output ports of a component within the definition of a component, use the syntax <code>my_component.this().port</code>.</p>
<pre><code class="language-python">def add_my_component(prog):
    my_component = prog.component(&quot;my_component&quot;)
    my_component.output(&quot;my_output&quot;, 32)

    with my_component.group(&quot;my_group&quot;):
        my_component.this().my_output = const(32, 1)
</code></pre>
<p>Note that it's possible to <a href="builder/ref.html#creating-handles">create a handle</a> to input and output ports.</p>
<h3 id="multi-component-designs-1"><a class="header" href="#multi-component-designs-1">Multi-Component Designs</a></h3>
<p>Calyx supports <a href="builder/../lang/multi-component.html">multi-component designs</a>. The <a href="builder/ref.html#top-level-program-structure">top-level example</a> demonstrates how to construct multi-component designs using the library.</p>
<h4 id="defining-common-calyx-cells"><a class="header" href="#defining-common-calyx-cells">Defining Common Calyx Cells</a></h4>
<p>Here's a snippet of code that adds a few common kinds of cells to a component:</p>
<pre><code class="language-python">my_component = prog.component(&quot;my_component&quot;)

# Registers: reg(name, bitwidth)
my_component.reg(&quot;my_reg&quot;, 32)

# Constants: const(name, bitwidth, value)
my_component.const(&quot;my_reg&quot;, 32, 42)

# Adders/Subtractors: [add|sub](name, size, signed=False)
# a signed adder 
my_component.add(&quot;my_add&quot;, 32, signed=True)
# a subtractor
my_component.sub(&quot;my_sub&quot;, 32)


# Comparators: [gt|lt|eq|neq|ge|le](name, size, signed=False)
my_component.gt(&quot;my_gt&quot;, 32)
# a signed le comparison
my_component.lt(&quot;my_lt&quot;, 32, signed=True)
my_component.eq(&quot;my_eq&quot;, 32)
my_component.neq(&quot;my_neq&quot;, 32)
my_component.ge(&quot;my_ge&quot;, 32)
my_component.le(&quot;my_le&quot;, 32)

# 1-D memory: 
# mem_d1(name, bitwidth, len, idx_size, is_external=False, is_ref=False)
my_component.mem_d1(&quot;my_mem&quot;, 32, 4, 32)
# An external memory
my_component.mem_d1(&quot;my_mem&quot;, 32, 4, 32, is_external=True)
# A memory by reference
my_component.mem_d1(&quot;my_mem&quot;, 32, 4, 32, is_ref=True)
</code></pre>
<p>If you're curious, you can read more about <a href="builder/../lang/data-format.html#external-memories">external memories</a> or <a href="builder/../lang/memories-by-reference.html#passing-cells-by-reference">memories by reference</a>.</p>
<h4 id="retrieving-cells"><a class="header" href="#retrieving-cells">Retrieving Cells</a></h4>
<p>In order to reference a cell without a <a href="builder/ref.html#creating-handles">handle</a>, use the <code>Builder().get_cell()</code> method.</p>
<pre><code class="language-python"># defining a register cell
my_component.reg(&quot;my_reg&quot;, 32)

# a few lines later 
my_reg = prog.get_cell(&quot;my_reg&quot;)
</code></pre>
<h2 id="wires"><a class="header" href="#wires">Wires</a></h2>
<h3 id="guarded-assignments-1"><a class="header" href="#guarded-assignments-1">Guarded Assignments</a></h3>
<p>Guarded assignments in the builder are syntactically similar to those in Calyx.</p>
<pre><code class="language-python">my_component = prog.component(&quot;my_component&quot;)

my_add = comp.add(&quot;my_add&quot;, 32)
my_reg = comp.reg(&quot;my_reg&quot;, 32)

with my_component.group(&quot;my_group&quot;):
    # unconditional assignments
    add.left = const(32, 1)
    add.right = const(32, 41)
    my_reg.write_en = 1

    # a guarded assignment using @
    # in Calyx, this line would be:
    # my_reg.in = (add.left &lt; add.right) ? add.out;
    my_reg.in = (add.left &lt; add.right) @ add.out
</code></pre>
<h3 id="groups"><a class="header" href="#groups">Groups</a></h3>
<h4 id="defining-groups"><a class="header" href="#defining-groups">Defining Groups</a></h4>
<p><a href="builder/../lang/ref.html#group-definitions">Groups</a> are defined using the <code>group()</code> method for a component. To make a <a href="builder/ref.html#creating-handles">handle</a> for a group, use the <code>as</code> syntax. Group handles are necessary in order to set done ports for groups.</p>
<p>It's possible to define a <a href="builder/../lang/static.html#delay-by-n-cycles">static delay</a> for a group using the optional <code>static_delay</code> argument.</p>
<pre><code class="language-python">my_component = prog.component(&quot;my_component&quot;)

# a group definition + handle for the group
with my_component.group(&quot;my_group&quot;) as my_group:
    # assignments here

# a group with a static delay
with my_component.group(&quot;my_static_group&quot;, static_delay=1): 

</code></pre>
<h4 id="defining-combinational-groups"><a class="header" href="#defining-combinational-groups">Defining Combinational Groups</a></h4>
<p><a href="builder/../lang/ref.html#comb-group-definitions">Combinational groups</a> are defined similarly to groups, except with the <code>comb_group</code> method.</p>
<pre><code class="language-python">my_component = prog.component(&quot;my_component&quot;)

with my_component.comb_group(&quot;my_comb_group&quot;):
    # assignments here
</code></pre>
<h4 id="retrieving-groups"><a class="header" href="#retrieving-groups">Retrieving Groups</a></h4>
<p>If a group doesn't have a <a href="builder/ref.html#creating-handles">handle</a>, it can be retrieved later with the <code>Builder().get_group()</code> method. It's possible to retrieve combinational groups as well as regular groups with this method.</p>
<pre><code class="language-python">prog = cb.Builder()
my_component = prog.component(&quot;my_component&quot;)

with my_component.group(&quot;my_group&quot;):
    # group definition here

# a few lines later
my_group = prog.get_group(&quot;my_group&quot;)

with my_component.comb_group(&quot;my_comb_group&quot;):
    # comb group definition here

my_comb_group = prog.get_group(&quot;my_comb_group&quot;)

</code></pre>
<h3 id="continuous-assignments-1"><a class="header" href="#continuous-assignments-1">Continuous Assignments</a></h3>
<p><a href="builder/../lang/ref.html#continuous-assignments">Continuous assignments</a> are generated by using the syntax <code>with comp.continuous</code>.</p>
<pre><code class="language-python">my_component = prog.component(&quot;my_component&quot;)

my_output = my_component.output(&quot;my_output&quot;, 32)
my_reg = comp.reg(&quot;my_reg&quot;, 32)

with my_component.continuous:
    my_component.this().my_output = my_reg.out

</code></pre>
<h2 id="control-operators-and-programs"><a class="header" href="#control-operators-and-programs">Control Operators and Programs</a></h2>
<p>A component's control program is defined by augmenting the list <code>my_component.control</code>. Control programs are constructed with <a href="builder/../lang/ref.html#the-control-operators">control operators</a>.</p>
<h3 id="group-enables"><a class="header" href="#group-enables">Group Enables</a></h3>
<p>To <a href="builder/../lang/ref.html#group-enable">enable a group</a>, include it in a component's control program.</p>
<pre><code class="language-python">my_component.control += my_group

# using `get_group`
my_component.control += my_component.get_group(&quot;my_group&quot;)
</code></pre>
<h3 id="seq-2"><a class="header" href="#seq-2"><code>seq</code></a></h3>
<p>Control statements are <a href="builder/../lang/ref.html#seq">sequenced</a> in the order that they appear in a component's control program, represented by a Python list. Let's say we want to sequence the control statements <code>A</code>, <code>B</code>, and <code>C</code>.</p>
<pre><code class="language-python">my_component.control += [A, B, C]
</code></pre>
<h3 id="par-2"><a class="header" href="#par-2"><code>par</code></a></h3>
<p>For <a href="builder/../lang/ref.html#par">parallel compositions</a> of control programs, use the <code>par()</code> function. Here's how to compose control programs <code>A</code> and <code>B</code> in parallel, and then sequence their composition with the control program <code>C</code>.</p>
<pre><code class="language-python">my_component.control += [par(A, B), C]
</code></pre>
<h3 id="if-2"><a class="header" href="#if-2"><code>if</code></a></h3>
<p>See the language reference for <a href="builder/../lang/ref.html#if"><code>if</code></a>.</p>
<pre><code class="language-python"># `if_(port, cond, body, else_body=None)`
my_if = if_(my_port, my_comb_group, my_true_group)

# with a nested if
my_other_if = if_(my_port, my_if)

# with a comb group to compute the value of my_port
my_if_comb = if_(my_port, my_comb_group, my_true_group)

# with an else body
my_if_else = if_(my_port, my_comb_group, my_true_group, my_false_group)

my_component.control += [my_if, my_other_if, my_if_comb, my_if_else]
</code></pre>
<h3 id="while-2"><a class="header" href="#while-2"><code>while</code></a></h3>
<p>See the language reference for <a href="builder/../lang/ref.html#while"><code>while</code></a>.</p>
<pre><code class="language-python"># while_(port, cond, body)
my_while = while_(my_port, my_body)

# with a comb group to compute the value of my_port
my_while = while_(my_port, my_comb_group, my_body)
</code></pre>
<h3 id="invoke-1"><a class="header" href="#invoke-1"><code>invoke</code></a></h3>
<p>See the language reference for <a href="builder/../lang/ref.html#invoke"><code>invoke</code></a>.</p>
<pre><code class="language-python"># invoke(cell, **kwargs)
my_invoke = invoke(my_cell, in_arg1=my_cell_arg1_reg.out, in_arg2=my_cell_arg2_reg.out)
</code></pre>
<h2 id="miscellaneous-tips--tricks"><a class="header" href="#miscellaneous-tips--tricks">Miscellaneous Tips + Tricks</a></h2>
<h3 id="creating-handles"><a class="header" href="#creating-handles">Creating Handles</a></h3>
<p>Handles allow components, groups, cells, control operators, and input/output ports to be referenced after their definition.</p>
<pre><code class="language-python">def add_my_component(prog):
    # Creating a handle to a component
    my_component = prog.component(&quot;my_component&quot;)

    # using the component handle
    my_component.reg(&quot;my_reg&quot;, 32)

    # Creating a handle to an input/output port
    my_input = component.input(&quot;my_input&quot;, 32)
    my_output = component.output(&quot;my_output&quot;, 32)

    # Creating a handle to a cell
    my_second_comp = my_component.cell(&quot;my_cell&quot;, my_second_comp)

    # Creating a handle to a group
    with my_component.group(&quot;my_group&quot;) as my_group:
        # assignments

    # Creating a handle to a control operator
    my_if = if_(my_second_comp.out_port, body=my_group)

    # using the group handle + control operator handle
    my_component.control += [my_group, my_if]
</code></pre>
<h3 id="importing-calyx-libraries"><a class="header" href="#importing-calyx-libraries">Importing Calyx Libraries</a></h3>
<p>To generate imports for Calyx libraries, use the <code>Builder.import_()</code> method.</p>
<pre><code class="language-python">prog = cb.Builder()
prog.import_(&quot;primitives/binary_operators.futil&quot;)
</code></pre>
<h3 id="explictly-stating-widths-with-const"><a class="header" href="#explictly-stating-widths-with-const">Explictly Stating Widths with <code>const</code></a></h3>
<p>Usually, the builder library can automatically infer the width of a port. In cases where it can't, use the <code>const(width, value)</code> expression:</p>
<pre><code class="language-python">my_cell.my_port = const(32, 1)
</code></pre>
<h3 id="high-and-low-signals"><a class="header" href="#high-and-low-signals">High and Low Signals</a></h3>
<p>The <code>calyx.builder.HI</code> or <code>calyx.builder.LO</code> are shorthand for one-bit high and low signals.</p>
<pre><code class="language-python">&quot;&quot;&quot;A one-bit low signal&quot;&quot;&quot;
LO = const(1, 0)
&quot;&quot;&quot;A one-bit high signal&quot;&quot;&quot;
HI = const(1, 1)
</code></pre>
<div style="break-before: page; page-break-before: always;"></div><h1 id="building-a-frontend-for-calyx"><a class="header" href="#building-a-frontend-for-calyx">Building a Frontend for Calyx</a></h1>
<blockquote>
<p>This tutorial assumes that you have already worked through the <a href="tutorial/./language-tut.html">Calyx tutorial</a>. You won't get very much out of it by itself!</p>
</blockquote>
<p>In the <a href="tutorial/./language-tut.html">Calyx tutorial</a> you wrote Calyx code by hand.
This is (probably) a good way to build character, but it's no way to live.
Indeed, Calyx was <em>designed</em> to be a compiler IL, and not a human-facing language.</p>
<p>In this tutorial, we're going to learn all about this by building a DSL-to-hardware compiler for a toy language that we wish to accelerate.
We will compile the DSL to Calyx, and then let Calyx take us to hardware.</p>
<h1 id="mrxl-overview"><a class="header" href="#mrxl-overview">MrXL Overview</a></h1>
<p>Meet MrXL, our toy DSL.
MrXL lets you define arrays and registers and then perform <code>map</code> and <code>reduce</code> operations.</p>
<h2 id="example-sum-of-squares"><a class="header" href="#example-sum-of-squares">Example: sum of squares</a></h2>
<p>Here's a MrXL program that squares and then sums the values of an input array:</p>
<pre><code>input avec: int[4]
output sos: int
squares := map 1 (a &lt;- avec) { a * a }
sos := reduce 1 (acc, i &lt;- squares) 0 { acc + i }
</code></pre>
<p>This short program shows off all of MrXL's features, so let's pick it apart line by line:</p>
<ol>
<li>We specify an array, <code>avec</code>, which will have four integers. The <code>input</code> keyword means that an external harness will populate the array.</li>
<li>We specify <code>sos</code>, a register. The <code>output</code> keyword means that we will populate <code>sos</code> in our program.</li>
<li>The <code>map</code> operation gets the values of <code>avec</code> and raises each to the second power. We stash the result in a new array, <code>squares</code>. The number <code>1</code> denotes a <em>parallelism factor</em> of 1, meaning that the operation is performed sequentially. We will improve this shortly.</li>
<li>The <code>reduce</code> operation walks over <code>squares</code> and accumulates the result into a register. The parallelism factor is again <code>1</code>.</li>
</ol>
<h2 id="running-our-example"><a class="header" href="#running-our-example">Running our example</a></h2>
<h3 id="installing-mrxl"><a class="header" href="#installing-mrxl">Installing MrXL</a></h3>
<blockquote>
<p>If you are going through this tutorial in the <a href="https://github.com/cucapra/calyx/pkgs/container/calyx">Docker container</a>, you can skip these installation steps and jump to <a href="tutorial/frontend-tut.html#running-mrxl"><em>Running MrXL</em></a> just below.</p>
</blockquote>
<p>First, install the <a href="tutorial/../calyx-py.html"><code>builder</code> library</a> by typing the following command from the repository root:</p>
<pre><code>cd calyx-py &amp;&amp; flit install -s &amp;&amp; cd -
</code></pre>
<p>Next, install the <code>mrxl</code> binary:</p>
<pre><code>cd frontends/mrxl &amp;&amp; flit install -s &amp;&amp; cd -
</code></pre>
<p>Register the <code>mrxl</code> binary with <code>fud</code>:</p>
<pre><code>fud register mrxl -p frontends/mrxl/fud/mrxl.py
</code></pre>
<p>Now, running <code>fud check</code> should report that the <code>mrxl</code> binary is correctly installed.</p>
<h3 id="running-mrxl"><a class="header" href="#running-mrxl">Running MrXL</a></h3>
<p>Run:</p>
<pre><code>mrxl frontends/mrxl/test/sos.mrxl --data frontends/mrxl/test/sos.mrxl.data --interpret
</code></pre>
<p>Why <code>42</code>? Because we populated <code>avec</code> with:</p>
<pre><code class="language-json">{
  &quot;avec&quot;: [
    0,
    1,
    4,
    5
  ]
}
</code></pre>
<p>and \( 0^2 + 1^2 + 4^2 + 5^2 = 42 \).</p>
<h2 id="compiling-our-example-into-calyx"><a class="header" href="#compiling-our-example-into-calyx">Compiling our example into Calyx</a></h2>
<p>Above, we merely <em>interpreted</em> MrXL code in software using a simple, pre-written interpreter implemented in Python.
Our goal in this tutorial is to build a compiler from MrXL to hardware by translating it to the Calyx IL.
The Calyx IL code generated by compiling this program looks more like:</p>
<details>
<summary>Click to expand 103 lines.</summary>
<pre><code class="language-C">import &quot;primitives/core.futil&quot;;
import &quot;primitives/binary_operators.futil&quot;;
component main() -&gt; () {
  cells {
    @external avec_b0 = std_mem_d1(32, 4, 32);
    @external sos = std_mem_d1(32, 1, 32);
    sos_reg = std_reg(32);
    squares_b0 = std_mem_d1(32, 4, 32);
    idx_b0_0 = std_reg(32);
    incr_b0_0 = std_add(32);
    lt_b0_0 = std_lt(32);
    mul_b0_0 = std_mult_pipe(32);
    idx1 = std_reg(32);
    incr_1 = std_add(32);
    lt_1 = std_lt(32);
    add_1 = std_add(32);
  }
  wires {
    group sos_reg2mem {
      sos.addr0 = 32'd0;
      sos.write_data = sos_reg.out;
      sos.write_en = 1'd1;
      sos_reg2mem[done] = sos.done;
    }
    group incr_idx_b0_0 {
      incr_b0_0.left = idx_b0_0.out;
      incr_b0_0.right = 32'd1;
      idx_b0_0.in = incr_b0_0.out;
      idx_b0_0.write_en = 1'd1;
      incr_idx_b0_0[done] = idx_b0_0.done;
    }
    comb group cond_b0_0 {
      lt_b0_0.left = idx_b0_0.out;
      lt_b0_0.right = 32'd4;
    }
    group eval_body_b0_0 {
      avec_b0.addr0 = idx_b0_0.out;
      mul_b0_0.left = avec_b0.read_data;
      mul_b0_0.right = avec_b0.read_data;
      squares_b0.addr0 = idx_b0_0.out;
      squares_b0.write_data = mul_b0_0.out;
      mul_b0_0.go = 1'd1;
      squares_b0.write_en = mul_b0_0.done;
      eval_body_b0_0[done] = squares_b0.done;
    }
    group init_idx_1 {
      idx1.in = 32'd0;
      idx1.write_en = 1'd1;
      init_idx_1[done] = idx1.done;
    }
    group incr_idx_1 {
      incr_1.left = idx1.out;
      incr_1.right = 32'd1;
      idx1.in = incr_1.out;
      idx1.write_en = 1'd1;
      incr_idx_1[done] = idx1.done;
    }
    comb group cond_1 {
      lt_1.left = idx1.out;
      lt_1.right = 32'd4;
    }
    group init_1 {
      sos_reg.in = 32'd0;
      sos_reg.write_en = 1'd1;
      init_1[done] = sos_reg.done;
    }
    group reduce1 {
      squares_b0.addr0 = idx1.out;
      add_1.left = sos_reg.out;
      add_1.right = squares_b0.read_data;
      sos_reg.in = add_1.out;
      sos_reg.write_en = 1'd1;
      reduce1[done] = sos_reg.done;
    }
  }
  control {
    seq {
      par {
        while lt_b0_0.out with cond_b0_0 {
          seq {
            eval_body_b0_0;
            incr_idx_b0_0;
          }
        }
      }
      seq {
        par {
          init_1;
          init_idx_1;
        }
        while lt_1.out with cond_1 {
          seq {
            reduce1;
            incr_idx_1;
          }
        }
      }
      par {
        sos_reg2mem;
      }
    }
  }
}
</code></pre>
</details>
<p>Generate it for yourself! Run:</p>
<pre><code>mrxl frontends/mrxl/test/sos.mrxl
</code></pre>
<h2 id="simulating-our-example-with-verilog"><a class="header" href="#simulating-our-example-with-verilog">Simulating our example with Verilog</a></h2>
<p>Finally, let us go the whole hog: we compile our MrXL program to Calyx, compile it to Verilog, then simulate it using <a href="https://www.veripool.org/wiki/verilator">Verilator</a>.</p>
<p>Run:</p>
<pre><code>fud e --from mrxl frontends/mrxl/test/sos.mrxl --to dat --through verilog -s mrxl.data frontends/mrxl/test/sos.mrxl.data
</code></pre>
<p>The above command takes a MrXL program, <code>sos.mrxl</code>, and generates results with Verilator using the MrXL data file <code>sos.mrxl.data</code>.</p>
<h1 id="compiling-mrxl-into-calyx"><a class="header" href="#compiling-mrxl-into-calyx">Compiling MrXL into Calyx</a></h1>
<p>Calyx is an infrastructure for designing <em>domain-specific languages</em> (DSL) which can generate efficient hardware.
The rest of the tutorial will show you how to implement such a DSL by studying <a href="https://github.com/cucapra/calyx/blob/master/frontends/mrxl/mrxl/gen_calyx.py">the MrXL-to-Calyx compiler</a>, written in Python.</p>
<p>We have placed a few simplifying restrictions on MrXL programs:</p>
<ol>
<li>Every array in a MrXL program has the same length.</li>
<li>Every integer in our generated hardware is 32 bits long.</li>
<li>The bodies of <code>map</code> and <code>reduce</code> operations must be binary <code>+</code> or <code>*</code> operations involving array elements or integers.</li>
<li>If repeated <code>map</code>/<code>reduce</code> operations are performed on the same array, each of those operations must have the same parallelism factor.</li>
<li>All <code>reduce</code> operations must be performed sequentially, i.e., with parallelism factor <code>1</code>.</li>
</ol>
<p>These restrictions can be lifted or relaxed via commensurate changes to the compiler.</p>
<p>The compilation process breaks into two steps:</p>
<ol>
<li>Parsing MrXL into a representation we can process in Python.</li>
<li>Generating Calyx code.</li>
</ol>
<h2 id="parsing-mrxl-into-an-ast"><a class="header" href="#parsing-mrxl-into-an-ast">Parsing MrXL into an AST</a></h2>
<p>To start, we'll parse the MrXL program into a Python AST representation.
We choose to represent <a href="https://github.com/cucapra/calyx/blob/mrxl/mrxl/mrxl/ast.py">AST</a> nodes with <a href="https://docs.python.org/3/library/dataclasses.html">Python dataclasses</a>.
A program is a sequence of array/register declarations followed by computation statements:</p>
<pre><code class="language-python">@dataclass
class Prog:
    &quot;&quot;&quot;A MrXL program.&quot;&quot;&quot;
    decls: List[Decl]  # Memory declarations
    stmts: List[Stmt]  # Map and reduce statements
</code></pre>
<p><code>Decl</code> nodes correspond to array declarations such as <code>input avec: int[4]</code>.
They carry information about whether the array is an <code>input</code> or <code>output</code>, the array's name, and the type of the array's elements:</p>
<pre><code class="language-python">@dataclass
class Decl:
    &quot;&quot;&quot;Declaration of a memory.&quot;&quot;&quot;
    input: bool  # If `False`, this is an `output`.
    name: str
    type: Type
</code></pre>
<p><code>Stmt</code> nodes represent statements such as <code>sos := reduce 1 (acc, i &lt;- squares) 0 { acc + i }</code>.
They contain further nested nodes representing the function-header and -body, and the type of operation:</p>
<pre><code class="language-python">@dataclass
class Stmt:
    &quot;&quot;&quot;A statement in the program.&quot;&quot;&quot;
    dst: str
    operation: Union[Map, Reduce]
</code></pre>
<p>We elide further details, but point you to the <a href="https://github.com/cucapra/calyx/blob/master/frontends/mrxl/mrxl/ast.py">AST</a>, which defines all the nodes we need to represent a MrXL program.</p>
<h2 id="generating-calyx-code"><a class="header" href="#generating-calyx-code">Generating Calyx code</a></h2>
<p><a href="tutorial/./language-tut.html">As you know</a>, the skeleton of a Calyx program has three sections:</p>
<pre><code>component main() -&gt; {
  cells {}
  wires {}
  control {}
}
</code></pre>
<p>The <a href="tutorial/../lang/ref.html#cells">cells section</a> instantiates hardware units like adders, memories and registers.
The <a href="tutorial/../lang/ref.html#the-wires-section">wires section</a> contains <a href="tutorial/../lang/ref.html#group-definitions">groups</a> that connect
hardware instances to perform some logical task (e.g, incrementing a register).
Finally, the <a href="tutorial/../lang/ref.html#the-control-operators">control section</a> <em>schedules</em> the execution of groups using control operators such as <code>seq</code>, <code>par</code>, and <code>while</code>.</p>
<p>We perform syntax-directed compilation by walking over the nodes of the AST and generating <code>cells</code>, <code>wires</code>, and <code>control</code> operations.</p>
<h3 id="an-embedded-dsl-that-generates-calyx"><a class="header" href="#an-embedded-dsl-that-generates-calyx">An Embedded DSL that Generates Calyx</a></h3>
<p>To make it easy to generate hardware, we'll use Calyx's <a href="tutorial/../calyx-py.html"><code>builder</code> module</a> written in Python:</p>
<pre><code class="language-python">import calyx.builder as cb

prog = cb.Builder() # A Calyx program
main = prog.component(&quot;main&quot;) # Create a component named &quot;main&quot;
</code></pre>
<h3 id="decl-nodes"><a class="header" href="#decl-nodes"><code>Decl</code> nodes</a></h3>
<p><code>Decl</code> nodes instantiate new memories and registers.
We need these to be instantiated in the <code>cells</code> section of our Calyx output.
We use Calyx's <a href="https://github.com/cucapra/calyx/blob/45075345ae2858b23a599d65d94b0ed7bf949a61/primitives/compile.futil#L22"><code>std_reg</code></a> and <a href="https://github.com/cucapra/calyx/blob/45075345ae2858b23a599d65d94b0ed7bf949a61/primitives/compile.futil#L22"><code>std_mem_d1</code></a> primitives to represent <a href="https://github.com/cucapra/calyx/blob/master/primitives/compile.futil#L31">registers</a> and <a href="https://github.com/cucapra/calyx/blob/master/primitives/core.sv#L220">memories</a>:</p>
<pre><code class="language-C">import &quot;primitives/core.futil&quot;; // Import standard library

component main() -&gt; () {
  cells {
    // A memory with 4 32-bit elements. Indexed using a 6-bit value.
    avec = std_mem_d1(32, 4, 6);
    // A register that contains a 32-bit value
    sos = std_reg(32);
  }
  ...
}
</code></pre>
<p>For each <code>Decl</code> node, we need to determine if we're instantiating a memory or a register, translate the node into a corresponding Calyx declaration, and place the declaration inside the <code>cells</code> section of our generated program.</p>
<p>If a memory is used in a parallel <code>map</code> or <code>reduce</code>, we might need to create different physical banks for it.
We explain why <a href="tutorial/frontend-tut.html#memory-banking">below</a>.
We <a href="https://github.com/cucapra/calyx/blob/45075345ae2858b23a599d65d94b0ed7bf949a61/frontends/mrxl/mrxl/gen_calyx.py#L312">define a function</a> to walk over the AST and compute the parallelism factor for each memory:</p>
<pre><code class="language-python">    # Collect banking factors.
    par_factor = compute_par_factors(prog.stmts)
</code></pre>
<p>Using this information, we can instantiate registers and memories for our inputs and outputs:</p>
<pre><code class="language-python">            for i in range(par):
                main.mem_d1(f&quot;{name}_b{i}&quot;, 32, arr_size // par, 32, is_external=True)
</code></pre>
<p>The <code>main.mem_d1</code> call is a function defined by the Calyx builder module to instantiate memories for a component.
By setting <code>is_external=True</code>, we're indicating that a memory declaration is a part of the component's input-output interface.</p>
<h2 id="compiling-map-operations"><a class="header" href="#compiling-map-operations">Compiling <code>map</code> operations</a></h2>
<p>For every <code>map</code> or <code>reduce</code> node, we need to generate Calyx code that iterates over an array, performs some kind of computation, and then stores the result of that computation.
For <code>map</code> operations, we'll perform a computation on every element of an input array, and then store the answers in a result array.
We can use Calyx's <a href="tutorial/../lang/ref.html#while">while loops</a> to do this.
At a high level, we want to generate the following pieces of hardware:</p>
<ol>
<li>A register to store the current value of the loop index.</li>
<li>A comparator to check of the loop index is less than the array size.</li>
<li>An adder to increment the value of the index.</li>
<li>Whatever hardware is needed to implement the loop body computation.</li>
</ol>
<p>We have implemented exactly this, and you have been using it thus far with the <code>fud</code> invocations that we have provided you.</p>
<p>However, it is time to get your hands dirty.
We provide a <a href="https://github.com/cucapra/calyx/blob/master/frontends/mrxl/mrxl/gen_calyx.py#L171-L191">stub implementation</a> of <code>map</code> in <code>gen_calyx.py</code>:</p>
<pre><code class="language-python">def my_map_impl(
    comp: cb.ComponentBuilder,
    dest: str,
    stmt: ast.Map,
    arr_size: int,
    bank_factor: int,
    s_idx: int,
):
    &quot;&quot;&quot;
    Returns a dictionary containing Calyx cells, wires and
    control needed to implement a `map` statement.
    See gen_stmt_impl for format of the dictionary.

    Generates these groups:
      - a group that implements the body of the `map` statement
      - a group that increments an index to access the `map` input array
      - a group that implements the loop condition, checking if the index
        has reached the end of the input array
    &quot;&quot;&quot;
    # TODO: Implement map!
    return Empty()
</code></pre>
<p>You are invited to try implementing map yourself according to the outline given in the description by filling in the body of this function.</p>
<p>To run <code>mrxl</code> with <code>my_map_impl</code> instead of our implementation, pass the <code>--my-map</code> flag:</p>
<pre><code class="language-sh">fud e --from mrxl test/sos.mrxl \
        --to dat --through verilog \
        -s mrxl.flags &quot;--my-map &quot;  \
        -s mrxl.data test/sos.mrxl.data
</code></pre>
<p>If you are feeling good about your implementation, skip to <a href="tutorial/frontend-tut.html#adding-parallelization">the next section</a>!
If you'd like to read through the details of our implementation – or build yours in tandem – continue on with the rest of this section.</p>
<h3 id="loop-condition"><a class="header" href="#loop-condition">Loop condition</a></h3>
<p>We define a <a href="tutorial/../lang/ref.html#comb-group-definitions">combinational group</a> to perform the comparison <code>idx &lt; arr_size</code> that uses an <code>lt</code> cell:</p>
<pre><code class="language-python">    group_name = f&quot;cond_{suffix}&quot;
    cell = f&quot;lt_{suffix}&quot;
    less_than = comp.cell(cell, Stdlib.op(&quot;lt&quot;, 32, signed=False))
    with comp.comb_group(group_name):
        less_than.left = idx.out
        less_than.right = cb.const(32, arr_size)
</code></pre>
<h3 id="index-increment"><a class="header" href="#index-increment">Index increment</a></h3>
<p>The loop index increment is implemented using a <a href="tutorial/../lang/ref.html#group-definitions">group</a> and an <code>adder</code>:</p>
<pre><code class="language-python">    group_name = f&quot;incr_idx_{suffix}&quot;
    adder = comp.add(f&quot;incr_{suffix}&quot;, 32)
    with comp.group(group_name) as incr:
        adder.left = idx.out
        adder.right = 1
        idx.in_ = adder.out
        idx.write_en = 1
        incr.done = idx.done
</code></pre>
<p>We provide the index's previous value and the constant <code>1</code> to <code>adder</code>, and write the adder's output into the register (<code>idx</code>).
Because we're performing a stateful update of the register, we must wait for the register to state that it has committed the write.
We do this by setting the group's <code>done</code> condition to track the register's <code>done</code> signal.</p>
<h3 id="body-computation"><a class="header" href="#body-computation">Body computation</a></h3>
<p>The final piece of the puzzle is the body's computation.
The corresponding group indexes into the input memories:</p>
<pre><code class="language-python">        with comp.group(f&quot;eval_body_{suffix}&quot;) as evl:
            # Index each array
            for bind in stmt.binds:
                # Map bindings have exactly one dest
                mem = comp.get_cell(f&quot;{name2arr[bind.dst[0]]}&quot;)
                mem.addr0 = idx.out
</code></pre>
<p>Because the builder module is an embedded DSL, we can simply use Python's <code>for</code> loop to generate all the required assignments for indexing.</p>
<p>This code instantiates an adder or a multiplier depending on the computation needed using the <code>expr_to_port</code> helper function:</p>
<pre><code class="language-python">        if body.operation == &quot;mul&quot;:
            operation = comp.cell(
                f&quot;mul_{suffix}&quot;, Stdlib.op(&quot;mult_pipe&quot;, 32, signed=False)
            )
        else:
            operation = comp.add(f&quot;add_{suffix}&quot;, 32)
</code></pre>
<p>and writes the value from the operation into the output memory:</p>
<pre><code class="language-py">            out_mem = comp.get_cell(f&quot;{dest}_b{bank}&quot;)
            out_mem.addr0 = idx.out
            out_mem.write_data = operation.out
            # Multipliers are sequential so we need to manipulate go/done signals
            if body.operation == &quot;mul&quot;:
                operation.go = 1
                out_mem.write_en = operation.done
            else:
                out_mem.write_en = 1
            evl.done = out_mem.done
</code></pre>
<p>This final operation is complicated because we must account for whether we're using an adder or a multiplier.
Adders are <em>combinational</em>–they produce their output immediately–while multipliers are <em>sequential</em> and require multiple cycles to produce its output.</p>
<p>When using a mutliplier, we need to explicitly set its <code>go</code> signal to one and only write the output from the multiplier into the memory when its <code>done</code> signal is asserted.
We do this by assigning the memory's <code>write_en</code> (write enable) signal to the multiplier's done signal.
Finally, the group's computation is done when the memory write is committed.</p>
<h3 id="generating-control"><a class="header" href="#generating-control">Generating control</a></h3>
<p>Once we have generated the hardware needed for our computation, we can schedule its computation using <a href="tutorial/../lang/ref.html#the-control-operators">control operators</a>:</p>
<pre><code class="language-py">            While(
                CompPort(CompVar(port), &quot;out&quot;),
                CompVar(cond),
                SeqComp(
                    [
                        Enable(f&quot;eval_body_{suffix}&quot;),
                        Enable(incr),
                    ]
                ),
            )
</code></pre>
<p>We generate a while loop that checks that the index is less than the array size.
Then, it sequentially executes the computation for the body and increments the loop index.</p>
<blockquote>
<p>Take a breather! You now understand the basics of compiling DSLs to Calyx.
However, we're not done yet; we build hardware because we want things to be fast and efficient, so the next part will teach you how to parallelize MrXL programs.</p>
</blockquote>
<h2 id="adding-parallelization"><a class="header" href="#adding-parallelization">Adding parallelization</a></h2>
<p>MrXL allows us to parallelize our <code>map</code> operations.</p>
<p>Consider a variation on our prior example:</p>
<pre><code>input avec: int[4]
output squares: int[4]
squares := map 2 (a &lt;- avec) { a * a }
</code></pre>
<p>The noteworthy change is the parallelism factor of the <code>map</code> operation.
The parallelism factor <code>2</code> specifies that two copies of the loop bodies should be executed in parallel.</p>
<p>Translating this into a hardware implementation has a couple of associated challenges:</p>
<ol>
<li>Our memories (<code>std_mem_d1</code>) are <em>extremely</em> primitive and do not support parallel accesses; a program may only read or write to one memory location every cycle. In order to support parallel accesses, we need to create <em>multiple physical banks</em> that represent one logical memory and contain distinct elements.</li>
<li>We need to generate <em>multiple copies</em> of the hardware we generated above because, again, adders and multipliers are physical resources and can only support one computation at a time.</li>
</ol>
<p>To produce the full Calyx program for the above example, run the following from the root of the Calyx repository:</p>
<pre><code>fud e --from mrxl --to calyx frontends/mrxl/test/squares.mrxl
</code></pre>
<h3 id="memory-banking"><a class="header" href="#memory-banking">Memory banking</a></h3>
<!-- Let us look back at our example featuring a parallel `map`:
```
input avec: int[4]
output squares: int[4]
squares := map 2 (a <- avec) { a * a }
```

Interpret this with:
```
mrxl frontends/mrxl/test/squares.mrxl --data frontends/mrxl/test/squares.mrxl.data --interpret
```

But more interestingly, compile this to Calyx IL with:
```
mrxl frontends/mrxl/test/squares.mrxl
``` -->
<p>There's a lot going on in the Calyx code, but the thing to focus on is this.
To take advantage of the parallelism in the program, the MrXL compiler assumes that the input memory <code>avec</code> is split into two <em>banks</em>, <code>avec_b0</code> and <code>avec_b1</code>.
Look for these in the Calyx code.</p>
<p>Why do we do this? Memories in Calyx can only support one read/write per cycle of the clock, so if we keep <code>avec</code> around as one memory, our attempts at parallelization will be thwarted simply because we will be bottlenecked when accessing our data.
Splitting <code>avec</code> into two banks allows us to read/write into two logical spots of <code>avec</code> in parallel.</p>
<p>Banking comes with an additional responsibility.
When driving data to the memories, we can't just supply values for a memory <code>avec</code>.
The memory <code>avec</code> exists logically in our minds, but Calyx now only knows about <code>avec_b0</code> and <code>avec_b1</code>.
We must drive data to <em>these</em>.
Though nontrivial, this data-banking can also be <a href="tutorial/frontend-tut.html#aside-supplying-data-to-mrxl-programs">handled automatically</a>; all the necessary information is in the MrXL source program.</p>
<h3 id="parallel-control"><a class="header" href="#parallel-control">Parallel Control</a></h3>
<p>Next, our compiler duplicates the computational resources, hooks them up to the right memories using groups, and generates a control program that looks like this:</p>
<pre><code>par {
  while le_b0.out with cond_b0 { seq { eval_body_b0; incr_idx_b0; } }
  while le_b1.out with cond_b1 { seq { eval_body_b1; incr_idx_b1; } }
}
</code></pre>
<p>The <a href="tutorial/../lang/ref.html#par"><code>par</code> operator</a> executes all the loops in parallel which use distinct computational resources.
As specified by the language specification, <a href="tutorial/../lang/ref.html#par">conflicting resource usage is undefined behavior</a>.</p>
<p>You can use <code>fud</code> to compile the MrXL program and run it with some data:</p>
<pre><code>fud e --from mrxl --to dat \
      --through verilog \
      -s mrxl.data frontends/mrxl/test/squares.mrxl.data \
      frontends/mrxl/test/squares.mrxl
</code></pre>
<blockquote>
<p>The <a href="https://github.com/cucapra/calyx/blob/master/frontends/mrxl/mrxl/gen_calyx.py">complete implementation</a> shows the necessary code to create physical memory banks and create an outer loop to generate distinct hardware for each copy of the loop.</p>
</blockquote>
<h1 id="further-steps"><a class="header" href="#further-steps">Further Steps</a></h1>
<p>Congratulations, you know about as much about MrXL as we do!
The small size of the language makes it a nice sandbox for you to play in.
We mentioned that the restrictions placed on the language can be lifted by beefing up the compiler, and here's your chance to give it a whirl!</p>
<p>Here are some of those restrictions again, along with pointers about how to lift them.</p>
<ol>
<li>
<blockquote>
<p>The bodies of <code>map</code> and <code>reduce</code> operations must be binary <code>+</code> or <code>*</code> operations involving array elements or integers.</p>
</blockquote>
<p>Say you wanted to add subtraction and division to the mix.
We have set you up for success: the MrXL parser already parses <code>-</code> and <code>/</code> into <code>sub</code> and <code>div</code> respectively.
Now, in <code>gen_calyx.py</code>, you need to check for &quot;sub&quot; and &quot;div&quot; as possible binary operations, and then invoke the appropriate cell-builders of the <code>builder</code> library.
For reference, see how the <code>+</code> and <code>*</code> operations are handled at present.
For &quot;fun&quot;, take a look at how Calyx implements <a href="https://github.com/cucapra/calyx/blob/master/primitives/binary_operators.sv#L27-L45">multiplication</a>, and how that maps to the existing invocation to create a 32-bit multiplication cell using the <code>builder</code>!</p>
</li>
<li>
<blockquote>
<p>All <code>reduce</code> operations must be performed sequentially, i.e., with parallelism factor <code>1</code>.</p>
</blockquote>
<p>This is a big gap!
One way to perform reductions in parallel is using <em>reduction trees</em>.
To get you started, we provide a toy implementation using the <code>builder</code> <a href="https://github.com/cucapra/calyx/blob/master/calyx-py/test/reduction_tree.py">here</a>.
That example is rather brittle: it takes exactly 16 inputs, banked into four arrays, and adds their values together.
Try incorporating this brittle version into your MrXL-to-Calyx compiler at first, and you can later think about generalizing it to any (commutative) operation, memories of any length, and any parallelism factor.</p>
<p>If you'd like to read more about reduction trees, you can check out <a href="http://www.cs.ucr.edu/~nael/217-f15/lectures/217-lec10.pdf">these slides</a> from David Kirk and Wen-mei W. Hwu.</p>
</li>
<li>
<blockquote>
<p>If repeated <code>map</code>/<code>reduce</code> operations are performed on the same array, each of those operations must have the same parallelism factor.</p>
</blockquote>
<p>The heart of the issue is figuring out how to bank the underlying array.
How do we bank it two different ways at the same time?
The answer is to bank the array a little finer than you think, and to then use <em>arbitration logic</em> to provide two fictional banking setups at the same time.
We provide a toy implementation using the <code>builder</code> <a href="https://github.com/cucapra/calyx/blob/master/calyx-py/test/arbiter_6.py">here</a>.
There, a 24-cell array has been split into <em>six</em> banks, but then we allow the user to pretend, simultaneously, that it is split into <em>two</em> banks or <em>three</em> banks.</p>
</li>
</ol>
<h1 id="aside-supplying-data-to-mrxl-programs"><a class="header" href="#aside-supplying-data-to-mrxl-programs">Aside: supplying data to MrXL programs</a></h1>
<p>You may have noticed that the data files that we pass to MrXL programs are lighter-weight than those we pass to Calyx programs.
They are lighter in two ways.</p>
<h2 id="boilerplate"><a class="header" href="#boilerplate">Boilerplate</a></h2>
<p>Calyx requires cells to be allocated for the output cells.
Instead of asking the user to supply zeroed-out arrays and registers for output cells, we can infer the need for these output cells from the source code.
We can then add these on to the MrXL-native data files to make them amenable to Calyx.</p>
<p>Additionally, because MrXL supports only a few kinds of data, some interesting parameters of Calyx-native data files turn into &quot;just boilerplate&quot; in MrXL-native data.
We can keep MrXL-native data files relatively light and add this <code>format</code> information automatically.</p>
<h2 id="example-squaresmrxldata"><a class="header" href="#example-squaresmrxldata">Example: <code>squares.mrxl.data</code></a></h2>
<p>Let us look at these changes in practice.</p>
<p>We write <code>avec</code>'s values as a straightforward array:</p>
<pre><code class="language-json">{
	&quot;avec&quot;: [
			0,
			1,
			4,
			5
		]
}
</code></pre>
<p>but under the hood, the <em>Calyx IL version</em> of <code>squares.mrxl</code> comes to expect something of the form:</p>
<pre><code class="language-json">{
    &quot;avec_b0&quot;: {
        &quot;data&quot;: [
            0,
            1
        ],
        &quot;format&quot;: {
            &quot;is_signed&quot;: false,
            &quot;numeric_type&quot;: &quot;bitnum&quot;,
            &quot;width&quot;: 32
        }
    },
    &quot;avec_b1&quot;: {
        &quot;data&quot;: [
            4,
            5
        ],
        &quot;format&quot;: {
            &quot;is_signed&quot;: false,
            &quot;numeric_type&quot;: &quot;bitnum&quot;,
            &quot;width&quot;: 32
        }
    },
    &quot;squares_b0&quot;: {
        &quot;data&quot;: [
            0,
            0
        ],
        &quot;format&quot;: {
            &quot;is_signed&quot;: false,
            &quot;numeric_type&quot;: &quot;bitnum&quot;,
            &quot;width&quot;: 32
        }
    },
    &quot;squares_b1&quot;: {
        &quot;data&quot;: [
            0,
            0
        ],
        &quot;format&quot;: {
            &quot;is_signed&quot;: false,
            &quot;numeric_type&quot;: &quot;bitnum&quot;,
            &quot;width&quot;: 32
        }
    }
}
</code></pre>
<p>And we can generate this automatically. Try it yourself:</p>
<pre><code>mrxl frontends/mrxl/test/squares.mrxl --data frontends/mrxl/test/squares.mrxl.data --convert
</code></pre>
<p>This transformation is achieved using a <a href="tutorial/../fud/index.html"><code>fud</code></a> pass that converts MrXL-native data files into Calyx-native data files.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="frontend-compilers"><a class="header" href="#frontend-compilers">Frontend Compilers</a></h1>
<p>Several compiler generate Calyx programs from other high-level languages.</p>
<ul>
<li><a href="frontends/./dahlia.html">Dahlia</a>: Dahlia is an imperative, loop-based programming language.</li>
<li><a href="frontends/./systolic-array.html">Systolic Array Generator</a>: Generates systolic arrays using parameters.</li>
<li><a href="frontends/./tvm-relay.html">TVM Relay</a>: Relay is an IR for the TVM framework to replace old computation graph based IRs.</li>
<li><a href="frontends/./ntt.html">NTT Pipeline Generator</a>: Generates a pipeline for the number theoretic transform.</li>
<li><a href="frontends/./mrxl.html">MrXL</a>: A simple example frontend developed in the <a href="frontends/../tutorial/frontend-tut.html">frontend tutorial</a>.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="dahlia"><a class="header" href="#dahlia">Dahlia</a></h1>
<p><a href="https://capra.cs.cornell.edu/dahlia">Dahlia</a> is an imperative, loop-based programming language for designing
hardware accelerators.</p>
<h2 id="installation-2"><a class="header" href="#installation-2">Installation</a></h2>
<p>First, install <a href="https://www.scala-sbt.org/1.x/docs/Setup.html">sbt</a> and <a href="https://docs.scala-lang.org/getting-started/index.html">scala</a>.</p>
<p>Then, clone the repository and build the Dahlia compiler:</p>
<pre><code>git clone https://github.com/cucapra/dahlia.git
cd dahlia
sbt compile
sbt assembly
chmod +x ./fuse
</code></pre>
<p>The Dahlia compiler can be run using the <code>./fuse</code> binary:</p>
<pre><code>./fuse --help
</code></pre>
<p>Finally, configure <code>fud</code> to use the Dahlia compiler:</p>
<pre><code>fud c stages.dahlia.exec &lt;path to Dahlia repository&gt;/fuse
</code></pre>
<p>Use <code>fud</code> to check if the compiler was installed correctly:</p>
<pre><code>fud check
</code></pre>
<p><code>fud</code> should report that the Dahlia compiler is available and has the right
version.</p>
<p>If something went wrong, try following the <a href="https://github.com/cucapra/dahlia#set-it-up">instructions</a> to build the Dahlia
compiler from its repository.</p>
<h2 id="compiling-dahlia-to-calyx"><a class="header" href="#compiling-dahlia-to-calyx">Compiling Dahlia to Calyx</a></h2>
<p>Dahlia programs can be compiled to Calyx using:</p>
<pre><code>fud e --from dahlia &lt;input file&gt; --to calyx
</code></pre>
<p>The Dahlia backed for Calyx is neither <em>complete</em> nor <em>stable</em>. If you find
a confusing error or wrong program, please open an <a href="https://github.com/cucapra/dahlia/issues">issue</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="systolic-array"><a class="header" href="#systolic-array">Systolic Array</a></h1>
<p>Systolic arrays are commonly used to implement fast linear-algebra
computations. See <a href="http://www.eecs.harvard.edu/~htk/publication/1982-kung-why-systolic-architecture.pdf">this paper</a> for an overview on
systolic arrays.</p>
<p>The systolic array frontend lives in the <a href="https://github.com/cucapra/calyx/tree/master/frontends/systolic-lang">systolic-lang</a> folder in the
Calyx repository and generates systolic arrays that can perform matrix
multiplies.</p>
<p>The <code>gen-systolic.py</code> contains the entire program required to generate
systolic arrays. In order to generate an <em>8 X 8</em> systolic array, run:</p>
<pre><code>./frontends/systolic-lang/gen-systolic.py -tl 8 -td 8 -ll 8 -ld 8
</code></pre>
<h2 id="installation-3"><a class="header" href="#installation-3">Installation</a></h2>
<p>Install the <a href="frontends/../calyx-py.html">calyx-py</a> library.</p>
<h2 id="command-line-options"><a class="header" href="#command-line-options">Command Line Options</a></h2>
<p>The command line options configure the dimensions of the generated
systolic array. There are no other properties of the systolic array that
can be configured.</p>
<ul>
<li><code>--top-length</code>, <code>--left-length</code>: The length of top and left sides of the systolic array.</li>
<li><code>--top-depth</code>, <code>--left-depth</code>: The length of the input streams from top and left sides of the array.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="tvm-relay"><a class="header" href="#tvm-relay">TVM Relay</a></h1>
<p><a href="https://tvm.apache.org">TVM</a> is a compiler for machine learning frameworks that can
optimize and target kernels to several different backends. <a href="https://tvm.apache.org/docs/api/python/relay/index.html">Relay</a>
is a high level intermediate representation for the TVM framework.
The goal of Relay is to replace old computation graph based
IRs with a more expressive IR.
More information can be found in <a href="https://arxiv.org/abs/1904.08368">this paper</a>.</p>
<p>The TVM Relay frontend lives in the <a href="https://github.com/cucapra/calyx/tree/master/frontends/relay">relay-lang</a> folder in the
Calyx repository and generates Calyx components from the Relay
intermediate representation.</p>
<h2 id="installation-4"><a class="header" href="#installation-4">Installation</a></h2>
<ol>
<li>
<p>Clone the TVM repository and checkout the tag <code>v0.10.dev0</code>:</p>
<pre><code> git clone git@github.com:apache/incubator-tvm.git
 cd incubator-tvm &amp;&amp; git checkout v0.10.dev0
 git submodule init &amp;&amp; git submodule update
</code></pre>
</li>
<li>
<p>Set up to build (the default configuration is fine because we don't need any fancy backends like LLVM or CUDA):</p>
<pre><code> mkdir build &amp;&amp; cd build
 cp ../cmake/config.cmake .
</code></pre>
</li>
<li>
<p>Build TVM:</p>
<pre><code> cmake -G Ninja .. &amp;&amp; ninja
</code></pre>
</li>
<li>
<p>Install the <code>tvm</code> Python package by building a <a href="https://packaging.python.org/guides/distributing-packages-using-setuptools/#wheels">wheel</a>:</p>
<pre><code> cd ../python &amp;&amp; python3 setup.py bdist_wheel
 pip3 install --user dist/tvm-*.whl
</code></pre>
<blockquote>
<p>If you get an error with <code>shutil</code>, try deleting the <code>python/</code> directory, restoring it, and rerunning the above command: <code>cd .. &amp;&amp; rm -rf python &amp;&amp; git checkout -- python</code><br />
If you are on MacOS - Big Sur and are getting an error similar to &quot;(wheel).whl is not a supported wheel on this platform&quot;, try changing part of the wheel's filename from 11_0 to 10_9. See this github <a href="https://github.com/apple/tensorflow_macos/issues/46">issue</a> for more information. </p>
</blockquote>
</li>
<li>
<p>Install ANTLR v4.7.2 (required for the Relay text format parser):</p>
<pre><code> pip3 install -Iv antlr4-python3-runtime==4.7.2
</code></pre>
</li>
<li>
<p>To run the <a href="https://github.com/apache/incubator-tvm/blob/main/python/tvm/relay/testing/mlp.py">MLP net</a> and <a href="https://github.com/apache/incubator-tvm/blob/main/python/tvm/relay/testing/vgg.py">VGG net</a> examples, install <code>pytest</code>:</p>
<pre><code> pip3 install pytest
</code></pre>
</li>
<li>
<p>Install <a href="https://github.com/cucapra/dahlia#set-it-up">Dahlia</a>, which is used when lowering Relay call nodes to Calyx.</p>
</li>
<li>
<p>Install the <a href="frontends/../calyx-py.html">calyx-py</a> library.</p>
</li>
</ol>
<h2 id="run-an-example"><a class="header" href="#run-an-example">Run an Example</a></h2>
<p>Try this to run a simple example:</p>
<pre><code>cd calyx/frontends/relay
python3 example.py tensor_add
</code></pre>
<ul>
<li><code>-h</code>: Help option; shows available examples.</li>
<li><code>-r</code>: Dumps the Relay IR. Otherwise, it dumps the Calyx output.</li>
</ul>
<h2 id="simulate-an-onnx-model"><a class="header" href="#simulate-an-onnx-model">Simulate an ONNX Model</a></h2>
<p>A simple script is provided to run an Open Neural Network Exchange (ONNX) model.
In addition to installing TVM Relay above, you'll need the following PIP installations
for ONNX simulation and image pre-processing:</p>
<pre><code>pip3 install opencv-python Pillow mxnet onnx simplejson
</code></pre>
<p>For example, we can simulate the LeNet ONNX model found <a href="https://github.com/ekut-es/pico-cnn/blob/master/data/lenet/lenet.onnx">here</a> using the following command:</p>
<pre><code>python3 frontends/relay/onnx_to_calyx.py \
-n &quot;lenet&quot; \
-d &quot;MNIST&quot; \
-i &quot;/path/to/image.png&quot; \
-onnx &quot;/path/to/model.onnx&quot; \
-o calyx
</code></pre>
<ul>
<li><code>-n</code>: The name of the input net. This is mostly used for naming the output files.</li>
<li><code>-d</code>: The dataset for which the input will be classified against. This is necessary to
determine what preprocessing should be done on the image. e.g. <code>&quot;mnist&quot;</code> or <code>&quot;imagenet&quot;</code>.</li>
<li><code>-i</code>: The file path to the input image which you want classified.</li>
<li><code>-onnx</code>: The file path to the ONNX model.</li>
<li><code>-o</code>: The type of output.
<ol>
<li><code>tvm</code>: Executes the ONNX model using the TVM executor. Prints the final softmax value
to console. No postprocessing is conducted.</li>
<li><code>relay</code>: Output a file with the corresponding Relay program. <code>&lt;net_name&gt;.relay</code></li>
<li><code>calyx</code>: Output a <code>.data</code> file and Calyx program for simulation. <code>&lt;net_name&gt;.futil</code>, <code>&lt;net_name&gt;.data</code></li>
<li><code>all</code>: All the above.</li>
</ol>
</li>
<li><code>-s</code>: This is an optional boolean argument that signifies <code>save_mem</code>, and is set to true by default. If this flag is set to true, then it will produce a Calyx 
design that requires less internal memory usage compared to the design that is produced when this flag is false. </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="number-theoretic-transform-ntt"><a class="header" href="#number-theoretic-transform-ntt">Number Theoretic Transform (NTT)</a></h1>
<p>The number theoretic transform is a generalization of the
fast Fourier transform that uses nth primitive root of unity
based upon a quotient ring instead of a field of complex numbers.</p>
<p>It is commonly used to speed up computer arithmetic, such as the
multiplication of large integers and large degree polynomials. The
pipeline produced here is based upon <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/05/RLWE-1.pdf">this paper</a>,
which also provides some background information on NTT.</p>
<p>The NTT pipeline frontend lives in the <a href="https://github.com/cucapra/calyx/tree/master/frontends/ntt-pipeline">ntt</a> folder in the
Calyx repository and generates the pipeline for the NTT transform.</p>
<p>The <code>gen-ntt-pipeline.py</code> file contains the entire program required to
generate NTT pipelines. In order to generate a pipeline with
bit width <code>32</code>, input size <code>4</code>, and modulus value <code>97</code>:</p>
<pre><code>./frontends/ntt-pipeline/gen-ntt-pipeline.py -b=32 -n=4 -q=97
</code></pre>
<h2 id="installation-5"><a class="header" href="#installation-5">Installation</a></h2>
<p>Install the <a href="frontends/../calyx-py.html">calyx-py</a> library.</p>
<p>The generator also produces a table to illustrate which operations are occurring
during each stage of the pipeline. This requires installing PrettyTable:</p>
<pre><code>pip3 install prettytable numpy
</code></pre>
<h2 id="fud-stage"><a class="header" href="#fud-stage">Fud Stage</a></h2>
<p>The NTT pipeline defines an [external fud stage][../fud/external.md] to
transform configuration files into Calyx programs.
To install, run:</p>
<pre><code>fud register ntt -p frontends/ntt-pipeline/fud/ntt.py &amp;&amp; fud check
</code></pre>
<p>This should report the newly installed <code>ntt</code> stage in the configuration.</p>
<h2 id="configuration-files"><a class="header" href="#configuration-files">Configuration Files</a></h2>
<p>Configurations files simply specify command line parameters:</p>
<pre><code class="language-json">{
  &quot;input_bitwidth&quot;: 32,
  &quot;input_size&quot;: 4,
  &quot;modulus&quot;: 97
}
</code></pre>
<h2 id="command-line-options-1"><a class="header" href="#command-line-options-1">Command Line Options</a></h2>
<p>The command line options configure the bit width, size, and modulus value of the
pipeline.</p>
<ul>
<li><code>--input_bitwidth</code>: The bit width of each value in the input array.</li>
<li><code>--input_size</code>: The length (or size) of the input array.</li>
<li><code>--modulus</code>: The (prime) modulus value used during the transformation.</li>
<li><code>--parallel_reduction</code>: Decreases fan-out by reducing the number of groups executed in parallel by this factor.</li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="mrxl"><a class="header" href="#mrxl">MrXL</a></h1>
<p>MrXL is an example DSL developed for the <a href="frontends/../tutorial/frontend-tut.html">frontend tutorial</a>.
MrXL programs consist of <code>map</code> and <code>reduce</code> operations on arrays.
For example, here is an implementation of dot-products:</p>
<pre><code>input avec: int[1024]
input bvec: int[1024]
output dot: int
prodvec := map 16 (a &lt;- avec, b &lt;- bvec) { a * b }
dot := reduce 4 (a, b &lt;- prodvec) 0 { a + b }
</code></pre>
<p>The numbers that come right after <code>map</code> and <code>reduce</code> (<code>16</code> and <code>4</code> respectively) are &quot;parallelism factors&quot; that guide the generation of hardware.
The explanation on this page is relatively brief; see the <a href="frontends/../tutorial/frontend-tut.html">frontend tutorial</a> for a more detailed explanation of the language. In particular, the <a href="frontends/../tutorial/frontend-tut.html#example-sum-of-squares">sum of squares</a> example is a good place to start.</p>
<h2 id="install"><a class="header" href="#install">Install</a></h2>
<p>First, install the <a href="frontends/../calyx-py.html">calyx-py</a> library.</p>
<p>The MrXL implementation is in Python and uses <a href="https://flit.readthedocs.io/en/latest/index.html">Flit</a>.
Install Flit (<code>pip install flit</code> or similar), and then type the
following after changing your directory to <code>frontend/mrxl</code>:</p>
<pre><code>flit install --symlink
</code></pre>
<p>This creates a symbolic link to the present directory and installs the <code>mrxl</code> command line tool.</p>
<p>By default, <a href="frontends/../fud">fud</a> looks for the <code>mrxl</code> executable to enable
the <code>mrxl</code> compilation stage.
Type <code>fud check</code> to make sure <code>fud</code> reports that the <code>mrxl</code> compiler has been
found. If it does not, run the following while still in <code>frontend/mrxl</code>.</p>
<pre><code>fud register mrxl -p fud/mrxl.py
</code></pre>
<p>Run <code>fud check</code> again to ensure that <code>fud</code> sees <code>mrxl</code>.</p>
<h2 id="interpreting-mrxl"><a class="header" href="#interpreting-mrxl">Interpreting MrXL</a></h2>
<p>To run the program through the MrXL interpreter, execute:</p>
<pre><code>mrxl &lt;prog&gt;.mrxl --data &lt;prog&gt;.mrxl.data --interpret
</code></pre>
<p>where <code>&lt;prog&gt;.mrxl</code> is a file containing MrXL source code and <code>&lt;prog&gt;.mrxl.data</code> is a file containing values for all the variables declared as <code>input</code>s in the MrXL program. The interpreter dumps the <code>output</code> variables, in JSON format, to stdout.</p>
<p>You could try, for example:</p>
<pre><code>mrxl test/dot.mrxl --data test/dot.mrxl.data --interpret
</code></pre>
<p>This is just a baby version of the dot-product implementation we showed at the very top; we have just shortened the input array so you can easily see it in full.
Similarly, we also provide <code>add.mrxl</code> and <code>sum.mrxl</code>, along with accompanying <code>&lt;prog&gt;.mrxl.data</code> files, under <code>test/</code>. Try playing with the inputs and the operations!</p>
<h2 id="compiling-to-calyx"><a class="header" href="#compiling-to-calyx">Compiling to Calyx</a></h2>
<blockquote>
<p>The dot-product example above shows off features of MrXL that are not yet supported by the compiler. In particular, the compiler does not yet support <code>reduce</code> with a parallelism factor other than <code>1</code>. This is because MrXL is mostly a pedagogical device, and we want new users of Calyx to try implementing this feature themselves. To learn more about this and other extensions to MrXL, consider working through the <a href="frontends/../tutorial/frontend-tut.html">frontend tutorial</a>.</p>
</blockquote>
<p>To run the compiler and see the Calyx code your MrXL program generates, just drop the <code>--data</code> and <code>--interpret</code> flags. For instance:</p>
<pre><code>mrxl test/dot.mrxl
</code></pre>
<p>In order to run the compiler through <code>fud</code>, pass the <code>--from mrxl</code> and <code>--to calyx</code> flags:</p>
<pre><code>fud e --from mrxl &lt;prog.mrxl&gt; --to calyx
</code></pre>
<p>And finally, the real prize.
In order to compile MrXL to Calyx and then simulate the Calyx code in Verilog, run:</p>
<pre><code>fud e --from mrxl &lt;prog&gt;.mrxl --to dat --through verilog -s mrxl.data &lt;prog&gt;.mrxl.data
</code></pre>
<p>An aside: MrXL permits a simplified data format, which is what we have been looking at in our <code>&lt;prog&gt;.mrxl.data</code> files.
Files of this form need to be beefed up with additional information so that Verilog (and similar simulators) can work with them.
We did this beefing up &quot;on the fly&quot; in the incantation above, but it is interesting to see the changes we made.</p>
<p>See this with:</p>
<pre><code>mrxl &lt;prog&gt;.mrxl --data &lt;prog&gt;.mrxl.data --convert
</code></pre>
<p>The output dumped to stdout is exactly this beefed-up data.
The changes it makes are:</p>
<ol>
<li>It adds some boilerplate about the <code>format</code> of the data.</li>
<li>It infers the <code>output</code> variables required by the program and adds data fields for them.</li>
<li>It infers, for each memory, the parallelism factor requested by the program, and then divides the relevant data entries into <em>memory banks</em>.</li>
</ol>
<div style="break-before: page; page-break-before: always;"></div><h1 id="runt"><a class="header" href="#runt">Runt</a></h1>
<p>Runt (Run Tests) is the expectation testing framework for Calyx. It organizes
collections of tests into test suites and specifies configuration for them.</p>
<p>Runt uses <code>runt.toml</code> to define the test suites and configure them.</p>
<h2 id="cheatsheet"><a class="header" href="#cheatsheet">Cheatsheet</a></h2>
<p>Runt workflow involves two things:</p>
<ol>
<li>Running tests and comparing differences</li>
<li>Saving new or changed golden files</li>
</ol>
<p>To run all the tests in a directory, run <code>runt</code> with a folder containing <code>runt.toml</code>.</p>
<p>The following commands help focus on specific tests to run:</p>
<ul>
<li><code>-i</code>: Include files that match the given pattern. The pattern is matched against <code>&lt;suite name&gt;:&lt;file path&gt;</code> so it can be used to filter both test suites or specific paths. General regex patterns are supported.</li>
<li><code>-x</code>: Exclude files that match the pattern</li>
<li><code>-o</code>: Filter out reported test results based on test status. Running with <code>miss</code> will only show the tests that don't have an <code>.expect</code> file.</li>
</ul>
<p><strong>Differences</strong>. <code>-d</code> or <code>--diff</code> shows differences between the expected test output and the generated output. Use this in conjunction with <code>-i</code> to focus on particular failing tests.</p>
<p><strong>Saving Files</strong>. <code>-s</code> is used to save test outputs when they have expected changes. In the case of <code>miss</code> tests, i.e. tests that currently don't have any expected output file, this saves a completely new <code>.expect</code> file.</p>
<p><strong>Dry run</strong>. <code>-n</code> flag shows the commands that <code>runt</code> will run for each test. Use this when you directly want to run the command for the test directly.</p>
<p>For other options, look at <code>runt --help</code> which documents other features in <code>runt</code>.</p>
<p>For instruction on using runt, see the <a href="https://docs.rs/runt/latest/runt/">official documentation</a>.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="data-gen"><a class="header" href="#data-gen">Data Gen</a></h1>
<p>Data Gen is a tool that can generate a memory json from a Calyx file. It reads 
the Calyx file and generates an entry in the json for each cell marked with the 
<code>@external</code> attribute. Currently, there are two types of number representation formats that can be generated as the data for the memory json: 1) unsigned 32 bit bitnums all equal to 0 and 2) signed, 32 bit fixed point numbers with <code>frac_width</code> = 16, and the data is randomly generated.</p>
<h2 id="how-to-run"><a class="header" href="#how-to-run">How to Run</a></h2>
<p>The following command can be run to generate unsigned, 32-bit zeroes:<br />
<code>cargo run -p data_gen -- &lt;calyx file&gt;</code></p>
<p>To generate random fixed point numbers, run:<br />
<code>cargo run -p data_gen -- &lt;calyx file&gt; -f true</code></p>
<p>It will print the json in the command line</p>
<h2 id="current-limitations"><a class="header" href="#current-limitations">Current Limitations</a></h2>
<p>As you can see, the tool is right now pretty limited, because it only supports 2 different representations of numbers. What if you want to generate random, 8 bit, unsigned ints in your memory? Data Gen currently wouldn't support that. Ideally, we would want each Calyx memory cell to have its own attribute(s) which can hold information about what type of number representation format the memory wants. This <a href="https://github.com/cucapra/calyx/issues/1163">github issue</a> goes into more detail about future improvements for the tool. </p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="exp-generator"><a class="header" href="#exp-generator"><code>exp</code> Generator</a></h1>
<p>The <code>exp</code> generator uses a Taylor series approximation to calculate the fixed point value of the natural
exponential function <code>e^x</code>. The <a href="https://en.wikipedia.org/wiki/Taylor_series#Exponential_function">Maclaurin series</a> 
for the function can be written as:</p>
<pre><code>e^x = 1 + x + x^2/2! + x^3/3! + ... + x^n/n!
</code></pre>
<p>where <code>n</code> is the nth degree or order of the polynomial.</p>
<p>For signed values, we can take the reciprocal value:</p>
<pre><code>e^(-x) = 1/e^x
</code></pre>
<p>The <code>fp_pow_full</code> component can calculate the value of <code>b^x</code> where <code>b</code> and <code>x</code> are 
any fixed point numbers. This can be calculated by first observing: </p>
<pre><code>b^x = e^(ln(b^x)) = e^(x*ln(b))
</code></pre>
<p>Therefore, we just calculate <code>x*ln(b)</code>, and then we can feed the result into the <code>exp</code><br />
component to get our answer. </p>
<p>To calculate <code>ln(p)</code> for fixed point values <code>p</code>, we use the second order <a href="https://en.wikipedia.org/wiki/Pad%C3%A9_approximant">Padé Approximant</a> of <code>ln(p)</code>. We calculated the approximant 
using <a href="https://www.wolframalpha.com/input?i=+PadeApproximant%5Bln%28x%29%2C%7Bx%2C1.5%2C%7B2%2C2%7D%7D%5D+">Wolfram Alpha</a>.</p>
<p>The <code>gen_exp.py</code> file can generate an entire Calyx program for testing purposes.
<code>gen_exp.py</code> can generate two different types of designs, depending on the 
<code>base_is_e</code> flag: if <code>base_is_e</code> is true, then the design can only caclulate 
values for <code>e^x</code>. The main component contains memories <code>x</code> (for the input) and <code>ret</code> for the result of <code>e^x</code>. 
If <code>base_is_e</code> is false, then the design can calculate values for <code>b^x</code> for any base 
<code>e</code>. Therefore, the main component contains memories <code>x</code> (the exponent input), <code>b</code> (the base intput),
and <code>ret</code> for the result of <code>b^x</code>. 
In order to generate an example program (that can only calculate exponent values with base 
<code>e</code>), with degree <code>4</code>, bit width <code>32</code>, integer bit width <code>16</code>, and <code>x</code> interpreted as a signed value:</p>
<pre><code>./calyx-py/calyx/gen_exp.py -d 4 -w 32 -i 16 -s true -e true 
</code></pre>
<p>Similarly, it provides a function to produce only the necessary components to be dropped into other Calyx programs.</p>
<h2 id="installation-6"><a class="header" href="#installation-6">Installation</a></h2>
<p>Install the <a href="tools/../calyx-py.html">calyx-py</a> library.</p>
<h2 id="command-line-options-2"><a class="header" href="#command-line-options-2">Command Line Options</a></h2>
<p>The command line options configure the degree (or order) of the taylor series, bit width, integer bit width, and sign.</p>
<ul>
<li><code>--degree</code>: The degree of the Taylor polynomial.</li>
<li><code>--width</code>: The bit width of the value <code>x</code>.</li>
<li><code>--int_width</code>: The integer bit width of the value <code>x</code>. The fractional bit width is then inferred as <code>width - int_width</code>.</li>
<li><code>--is_signed</code>: The signed interpretation of the value <code>x</code>. If <code>x</code> is a signed value, this should be <code>true</code> and otherwise, <code>false</code>. </li>
<li><code>--base_is_e</code>: A boolean that determines whether or not to generate 
components needed to just calculate <code>e^x</code>, or to generate components needed to 
calculate <code>b^x</code> for any base <code>b</code>. </li>
</ul>
<div style="break-before: page; page-break-before: always;"></div><h1 id="editor-highlighting"><a class="header" href="#editor-highlighting">Editor Highlighting</a></h1>
<h2 id="vim"><a class="header" href="#vim">Vim</a></h2>
<p>The vim extension highlights files with the extension <code>.futil</code>.
It can be installed using a plugin manager such as <a href="https://github.com/junegunn/vim-plug">vim-plug</a> using a
local installation.
Add the following to your vim plug configuration:</p>
<pre><code>Plug '&lt;path-to-calyx&gt;/tools/vim'
</code></pre>
<p>And run:</p>
<pre><code>:PlugInstall
</code></pre>
<h2 id="emacs"><a class="header" href="#emacs">Emacs</a></h2>
<p><code>futil-mode</code> is implements highlighting for <code>.futil</code> files in emacs.
It is located in <code>&lt;repo&gt;/tools/emacs/futil-mode</code>.</p>
<p>The <code>highlight-numbers</code> package is required as part of <code>futil-mode</code>, install it:</p>
<pre><code>M-x package-install RET highlight-numbers RET
</code></pre>
<p>Clone the repository, add the above path to your <a href="http://www.emacswiki.org/emacs/LoadPath">load path</a>, and require
<code>futil-mode</code> in your <code>.emacs</code> file:</p>
<pre><code class="language-elisp">(push &quot;~/.emacs.d/private/local/futil-mode&quot; load-path)
(require 'futil-mode)
</code></pre>
<p>If you use <a href="https://www.spacemacs.org/">Spacemacs</a>, you would add this to <code>dotspacemacs/user-config</code>
in your <code>.spacemacs</code>.</p>
<h2 id="visual-studio-code"><a class="header" href="#visual-studio-code">Visual Studio Code</a></h2>
<p>Add a link to the Calyx VSCode extension directory to your VSCode extensions directory.</p>
<pre><code>cd $HOME/.vscode/extensions
ln -s &lt;calyx root directory&gt;/tools/vscode calyx.calyx-0.0.1
</code></pre>
<p>Restart VSCode.</p>
<div style="break-before: page; page-break-before: always;"></div><h1 id="contributors"><a class="header" href="#contributors">Contributors</a></h1>
<p>Here is a list of all the people who have worked on Calyx:</p>
<p><strong>Current Contributors</strong></p>
<ul>
<li><a href="https://sgtpeacock.com/">Sam Thomas</a></li>
<li><a href="https://rachitnigam.com">Rachit Nigam</a></li>
<li><a href="https://griffinberlste.in">Griffin Berlstein</a></li>
<li><a href="https://chrispg.dev">Chris Gyurgyik</a></li>
<li><a href="https://adriansampson.net">Adrian Sampson</a></li>
<li>Pai Li</li>
<li>Nathaniel Navarro</li>
<li>Caleb Kim</li>
<li>Andrew Butt</li>
</ul>
<p><strong>Previous Contributors</strong></p>
<ul>
<li><a href="https://neiladit.com/">Neil Adit</a></li>
<li>Kenneth Fang</li>
<li><a href="https://tissue3.github.io/">Zhijing Li</a></li>
<li><a href="https://www.viviyye.com/">Yuwei Ye</a></li>
<li>Ted Bauer</li>
<li>YooNa Chang</li>
<li>Karen Zhang</li>
<li>Andrii Iermolaiev</li>
<li>Alma Thaler</li>
<li>YoungSeok Na</li>
<li><a href="https://jpramos.me">Jan-Paul Ramos</a></li>
<li>Jiaxuan (Crystal) Hu</li>
</ul>
<p>If you're missing from this list, please <a href="https://github.com/cucapra/calyx/edit/master/docs/contributors.md">add yourself</a>!</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->


                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">

            </nav>

        </div>




        <script>
            window.playground_copyable = true;
        </script>


        <script src="elasticlunr.min.js"></script>
        <script src="mark.min.js"></script>
        <script src="searcher.js"></script>

        <script src="clipboard.min.js"></script>
        <script src="highlight.js"></script>
        <script src="book.js"></script>

        <!-- Custom JS scripts -->

        <script>
        window.addEventListener('load', function() {
            MathJax.Hub.Register.StartupHook('End', function() {
                window.setTimeout(window.print, 100);
            });
        });
        </script>

    </div>
    </body>
</html>
